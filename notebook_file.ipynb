 1/1: print(name)
 1/2:
name = ("Jerry")
print(name)
 1/3:
name = ("Jerry")
print("name")
 1/4:
satisfied = True
print(f"Am I satisfied with my current wage? {satisfied}")
 1/5: name = input("What is your name?")
 1/6: print(name)
 1/7: type(name)
 1/8: name = input("What is your name?")
 1/9: print(name)
1/10: name = input("What is your first name?")
1/11: neighbor = input("What is your neighbors first name?)
1/12: neighbor = input("What is your neighbors first name?")
1/13: my_code = input("How long have I been coding for?")
1/14: his_code = input("How long have you been coding for?")
1/15: print(f"name is ")
1/16: print(f"{name} is ")
1/17: print(f"{name} has been coding for str{my_code} months. ")
1/18: print(f"{name} has been coding for {my_code} months. ")
1/19: print(f"{name} has been coding for {my_code} months. {neighbor} has been coding for {his_code} months.")
1/20:
if x <10:
    if y <5:
        print("x is less than 10 and y is less than 5")
    elif y== 5:
        print("x is less than 10 and y is equal to 5")
    else print ("x is less than 10 and y is greater than 5")
1/21:
if x <10:
    if y <5:
        print("x is less than 10 and y is less than 5")
    elif y== 5:
        print("x is less than 10 and y is equal to 5")
1/22:
x = 5
y = 10
if 2 * x > 10:
    print("Question 1 works!")
else:
    print("oooo needs some work")
1/23:
x = 5
y = 10
if len("Dog") < x:
    print("Question 2 works!")
else:
    print("Still missing out")
1/24:
x = 2
y = 5
if (x ** 3 >= y) and (y ** 2 < 26):
    print("GOT QUESTION 3!")
else:
    print("Oh good you can count")
1/25:
myList = ["Jacob, 25, jerry, 23"]
print (myList)
1/26:
myList = ["Jacob", 25, "jerry", 23]
print (myList)
1/27: myList.append("Matt")
1/28:
myList = ["Jacob", 25, "jerry", 23]
print (myList)
1/29:
myList.append("Matt")
print(myList)
1/30: print(myList.index("Matt")
1/31: print(myList.index("Matt"))
1/32:
myList.remove("Matt")
print(myList)
 3/1: Print("Hello User!")
 3/2: Print(Hello User!)
 3/3: print("Hello User!")
 3/4: input("What is your name?")
 3/5: name = input("What is your name?")
 3/6: input(F"Hello {name})
 3/7: print(F"Hello {name})
 3/8: print(f"Hello {name})
 3/9: print(f"Hello {name}")
3/10: input("What is your favorite number?")
3/11: print("Your favorite number is lower than mine.")
3/12: number = input("What is your favorite number?")
3/13:
if number > 7:
    print("Your favorite number is higher than mine.")
elif number < 7:
    print("Your favorite number is lower than mine.")
else:
    print("Your favorite number is the same as mine!")
3/14:
if int(number) > 7:
    print("Your favorite number is higher than mine.")
elif int(number) < 7:
    print("Your favorite number is lower than mine.")
else:
    print("Your favorite number is the same as mine!")
3/15:
if int(number) > your_favorite_number:
    print("Your favorite number is higher than mine.")
elif int(number) < your_favorite_number:
    print("Your favorite number is lower than mine.")
else:
    print("Your favorite number is the same as mine!")
3/16: your_favorite_number = 21
3/17:
if int(number) > your_favorite_number:
    print("Your favorite number is higher than mine.")
elif int(number) < your_favorite_number:
    print("Your favorite number is lower than mine.")
else:
    print("Your favorite number is the same as mine!")
3/18: your_favorite_number = 9
3/19:
if int(number) > your_favorite_number:
    print("Your favorite number is higher than mine.")
elif int(number) < your_favorite_number:
    print("Your favorite number is lower than mine.")
else:
    print("Your favorite number is the same as mine!")
3/20: your_favorite_number = 25
3/21:
if int(number) > your_favorite_number:
    print("Your favorite number is higher than mine.")
elif int(number) < your_favorite_number:
    print("Your favorite number is lower than mine.")
else:
    print("Your favorite number is the same as mine!")
3/22: #Kid in a Candy Store Activity
3/23:
#questions
#Create a loop that prints all of the candies in the store to the terminal, 
#with their index stored in brackets beside them.

#Create a second loop that runs for a set number of times determined by the variable allowance.

#Use another loop to print all of the candies selected to the terminal.
3/24:
# The list of candies to print to the screen
candy_list = ["Snickers", "Kit Kat", "Sour Patch Kids", "Juicy Fruit", "Swedish Fish", "Skittles", "Hershey Bar", "Starbursts", "M&Ms"]

# The amount of candy the user will be allowed to choose
allowance = 5

# The list used to store all of the candies selected inside of
candy_cart = []

# Print out options
3/25:
# The list of candies to print to the screen
candy_list = ["Snickers", "Kit Kat", "Sour Patch Kids", "Juicy Fruit", "Swedish Fish", "Skittles", "Hershey Bar", "Starbursts", "M&Ms"]
print("candy_list.index")
3/26:
# The list of candies to print to the screen
candy_list = ["Snickers", "Kit Kat", "Sour Patch Kids", "Juicy Fruit", "Swedish Fish", "Skittles", "Hershey Bar", "Starbursts", "M&Ms"]
print(candy_list.index)
3/27:
# The list of candies to print to the screen
candy_list = ["Snickers", "Kit Kat", "Sour Patch Kids", "Juicy Fruit", "Swedish Fish", "Skittles", "Hershey Bar", "Starbursts", "M&Ms"]
index = candy_list.index(candy_list)
print(index)
3/28:
# The list of candies to print to the screen
candy_list = ["Snickers", "Kit Kat", "Sour Patch Kids", "Juicy Fruit", "Swedish Fish", "Skittles", "Hershey Bar", "Starbursts", "M&Ms"]
index = candy_list.index("Snickers", "Kit Kat", "Sour Patch Kids", "Juicy Fruit", "Swedish Fish", "Skittles", "Hershey Bar", "Starbursts", "M&Ms")
print(index)
3/29:
# The list of candies to print to the screen
candy_list = ["Snickers", "Kit Kat", "Sour Patch Kids", "Juicy Fruit", "Swedish Fish", "Skittles", "Hershey Bar", "Starbursts", "M&Ms"]
for candy in candy_list:
    print(candy)
3/30:
# The list of candies to print to the screen
candy_list = ["Snickers", "Kit Kat", "Sour Patch Kids", "Juicy Fruit", "Swedish Fish", "Skittles", "Hershey Bar", "Starbursts", "M&Ms"]
for candy in candy_list:
    print(candy & index)
3/31:
# The list of candies to print to the screen
candy_list = ["Snickers", "Kit Kat", "Sour Patch Kids", "Juicy Fruit", "Swedish Fish", "Skittles", "Hershey Bar", "Starbursts", "M&Ms"]
for candy in candy_list:
    print(candy & candy_list.index)
3/32:
# The list of candies to print to the screen
candy_list = ["Snickers", "Kit Kat", "Sour Patch Kids", "Juicy Fruit", "Swedish Fish", "Skittles", "Hershey Bar", "Starbursts", "M&Ms"]
for candy in candy_list:
    print(candy and candy_list.index)
3/33:
candy_list = ["Snickers", "Kit Kat", "Sour Patch Kids", "Juicy Fruit", "Swedish Fish", "Skittles", "Hershey Bar", "Starbursts", "M&Ms"]
index = candy_list.index(f"candy_list")
3/34:
candy_list = ["Snickers", "Kit Kat", "Sour Patch Kids", "Juicy Fruit", "Swedish Fish", "Skittles", "Hershey Bar", "Starbursts", "M&Ms"]
print(f"[{str(candy_list.index(candy))}] {candy}"")
3/35:
# The list of candies to print to the screen
candy_list = ["Snickers", "Kit Kat", "Sour Patch Kids", "Juicy Fruit", "Swedish Fish", "Skittles", "Hershey Bar", "Starbursts", "M&Ms"]
for candy in candy_list:
    print(f"[{str(candy_list.index(candy))}] {candy}")
3/36:
# The list of candies to print to the screen
candy_list = ["Snickers", "Kit Kat", "Sour Patch Kids", "Juicy Fruit", "Swedish Fish", "Skittles", "Hershey Bar", "Starbursts", "M&Ms"]
for candy in candy_list:
    print(f"{str(candy_list.index(candy))} {candy}")
3/37:
# The list of candies to print to the screen
candy_list = ["Snickers", "Kit Kat", "Sour Patch Kids", "Juicy Fruit", "Swedish Fish", "Skittles", "Hershey Bar", "Starbursts", "M&Ms"]
for candy in candy_list:
    print(f"{str(candy_list.index(candy))} {candy}")
3/38:
# The list of candies to print to the screen
candy_list = ["Snickers", "Kit Kat", "Sour Patch Kids", "Juicy Fruit", "Swedish Fish", "Skittles", "Hershey Bar", "Starbursts", "M&Ms"]
for candy in candy_list:
    print(f"[{str(candy_list.index(candy))}] {candy}")
3/39:
# The amount of candy the user will be allowed to choose
allowance = 5
for loop in allowance(5):
    print(loop)
3/40:
# The amount of candy the user will be allowed to choose
allowance = 5
for allowance in range(5):
    print(loop)
3/41:
# The amount of candy the user will be allowed to choose
allowance = 5
for allowance in range(5):
    print(range)
3/42:
# The amount of candy the user will be allowed to choose
allowance = 5
for allowance in range(5):
    print(allowance)
3/43:
# The amount of candy the user will be allowed to choose
allowance = 5

# The list used to store all of the candies selected inside of
candy_cart = []

for i in range(allowance):
    selection = input("Which candy index would you like?")
    
    #Appends(adds) candy at chosen index to candy cart list
    candy_cart.append(candy_list[int{selection}])
3/44:
import re As re
import string As string
3/45:
import re As re
import string As str
3/46:
import re 
import string
3/47: import pandas
3/48:
import pandas as pd
pd.read_csv('comic_books.csv')
3/49: import os
3/50:
import os
import csv
3/51: csvpath = os.path.join('..', 'activities', 'comic_books.csv')
3/52:
import os
import csv
3/53:
# Module for reading CSV files
import csv

#csvpath = os.path.join('..', 'Resources', 'contacts.csv')
comic_books_path = '/Users/Jerry/documents/PythonStuff/activities/comic_books.csv'
# Method 2: Improved Reading using CSV module

with open(comic_books_path) as csvfile:

    # CSV reader specifies delimiter and variable that holds contents
    csvreader = csv.reader(csvfile, delimiter=',')

    print(csvreader)

    # Read the header row first (skip this step if there is now header)
    csv_header = next(csvreader)
    print(f"CSV Header: {csv_header}")

    # Read each row of data after the header
    for row in csvreader:
        print(type(row))
3/54:
# Module for reading CSV files
import csv

#csvpath = os.path.join('..', 'Resources', 'contacts.csv')
comic_books_path = '/Users/Jerry/documents/PythonStuff/activities/comic_books.csv'
# Method 2: Improved Reading using CSV module

with open(comic_books_path) as csvfile:

    # CSV reader specifies delimiter and variable that holds contents
    csvreader = csv.reader(csvfile, delimiter=',')

    print(csvreader)

    # Read the header row first (skip this step if there is now header)
    csv_header = next(csvreader)
    print(f"CSV Header: {csv_header}")

    # Read each row of data after the header
    for row in csvreader:
        print(row)
3/55:
# Module for reading CSV files
import csv

#csvpath = os.path.join('..', 'Resources', 'contacts.csv')
comic_books_path = '/Users/Jerry/documents/PythonStuff/activities/comic_books.csv'
# Method 2: Improved Reading using CSV module

user = input() 
with open(comic_books_path) as csvfile:

    # CSV reader specifies delimiter and variable that holds contents
    csvreader = csv.reader(csvfile, delimiter=',')

    print(csvreader)

    # Read the header row first (skip this step if there is now header)
    csv_header = next(csvreader)
    print(f"CSV Header: {csv_header}")

    # Read each row of data after the header
    for row in csvreader:
        print(row)
3/56:
# Module for reading CSV files
import csv

#csvpath = os.path.join('..', 'Resources', 'contacts.csv')
comic_books_path = '/Users/Jerry/documents/PythonStuff/activities/comic_books.csv'
# Method 2: Improved Reading using CSV module

user = input() 
with open(comic_books_path) as csvfile:

    # CSV reader specifies delimiter and variable that holds contents
    csvreader = csv.reader(csvfile, delimiter=',')

    print(csvreader)

    # Read the header row first (skip this step if there is now header)
    csv_header = next(csvreader)
    print(f"CSV Header: {csv_header}")

    # Read each row of data after the header
    for row in csvreader:
        print(row[0])
3/57:
# Module for reading CSV files
import csv

#csvpath = os.path.join('..', 'Resources', 'contacts.csv')
comic_books_path = '/Users/Jerry/documents/PythonStuff/activities/comic_books.csv'
# Method 2: Improved Reading using CSV module

user = input() 
with open(comic_books_path) as csvfile:

    # CSV reader specifies delimiter and variable that holds contents
    csvreader = csv.reader(csvfile, delimiter=',')

    print(csvreader)

    # Read the header row first (skip this step if there is now header)
    csv_header = next(csvreader)
    print(f"CSV Header: {csv_header}")

    # Read each row of data after the header
    for row in csvreader:
        if row[0] == user:
        print(row[0])
3/58:
# Module for reading CSV files
import csv

#csvpath = os.path.join('..', 'Resources', 'contacts.csv')
comic_books_path = '/Users/Jerry/documents/PythonStuff/activities/comic_books.csv'
# Method 2: Improved Reading using CSV module

user = input() 
with open(comic_books_path) as csvfile:

    # CSV reader specifies delimiter and variable that holds contents
    csvreader = csv.reader(csvfile, delimiter=',')

    print(csvreader)

    # Read the header row first (skip this step if there is now header)
    csv_header = next(csvreader)
    print(f"CSV Header: {csv_header}")

    # Read each row of data after the header
    for row in csvreader:
        if row[0] == user:
            print(row[0])
3/59:
# Module for reading CSV files
import csv

#csvpath = os.path.join('..', 'Resources', 'contacts.csv')
comic_books_path = '/Users/Jerry/documents/PythonStuff/activities/comic_books.csv'
# Method 2: Improved Reading using CSV module

user = input() 
with open(comic_books_path) as csvfile:

    # CSV reader specifies delimiter and variable that holds contents
    csvreader = csv.reader(csvfile, delimiter=',')

    print(csvreader)

    # Read the header row first (skip this step if there is now header)
    csv_header = next(csvreader)
    print(f"CSV Header: {csv_header}")

    # Read each row of data after the header
    for row in csvreader:
        if row[0] == user:
            print(row[0])
3/60:
# Module for reading CSV files
import csv

#csvpath = os.path.join('..', 'Resources', 'contacts.csv')
comic_books_path = '/Users/Jerry/documents/PythonStuff/activities/comic_books.csv'
# Method 2: Improved Reading using CSV module

user = input() 
with open(comic_books_path) as csvfile:

    # CSV reader specifies delimiter and variable that holds contents
    csvreader = csv.reader(csvfile, delimiter=',')

    print(csvreader)

    # Read the header row first (skip this step if there is now header)
    csv_header = next(csvreader)
    print(f"CSV Header: {csv_header}")

    # Read each row of data after the header
    for row in csvreader:
        if row[0] == user:
            print(row)
3/61:
# Module for reading CSV files
import csv

#csvpath = os.path.join('..', 'Resources', 'contacts.csv')
comic_books_path = '/Users/Jerry/documents/PythonStuff/activities/comic_books.csv'
# Method 2: Improved Reading using CSV module

user = input() 
with open(comic_books_path) as csvfile:

    # CSV reader specifies delimiter and variable that holds contents
    csvreader = csv.reader(csvfile, delimiter=',')

    print(csvreader)

    # Read the header row first (skip this step if there is now header)
    csv_header = next(csvreader)
    print(f"CSV Header: {csv_header}")

    # Read each row of data after the header
    for row in csvreader:
        if row[0] == user:
            print(row[0])
3/62:
# Module for reading CSV files
import csv

#csvpath = os.path.join('..', 'Resources', 'contacts.csv')
comic_books_path = '/Users/Jerry/documents/PythonStuff/activities/comic_books.csv'
# Method 2: Improved Reading using CSV module

user = input() 
with open(comic_books_path) as csvfile:

    # CSV reader specifies delimiter and variable that holds contents
    csvreader = csv.reader(csvfile, delimiter=',')

    print(csvreader)

    # Read the header row first (skip this step if there is now header)
    csv_header = next(csvreader)
    print(f"CSV Header: {csv_header}")

    # Read each row of data after the header
    for row in csvreader:
        if row[0] == user:
            print(row)
 4/1: csv_path = os.path.join("Downloads", "cereal.csv")
 4/2:
#import modules
import os
import csv
 4/3: csv_path = os.path.join("Downloads", "cereal.csv")
 4/4: print(csv_path)
 4/5:
# Open the CSV
with open(csv_path, encoding='utf') as csvfile:
    csv_reader = csv.reader(csvfile, delimiter=",")
        next(csv_reader, None)

    # Loop through looking for the video
    for cereal in csv_reader:
        if cereal[7] >= 5
            print(cereal[0] + cereal[7])
 4/6:
# Open the CSV
with open(csv_path, encoding='utf') as csvfile:
    csv_reader = csv.reader(csvfile, delimiter=",")
    next(csv_reader, None)

    # Loop through looking for the video
    for cereal in csv_reader:
        if cereal[7] >= 5
            print(cereal[0] + cereal[7])
 4/7:
# Open the CSV
with open(csv_path, encoding='utf') as csvfile:
    csv_reader = csv.reader(csvfile, delimiter=",")
    next(csv_reader, None)

    # Loop through looking for the video
    for cereal in csv_reader:
        if cereal[7] > 5
            print(cereal[0] + cereal[7])
 4/8:
# Open the CSV
with open(csv_path, encoding='utf') as csvfile:
    csv_reader = csv.reader(csvfile, delimiter=",")
    next(csv_reader, None)

    # Loop through looking for the video
    for cereal in csv_reader:
        if cereal[7] > 5:
            print(cereal[0] + cereal[7])
 4/9: os.getcwd()
4/10:
#import modules
import os
import csv
4/11:
#csv_path = os.path.join("Downloads", "cereal.csv")
csv_path = '/Users/Jerry/Documents/PythonStuff/activities/cereal.csv'
4/12: print(csv_path)
4/13:
# Open the CSV
with open(csv_path) as csvfile:
    csv_reader = csv.reader(csvfile, delimiter=",")
    csv_header = next(csv_reader)

    # Loop through looking for the video
    for cereal in csv_reader:
        if cereal[7] >= 5:
            print(cereal[0] + cereal[7])
4/14:
#csv_path = os.path.join("Downloads", "cereal.csv")
csv_path = '/Users/Jerry/Documents/PythonStuff/activities/cereal.csv'
4/15: print(csv_path)
4/16:
# Open the CSV
with open(csv_path) as csvfile:
    csv_reader = csv.reader(csvfile, delimiter=",")
    csv_header = next(csv_reader)

    # Loop through looking for the video
    for cereal in csv_reader:
        if cereal[7] >= 5:
            print(cereal[0] + cereal[7])
4/17:
# create a dictionary to hold actor's name
actors = {}

# create a dictionary using a built in function
actors = dict()
4/18: type(actors)
4/19: actors = {"name" : "Tom Cruise"}
4/20: print(f"actors{name}")
4/21: print(f"{actors["name"]}")
4/22: print(f'{actors["name"]}')
4/23:
hobbies{}
hobby_list = (running, climbing, gyming, basketball)
print(hobby_list)
4/24:
hobbies{}
hobby_list = (running, climbing, gyming, basketball)
print("hobby_list")
4/25:
hobbies{}
hobby_list = ("running", "climbing", "gyming", "basketball")
print("hobby_list")
4/26:
hobbies{}

hobbies{"name": "Jerry",
       "age": "23"
        "hobbies": ["climbing", "gyming"]
       }
print("hobbies")
4/27:
hobbies{}

hobbies = {"name": "Jerry",
            "age": "23"
            "hobbies": ["climbing", "gyming"]
           }
print(hobbies)
4/28:
hobbies{}
hobbies = dict{}

hobbies = {"name": "Jerry",
            "age": "23"
            "hobbies": ["climbing", "gyming"]
           }
print(hobbies)
4/29:

hobbies = dict{}

hobbies = {"name": "Jerry",
            "age": "23"
            "hobbies": ["climbing", "gyming"]
           }
print(hobbies)
4/30:

hobbies = dict{}

hobbies = {"name": "Jerry",
            "age": "23"
            "hobbies": ["climbing", "gyming"]
           }
print(hobbies)
4/31: hobbies = {}
4/32:
hobbies = {"name": "Jerry",
            "age": "23"
            "hobbies": ["climbing", "gyming"]
           }
print(hobbies)
4/33:
hobbies = {"name": "Jerry",
            "age": "23"
            "hobbies": ["climbing", "gyming"]
           }
print(f'{hobbies["name"]}')
4/34:
hobbies = {"name": "Jerry",
            "age": "23"}
print(f'{hobbies["name"]}')
4/35:
#Workspace
names = []
for names in range(5):
    name = input("Please enter the name of someone you know. ")
    names.append(name)
4/36:
#Workspace
names = []
for _ in range(5):
    name = input("Please enter the name of someone you know. ")
    names.append(name)
 5/1: print(square)
 5/2: print(square(2))
 5/3: print(square(2))
 5/4: age = [23, 18, 36, 42, 27, 74]
 5/5:
age = [23, 18, 36, 42, 27, 74]
    print(sum(age))
 5/6:
age = [23, 18, 36, 42, 27, 74]
print(sum(age))
 5/7:
# @TODO: Write a function that returns the arithmetic average for a list of numbers
age = [23, 18, 36, 42, 27, 74]
def mean(age)
print(mean(age))
    

# Test your function with the following:
# print(average([1, 5, 9]))
# print(average(range(11)))
 5/8:
# @TODO: Write a function that returns the arithmetic average for a list of numbers
age = [23, 18, 36, 42, 27, 74]
print(mean(age))
    

# Test your function with the following:
# print(average([1, 5, 9]))
# print(average(range(11)))
 5/9:
# @TODO: Write a function that returns the arithmetic average for a list of numbers
age = [23, 18, 36, 42, 27, 74]
print(average(age))
    

# Test your function with the following:
# print(average([1, 5, 9]))
# print(average(range(11)))
5/10: print(count(age))
5/11:
# @TODO: Write a function that returns the arithmetic average for a list of numbers
age = [23, 18, 36, 42, 27, 74]
def mean(age)
    returen (sum(age))/4
    

# Test your function with the following:
# print(average([1, 5, 9]))
# print(average(range(11)))
5/12:
# @TODO: Write a function that returns the arithmetic average for a list of numbers
age = [23, 18, 36, 42, 27, 74]
def mean(age):
    returen (sum(age))/4
    

# Test your function with the following:
# print(average([1, 5, 9]))
# print(average(range(11)))
5/13:
# @TODO: Write a function that returns the arithmetic average for a list of numbers
age = [23, 18, 36, 42, 27, 74]
def mean(age):
    returen (sum(age))/4
    

# Test your function with the following:
# print(average([1, 5, 9]))
# print(average(range(11)))
5/14:
# @TODO: Write a function that returns the arithmetic average for a list of numbers
age = []
def mean(age):
    print(mean([1, 5, 9]))
    
    

# Test your function with the following:
# print(average([1, 5, 9]))
# print(average(range(11)))
5/15: length = len(numbers)
5/16:
length = len(numbers)
numbers = jerry
5/17:
numbers = "jerry"
length = len(numbers)
5/18:
numbers = "jerry"
length = len(numbers)
print(length)
5/19:
numbers = jerry
length = len(numbers)
print(length)
5/20:
numbers = 5
length = len(numbers)
print(length)
5/21: type(number)
5/22: type(numbers)
5/23:
numbers = (5, 15)
length = len(numbers)
print(length)
5/24:
# @TODO: Write a function that returns the arithmetic average for a list of numbers
def average(numbers):
    length = len(numbers)
    total = 0.0
    for number in numbers:
        total += number
    return total / length
    

# Test your function with the following:
# print(average([1, 5, 9]))
# print(average(range(11)))
5/25: print(average([1, 5, 9]))
5/26: print(average(range(11)))
5/27:
def average(numbers)
    return sum(numbers)/ len(numbers)
5/28:
def average (numbers):
    return sum(numbers)/ len(numbers)
5/29:
def average (numbers):
    return sum(numbers)/ len(numbers)
5/30:
movies = ("Iron Man", "Harry Potter", "Avengers")
print(movies)
 7/1: name = "Jerry"
 7/2: country =
 7/3: country = "USA"
 7/4:
age = 24
hourly_wage = 36
 7/5: output(age)
 7/6: print(age)
 7/7: print(name, age)
 7/8: print(name, "is", age, "years old")
 7/9: name = ("Jerry", "Vanessa", "Bella")
7/10: print = name(1)
7/11: print = (name[1])
7/12: print = (name[1])
7/13: print = (name(1))
7/14: print = (name[1)]
7/15: satisfied = True
7/16: print = (satisfied)
7/17: daily_wage = (hourly_wage) * 8
7/18: print(daily_wage)
7/19: daily_wage = (hourly_wage)8
7/20: daily_wage = (hourly_wage)*8
7/21: print(daily_wage)
7/22:
hourly_wage = 36
print(daily_wage = (hourly_wage)*8)
7/23: print(name + country + age + hourly_wage)
7/24: print(name + country + str(age) + hourly_wage)
7/25: print("name" + "country" + str(age) + "hourly_wage")
7/26: type (name)
7/27: str(name) = "Jerry"
7/28: print(f"{name} is {age})
7/29: print(f"{name} "is" {age})
7/30:
hourly_wage = 36
daily_wage = hourly_wage * 8
7/31: print(daily_wage)
7/32:
hourly_wage = 36
daily_wage = hourly_wage * 8
7/33: print("Hello" + name + "!")
7/34: name = "Jerry"
7/35: print(name = "Jerry")
 8/1: name = "Jerry"
 8/2: age = 24
 8/3: country = "USA"
 8/4: hourly_wage = 25
 8/5: daily_wage = (hourly_wage) * 8
 8/6: satisfied = True
 8/7: print("Hello" name "!")
 8/8: print("Hello" + name + "!")
 8/9: print("Hello " + name + "!")
8/10: print(daily_wage)
8/11: print(name + country + age + hourly_wage)
8/12: print(name + country + str(age) + hourly_wage)
8/13: print(name + country + str(age) + str(hourly_wage))
8/14: print(f"{name} is {age} years old")
8/15: print(f"You make {daily_wage} per day")
8/16: print(f"Are you satisfied with your current wage? {satisfied}")
8/17: #DownToInput Activity
8/18: input("what is your first name?")
8/19: input("what is your nieghbors name?")
8/20: firstname = input("what is your first name?")
8/21: neighbor = input("what is your nieghbors name?")
8/22: ncoding = input("how long has " neighbor " coding?" )
8/23: ncoding = input("how long has " neighbor " coding?")
8/24: ncoding = input("how long has the neighbor coding?")
8/25: jcoding = input("how long has jerry been coding?")
8/26: ncoding = input("how long has the neighbor coding?")
8/27: print(f"{firstname} and {neighbor} have been coding for {jcoding} and {ncoding} respectively.)
8/28: total_months_coded = ncoding + jcoding
8/29: total_months_coded = int(ncoding) + int(jcoding)
8/30: print(f"{firstname} and {neighbor} have coded a total of {total_months_coded}")
8/31: print(f"{firstname} and {neighbor} have coded a total of {total_months_coded} months")
 9/1:
import os
import csv
 9/2: import pandas as pd
 9/3:
import pandas as pd
import os
import csv
 9/4: csv_imported = "/Users/Jerry/Downloads/comic_books.csv"
 9/5:
with open(csv_imported, encoding = 'utf') as comicfilecsv:
    csvreader = csv.read(comicfilecsv, delimiter = ",")
 9/6: csv_imported = "/Users/Jerry/Downloads/comic_books.csv"
 9/7:
with open(csv_imported, encoding = 'utf') as comicfilecsv:
    csvreader = csv.read(comicfilecsv, delimiter = ",")
 9/8:
with open(csv_imported, encoding = 'utf') as comicfilecsv:
    csvreader = csv.reader(comicfilecsv, delimiter = ",")
 9/9: found = False
9/10: #new activity
9/11: import pandas as pd
9/12: df = pd.read_csv(csv_imported)
9/13: #dataframeshop activity
9/14:
#Import dependencies
Frame = ("Ornate", "Classical", "Modern", "Wood", "Cardboard")
Price = (15.0, 12.5, 10.0, 5.0, 1.0)
Sales = (100, 200, 150, 300, "N/A")
9/15: print(sales(4))
9/16: print(Sales(4))
9/17: print(Sales(0))
9/18: print(Sales[0])
9/19: print(Sales[4])
9/20:
frameshop_df = pd.DataFrame(
    {"Frame": ["Ornate", "Classical", "Modern", "Wood", "Cardboard"]},
    "Price": [15.0, 12.5, 10.0, 5.0, 1.0],
    "Sales": [100, 200, 150, 300, "N/A"]
    }   
)
9/21:
data ={"Frame": ["Ornate", "Classical", "Modern", "Wood", "Cardboard"]},
    "Price": [15.0, 12.5, 10.0, 5.0, 1.0],
    "Sales": [100, 200, 150, 300, "N/A"]
    }
9/22: data ={"Frame": ["Ornate", "Classical", "Modern", "Wood", "Cardboard"]},"Price": [15.0, 12.5, 10.0, 5.0, 1.0],"Sales": [100, 200, 150, 300, "N/A"]}
9/23:
data = {
    "Frame": ["Ornate", "Classical", "Modern", "Wood", "Cardboard"],
    "Price": [15.0, 12.5, 10.0, 5.0, 1.0],
    "Sales": [100, 200, 150, 300, "N/A"]}
9/24: frameshop_df = pd.DataFrame(data)
9/25: print(frameshop_df)
9/26:
frameshop_df = pd.DataFrame(
    "Frame": ["Ornate", "Classical", "Modern", "Wood", "Cardboard"],
    "Price": [15.0, 12.5, 10.0, 5.0, 1.0],
    "Sales": [100, 200, 150, 300, "N/A"]}
)
9/27:
frameshop_df = pd.DataFrame("Frame": ["Ornate", "Classical", "Modern", "Wood", "Cardboard"],
                            "Price": [15.0, 12.5, 10.0, 5.0, 1.0],
                            "Sales": [100, 200, 150, 300, "N/A"]}
)
9/28:
frameshop_df = pd.DataFrame({"Frame": ["Ornate", "Classical", "Modern", "Wood", "Cardboard"],
                            "Price": [15.0, 12.5, 10.0, 5.0, 1.0],
                            "Sales": [100, 200, 150, 300, "N/A"]}
)
9/29:
frameshop_df = pd.DataFrame({"Frame": ["Ornate", "Classical", "Modern", "Wood", "Cardboard"],
                        "Price": [15.0, 12.5, 10.0, 5.0, 1.0],
                        "Sales": [100, 200, 150, 300, "N/A"]}
)
9/30:
frameshop_df = pd.DataFrame({"Frame": ["Ornate", "Classical", "Modern", "Wood", "Cardboard"],
    "Price": [15.0, 12.5, 10.0, 5.0, 1.0],
    "Sales": [100, 200, 150, 300, "N/A"]}
)
9/31:
# Convert a list of dictionaries into a dataframe
states_dicts = [{"STATE": "New Jersey", "ABBREVIATION": "NJ"},
                {"STATE": "New York", "ABBREVIATION": "NY"}]

states_df = pd.DataFrame(states_dicts)
states_df
9/32:
# We can create a Pandas Series from a raw list
data_series = pd.Series(["UCLA", "UC Berkeley", "UC Irvine",
                         "University of Central Florida", "Rutgers University"])
data_series
9/33: #Trainging Grounds Activity
9/34: #Resources given for activity
9/35: #Instructions: Provide a simple analytical overview of the dataset's numeric columns.
9/36:
# A gigantic DataFrame of individuals' names, their trainers, their weight, and their days as gym members
training_df = pd.DataFrame({
    "Name":["Gino Walker","Hiedi Wasser","Kerrie Wetzel","Elizabeth Sackett","Jack Mitten","Madalene Wayman","Jamee Horvath","Arlena Reddin","Tula Levan","Teisha Dreier","Leslie Carrier","Arlette Hartson","Romana Merkle","Heath Viviani","Andres Zimmer","Allyson Osman","Yadira Caggiano","Jeanmarie Friedrichs","Leann Ussery","Bee Mom","Pandora Charland","Karena Wooten","Elizabet Albanese","Augusta Borjas","Erma Yadon","Belia Lenser","Karmen Sancho","Edison Mannion","Sonja Hornsby","Morgan Frei","Florencio Murphy","Christoper Hertel","Thalia Stepney","Tarah Argento","Nicol Canfield","Pok Moretti","Barbera Stallings","Muoi Kelso","Cicely Ritz","Sid Demelo","Eura Langan","Vanita An","Frieda Fuhr","Ernest Fitzhenry","Ashlyn Tash","Melodi Mclendon","Rochell Leblanc","Jacqui Reasons","Freeda Mccroy","Vanna Runk","Florinda Milot","Cierra Lecompte","Nancey Kysar","Latasha Dalton","Charlyn Rinaldi","Erline Averett","Mariko Hillary","Rosalyn Trigg","Sherwood Brauer","Hortencia Olesen","Delana Kohut","Geoffrey Mcdade","Iona Delancey","Donnie Read","Cesar Bhatia","Evia Slate","Kaye Hugo","Denise Vento","Lang Kittle","Sherry Whittenberg","Jodi Bracero","Tamera Linneman","Katheryn Koelling","Tonia Shorty","Misha Baxley","Lisbeth Goering","Merle Ladwig","Tammie Omar","Jesusa Avilla","Alda Zabala","Junita Dogan","Jessia Anglin","Peggie Scranton","Dania Clodfelter","Janis Mccarthy","Edmund Galusha","Tonisha Posey","Arvilla Medley","Briana Barbour","Delfina Kiger","Nia Lenig","Ricarda Bulow","Odell Carson","Nydia Clonts","Andree Resendez","Daniela Puma","Sherill Paavola","Gilbert Bloomquist","Shanon Mach","Justin Bangert","Arden Hokanson","Evelyne Bridge","Hee Simek","Ward Deangelis","Jodie Childs","Janis Boehme","Beaulah Glowacki","Denver Stoneham","Tarra Vinton","Deborah Hummell","Ulysses Neil","Kathryn Marques","Rosanna Dake","Gavin Wheat","Tameka Stoke","Janella Clear","Kaye Ciriaco","Suk Bloxham","Gracia Whaley","Philomena Hemingway","Claudette Vaillancourt","Olevia Piche","Trey Chiles","Idalia Scardina","Jenine Tremble","Herbert Krider","Alycia Schrock","Miss Weibel","Pearlene Neidert","Kina Callender","Charlotte Skelley","Theodora Harrigan","Sydney Shreffler","Annamae Trinidad","Tobi Mumme","Rosia Elliot","Debbra Putt","Rena Delosantos","Genna Grennan","Nieves Huf","Berry Lugo","Ayana Verdugo","Joaquin Mazzei","Doris Harmon","Patience Poss","Magaret Zabel","Marylynn Hinojos","Earlene Marcantel","Yuki Evensen","Rema Gay","Delana Haak","Patricia Fetters","Vinnie Elrod","Octavia Bellew","Burma Revard","Lakenya Kato","Vinita Buchner","Sierra Margulies","Shae Funderburg","Jenae Groleau","Louetta Howie","Astrid Duffer","Caron Altizer","Kymberly Amavisca","Mohammad Diedrich","Thora Wrinkle","Bethel Wiemann","Patria Millet","Eldridge Burbach","Alyson Eddie","Zula Hanna","Devin Goodwin","Felipa Kirkwood","Kurtis Kempf","Kasey Lenart","Deena Blankenship","Kandra Wargo","Sherrie Cieslak","Ron Atha","Reggie Barreiro","Daria Saulter","Tandra Eastman","Donnell Lucious","Talisha Rosner","Emiko Bergh","Terresa Launius","Margy Hoobler","Marylou Stelling","Lavonne Justice","Kala Langstaff","China Truett","Louanne Dussault","Thomasena Samaniego","Charlesetta Tarbell","Fatimah Lade","Malisa Cantero","Florencia Litten","Francina Fraise","Patsy London","Deloris Mclaughlin"],
    "Trainer":['Bettyann Savory','Mariah Barberio','Gordon Perrine','Pa Dargan','Blanch Victoria','Aldo Byler','Aldo Byler','Williams Camire','Junie Ritenour','Gordon Perrine','Bettyann Savory','Mariah Barberio','Aldo Byler','Barton Stecklein','Bettyann Savory','Barton Stecklein','Gordon Perrine','Pa Dargan','Aldo Byler','Brittani Brin','Bettyann Savory','Phyliss Houk','Bettyann Savory','Junie Ritenour','Aldo Byler','Calvin North','Brittani Brin','Junie Ritenour','Blanch Victoria','Brittani Brin','Bettyann Savory','Blanch Victoria','Mariah Barberio','Bettyann Savory','Blanch Victoria','Brittani Brin','Junie Ritenour','Pa Dargan','Gordon Perrine','Phyliss Houk','Pa Dargan','Mariah Barberio','Phyliss Houk','Phyliss Houk','Calvin North','Williams Camire','Brittani Brin','Gordon Perrine','Bettyann Savory','Bettyann Savory','Pa Dargan','Phyliss Houk','Barton Stecklein','Blanch Victoria','Coleman Dunmire','Phyliss Houk','Blanch Victoria','Pa Dargan','Harland Coolidge','Calvin North','Bettyann Savory','Phyliss Houk','Bettyann Savory','Harland Coolidge','Gordon Perrine','Junie Ritenour','Harland Coolidge','Blanch Victoria','Mariah Barberio','Coleman Dunmire','Aldo Byler','Bettyann Savory','Gordon Perrine','Bettyann Savory','Barton Stecklein','Harland Coolidge','Aldo Byler','Aldo Byler','Pa Dargan','Junie Ritenour','Brittani Brin','Junie Ritenour','Gordon Perrine','Mariah Barberio','Mariah Barberio','Mariah Barberio','Bettyann Savory','Brittani Brin','Aldo Byler','Phyliss Houk','Blanch Victoria','Pa Dargan','Phyliss Houk','Brittani Brin','Barton Stecklein','Coleman Dunmire','Bettyann Savory','Bettyann Savory','Gordon Perrine','Blanch Victoria','Junie Ritenour','Phyliss Houk','Coleman Dunmire','Williams Camire','Harland Coolidge','Williams Camire','Aldo Byler','Harland Coolidge','Gordon Perrine','Brittani Brin','Coleman Dunmire','Calvin North','Phyliss Houk','Brittani Brin','Aldo Byler','Bettyann Savory','Brittani Brin','Gordon Perrine','Calvin North','Harland Coolidge','Coleman Dunmire','Harland Coolidge','Aldo Byler','Junie Ritenour','Blanch Victoria','Harland Coolidge','Blanch Victoria','Junie Ritenour','Harland Coolidge','Junie Ritenour','Gordon Perrine','Brittani Brin','Coleman Dunmire','Williams Camire','Junie Ritenour','Brittani Brin','Calvin North','Barton Stecklein','Barton Stecklein','Mariah Barberio','Coleman Dunmire','Bettyann Savory','Mariah Barberio','Pa Dargan','Barton Stecklein','Coleman Dunmire','Brittani Brin','Barton Stecklein','Pa Dargan','Barton Stecklein','Junie Ritenour','Bettyann Savory','Williams Camire','Pa Dargan','Calvin North','Williams Camire','Coleman Dunmire','Aldo Byler','Barton Stecklein','Coleman Dunmire','Blanch Victoria','Mariah Barberio','Mariah Barberio','Harland Coolidge','Barton Stecklein','Phyliss Houk','Pa Dargan','Bettyann Savory','Barton Stecklein','Harland Coolidge','Junie Ritenour','Pa Dargan','Mariah Barberio','Blanch Victoria','Williams Camire','Phyliss Houk','Phyliss Houk','Coleman Dunmire','Mariah Barberio','Gordon Perrine','Coleman Dunmire','Brittani Brin','Pa Dargan','Coleman Dunmire','Brittani Brin','Blanch Victoria','Coleman Dunmire','Gordon Perrine','Coleman Dunmire','Aldo Byler','Aldo Byler','Mariah Barberio','Williams Camire','Phyliss Houk','Aldo Byler','Williams Camire','Aldo Byler','Williams Camire','Coleman Dunmire','Phyliss Houk'],
    "Weight":[128,180,193,177,237,166,224,208,177,241,114,161,162,151,220,142,193,193,124,130,132,141,190,239,213,131,172,127,184,157,215,122,181,240,218,205,239,217,234,158,180,131,194,171,177,110,117,114,217,123,248,189,198,127,182,121,224,111,151,170,188,150,137,231,222,186,139,175,178,246,150,154,129,216,144,198,228,183,173,129,157,199,186,232,172,157,246,239,214,161,132,208,187,224,164,177,175,224,219,235,112,241,243,179,208,196,131,207,182,233,191,162,173,197,190,182,231,196,196,143,250,174,138,135,164,204,235,192,114,179,215,127,185,213,250,213,153,217,176,190,119,167,118,208,113,206,200,236,159,218,168,159,156,183,121,203,215,209,179,219,174,220,129,188,217,250,166,157,112,236,182,144,189,243,238,147,165,115,160,134,245,174,238,157,150,184,174,134,134,248,199,165,117,119,162,112,170,224,247,217],
    "Membership(Days)":[52,70,148,124,186,157,127,155,37,185,158,129,93,69,124,13,76,153,164,161,48,121,167,69,39,163,7,34,176,169,108,162,195,86,155,77,197,200,80,142,179,67,58,145,188,147,125,15,13,173,125,4,61,29,132,110,62,137,197,135,162,174,32,151,149,65,18,42,63,62,104,200,189,40,38,199,1,12,8,2,195,30,7,72,130,144,2,34,200,143,43,196,22,115,171,54,143,59,14,52,109,115,187,185,26,19,178,18,120,169,45,52,130,69,168,178,96,22,78,152,39,51,118,130,60,156,108,69,103,158,165,142,86,91,117,77,57,169,86,188,97,111,22,83,81,177,163,35,12,164,21,181,171,138,22,107,58,51,38,128,19,193,157,13,104,89,13,10,26,190,179,101,7,159,100,49,120,109,56,199,51,108,47,171,69,162,74,119,148,88,32,159,65,146,140,171,88,18,59,13]
})
training_df.head(10)
9/37: training_df.describe()
9/38: training_df.unique(Trainer)
9/39: training_df.["Trainer"]unique()
9/40: training_df["Trainer"].unique()
9/41: trainers = training_df["Trainer"].unique()
9/42:
trainers = training_df["Trainer"].unique()
print(trainers)
9/43: count = training_df["Trainer"].value_counts()
9/44: training_df["Trainer"].value_counts()
9/45: student_count = training_df["Trainer"].value_counts()
9/46:
student_count = training_df["Trainer"].value_counts()
print(student_count)
9/47: # Finding the average weight of all students
9/48:
# Finding the average weight of all students
training_df["Weight"].mean()
9/49:
# Finding the average weight of all students
training_df["Weight"].mean()
9/50:
 # Finding the combined weight of all students
training_df["Weight"].total()
9/51:
 # Finding the combined weight of all students
training_df["Weight"].sum()
9/52:
 # Converting the membership days into weeks and then adding a column to the DataFrame
weeks = training_df["membership_days"]/7
training_df["weeks"] = weeks
training_df.head()
9/53:
 # Converting the membership days into weeks and then adding a column to the DataFrame
weeks = training_df["Membership(Days)"]/7
training_df["weeks"] = weeks
training_df.head()
9/54:
Arnold_df = {“Character_in_show”: ["Arnold", "Gerald", "Helga", "Phoebe", "Harold", "Eugene"],
            “color_of_hair”: ["blonde", "black", "blonde", "black", "unknown", "red"],
            “Height”: ["average", "tallish", "tallish", "short", "tall", "short"],
            “Football_Shaped_Head”: ["True", "False", "False", "False", "False", "False"]    
            }
9/55:
Arnold_df = {“Character_in_show”: ["Arnold", "Gerald", "Helga", "Phoebe", "Harold", "Eugene"],
            “color_of_hair”: ["blonde", "black", "blonde", "black", "unknown", "red"],
            “Height”: ["average", "tallish", "tallish", "short", "tall", "short"],
            “Football_Shaped_Head”: ["True", "False", "False", "False", "False", "False"]    
            }
9/56:
Arnold_df = {
    “Character_in_show”: ["Arnold", "Gerald", "Helga", "Phoebe", "Harold", "Eugene"],
    “color_of_hair”: ["blonde", "black", "blonde", "black", "unknown", "red"],
    “Height”: ["average", "tallish", "tallish", "short", "tall", "short"],
    “Football_Shaped_Head”: ["True", "False", "False", "False", "False", "False"]    
            }
9/57:
Arnold_df = {
    “Character_in_show”: ["Arnold", "Gerald", "Helga", "Phoebe", "Harold", "Eugene"],
    “color_of_hair”: ["blonde", "black", "blonde", "black", "unknown", "red"],
    “Height”: ["average", "tallish", "tallish", "short", "tall", "short"],
    “Football_Shaped_Head”: ["True", "False", "False", "False", "False", "False"]    
            }
9/58:
Arnold_df = {
    "Character_in_show": ["Arnold", "Gerald", "Helga", "Phoebe", "Harold", "Eugene"],
    "color_of_hair": ["blonde", "black", "blonde", "black", "unknown", "red"],
    "Height": ["average", "tallish", "tallish", "short", "tall", "short"],
    "Football_Shaped_Head": ["True", "False", "False", "False", "False", "False"]    
            }
9/59:
Arnold_df = {
    "Character_in_show": ["Arnold", "Gerald", "Helga", "Phoebe", "Harold", "Eugene"],
    "color_of_hair": ["blonde", "black", "blonde", "black", "unknown", "red"],
    "Height": ["average", "tallish", "tallish", "short", "tall", "short"],
    "Football_Shaped_Head": ["True", "False", "False", "False", "False", "False"]    
            }
print(Arnold_df)
9/60:
list = {
    "Character_in_show": ["Arnold", "Gerald", "Helga", "Phoebe", "Harold", "Eugene"],
    "color_of_hair": ["blonde", "black", "blonde", "black", "unknown", "red"],
    "Height": ["average", "tallish", "tallish", "short", "tall", "short"],
    "Football_Shaped_Head": ["True", "False", "False", "False", "False", "False"]    
            }
arnold_df = pd.DataFrame(list)
9/61:
list = {
    "Character_in_show": ["Arnold", "Gerald", "Helga", "Phoebe", "Harold", "Eugene"],
    "color_of_hair": ["blonde", "black", "blonde", "black", "unknown", "red"],
    "Height": ["average", "tallish", "tallish", "short", "tall", "short"],
    "Football_Shaped_Head": ["True", "False", "False", "False", "False", "False"]    
            }
arnold_df = pd.DataFrame(list)
print(arnold_df)
9/62: arnold_df.rename(columns={"Character_in_show":"Character", "color_of_hair" : "color", "Football_Shaped_Head" : "Football Head"})
9/63: arnold_df[["Character", "Height", "color", "Football Head"]]
9/64: organized_df = arnold_df[["Character", "Height", "color", "Football Head"]]
9/65:
organized_df = arnold_df[["Character", "Height", "color", "Football Head"]]
organized_df.Head()
9/66: renamed_df = arnold_df.rename(columns={"Character_in_show":"Character", "color_of_hair" : "color", "Football_Shaped_Head" : "Football Head"})
9/67:
organized_df = renamed_df[["Character", "Height", "color", "Football Head"]]
organized_df.Head()
9/68:
organized_df = renamed_df[["Character", "Height", "color", "Football Head"]]
organized_df.head()
9/69:
renamed_df = arnold_df.rename(columns={"Character_in_show":"Character", 
                                       "color_of_hair" : "color", 
                                       "Football_Shaped_Head" : "Football Head"}, inplace = True)
9/70:
organized_df = renamed_df[["Character", "Height", "color", "Football Head"]]
organized_df.head()
9/71:
organized_df = renamed_df[["Character", "Height", "color", "Football Head"]]
organized_df.head()
9/72:
arnold_df.rename(columns={"Character_in_show":"Character", 
                                       "color_of_hair" : "color", 
                                       "Football_Shaped_Head" : "Football Head"}, inplace = True)
9/73: organized_df = arnold_df[["Character", "Height", "color", "Football Head"]]
10/1: #Conditional Conundrum
10/2:
# Incorporate the random library
import random

# Print Title
print("Let's Play Rock Paper Scissors!")

# Specify the three options
options = ["r", "p", "s"]

# Computer Selection
computer_choice = random.choice(options)

# User Selection
user_choice = input("Make your Choice: (r)ock, (p)aper, (s)cissors? ")

# Run Conditionals
if user_choice = r and computer_choice = r:
    print("Draw!")
elif user_choice = r and computer_choice = p:
    print("Computer wins!")
elif user_choice = r and computer_choice = s:
    print()
10/3:
# Incorporate the random library
import random

# Print Title
print("Let's Play Rock Paper Scissors!")

# Specify the three options
options = ["r", "p", "s"]

# Computer Selection
computer_choice = random.choice(options)

# User Selection
user_choice = input("Make your Choice: (r)ock, (p)aper, (s)cissors? ")

# Run Conditionals
if (user_choice == "r" and computer_choice == "r"):
    print("Draw!")
elif (user_choice == "r" and computer_choice == "p"):
    print("Computer wins!")
elif (user_choice == "r" and computer_choice == "s"):
    print("User wins!")
elif (user_choice == "p" and computer_choice == "r"):
    print("User Wins!")
elif (user_choice == "p" and computer_choice == "p"):
    print("Draw!")
elif (user_choice == "p" and computer_choice == "s"):
    print("Computer wins!")
elif (user_choice == "s" and computer_choice == "r"):
    print("Computer wins!")
elif (user_choice == "s" and computer_choice == "p"):
    print("User Wins!")
elif (user_choice == "s" and computer_choice == "s"):
    print("Draw!")
else:
    print("Next time, choose from 'r', 'p', 's'.")
10/4:
# Incorporate the random library
import random

# Print Title
print("Let's Play Rock Paper Scissors!")

# Specify the three options
options = ["r", "p", "s"]

# Computer Selection
computer_choice = random.choice(options)

# User Selection
user_choice = input("Make your Choice: (r)ock, (p)aper, (s)cissors? ")

# Run Conditionals
if (user_choice == "r" and computer_choice == "r"):
    print("Draw!")
elif (user_choice == "r" and computer_choice == "p"):
    print("Computer wins!")
elif (user_choice == "r" and computer_choice == "s"):
    print("User wins!")
elif (user_choice == "p" and computer_choice == "r"):
    print("User Wins!")
elif (user_choice == "p" and computer_choice == "p"):
    print("Draw!")
elif (user_choice == "p" and computer_choice == "s"):
    print("Computer wins!")
elif (user_choice == "s" and computer_choice == "r"):
    print("Computer wins!")
elif (user_choice == "s" and computer_choice == "p"):
    print("User Wins!")
elif (user_choice == "s" and computer_choice == "s"):
    print("Draw!")
else:
    print("Next time, choose from 'r', 'p', 's'.")
10/5:
# Incorporate the random library
import random

# Print Title
print("Let's Play Rock Paper Scissors!")

# Specify the three options
options = ["r", "p", "s"]

# Computer Selection
computer_choice = random.choice(options)

# User Selection
user_choice = input("Make your Choice: (r)ock, (p)aper, (s)cissors? ")

# Run Conditionals
if (user_choice == "r" and computer_choice == "r"):
    print("Draw!")
elif (user_choice == "r" and computer_choice == "p"):
    print("Computer wins!")
elif (user_choice == "r" and computer_choice == "s"):
    print("User wins!")
elif (user_choice == "p" and computer_choice == "r"):
    print("User Wins!")
elif (user_choice == "p" and computer_choice == "p"):
    print("Draw!")
elif (user_choice == "p" and computer_choice == "s"):
    print("Computer wins!")
elif (user_choice == "s" and computer_choice == "r"):
    print("Computer wins!")
elif (user_choice == "s" and computer_choice == "p"):
    print("User Wins!")
elif (user_choice == "s" and computer_choice == "s"):
    print("Draw!")
else:
    print("Next time, choose from 'r', 'p', 's'.")
10/6:
# Incorporate the random library
import random

# Print Title
print("Let's Play Rock Paper Scissors!")

# Specify the three options
options = ["r", "p", "s"]

# Computer Selection
computer_choice = random.choice(options)

# User Selection
user_choice = input("Make your Choice: (r)ock, (p)aper, (s)cissors? ")

# Run Conditionals
if (user_choice == "r" and computer_choice == "r"):
    print("Draw!")
elif (user_choice == "r" and computer_choice == "p"):
    print("Computer wins!")
elif (user_choice == "r" and computer_choice == "s"):
    print("User wins!")
elif (user_choice == "p" and computer_choice == "r"):
    print("User Wins!")
elif (user_choice == "p" and computer_choice == "p"):
    print("Draw!")
elif (user_choice == "p" and computer_choice == "s"):
    print("Computer wins!")
elif (user_choice == "s" and computer_choice == "r"):
    print("Computer wins!")
elif (user_choice == "s" and computer_choice == "p"):
    print("User Wins!")
elif (user_choice == "s" and computer_choice == "s"):
    print("Draw!")
else:
    print("Next time, choose from 'r', 'p', 's'.")
10/7: #Number Chain
10/8:
#use a while loop 
input("How many numbers?")
10/9:
#inital variable to track game
user_play == "y"

#while we are still playing
while user_play == "y":
    
    #ask the user how many numbers to loop through
    user_number = input("How many numbers should be looped through?")
10/10:
#inital variable to track game
user_play == "y"

#while we are still playing
while user_play == "y":
    
    #ask the user how many numbers to loop through
    user_number = int(input("How many numbers should be looped through?"))
    
    #loop through the number
    for number in range(user_number):
        
        # Print each number in the range
        print(number)
        
    #once complete
    user_play = input("Continue: (y) or (n)")
10/11:
#inital variable to track game
user_play = "y"

#while we are still playing
while user_play == "y":
    
    #ask the user how many numbers to loop through
    user_number = int(input("How many numbers should be looped through?"))
    
    #loop through the number
    for number in range(user_number):
        
        # Print each number in the range
        print(number)
        
    #once complete
    user_play = input("Continue: (y)es or (n)o ?")
10/12:
# Initial variable to track game play
user_play = "y"

# Set start and last number
start_number = 0

# While we are still playing...
while user_play == "y":

    # Ask the user how many numbers to loop through
    user_number = input("How many numbers? ")

    # Loop through the numbers. (Be sure to cast the string into an integer.)
    for x in range(start_number, int(user_number) + start_number):

        # Print each number in the range
        print(x)

    # Set the next start number as the last number of the loop
    start_number = start_number + int(user_number)

    # Once complete...
    user_play = input("Continue the chain: (y)es or (n)o? ")
11/1:
#PyPoll
#You are tasked with helping a small, rural town modernize its vote counting process.
11/2:
#import relevant modules
import pandas as pd

#import csv file
pypoll_df = pd.csv_read("/Users/Jerry/Documents/Homework/python-challenge/election_data.csv")
11/3:
#import relevant modules
import pandas as pd

#import csv file
pypoll_df = pd.csvread(r"/Users/Jerry/Documents/Homework/python-challenge/election_data.csv")
11/4:
#import relevant modules
import pandas as pd
11/5:
#import relevant modules
import pandas as pd

#import csv file
pypoll_df = pd.csvread("/Users/Jerry/Documents/Homework/python-challenge/election_data.csv")
11/6:
#import relevant modules
import pandas as pd

#import csv file
pypoll_df = pd.csvread(r"/Users/Jerry/Documents/Homework/python-challenge/election_data.csv")
11/7:
#import relevant modules
import pandas as pd

#import csv file
pypoll_df = pd.csv_read("/Users/Jerry/Documents/Homework/python-challenge/election_data.csv")
11/8:
#import relevant modules
import pandas as pd

#import csv file
pypoll_df = pd.read_csv("/Users/Jerry/Documents/Homework/python-challenge/election_data.csv")
11/9:
#summarize the top and the bottom of the csv file
head(pypoll_df)
11/10:
#summarize the top and the bottom of the csv file
pypoll_df.head()
11/11: pypoll_df.tail()
11/12: pypoll_df.columns()
11/13: pypoll_df.columns
11/14:
#The total number of votes cast
total_votes = pypoll_df["Ballot ID"].values_count()
11/15:
#The total number of votes cast
total_votes = len(pypoll_df["Ballot ID"].unique())
11/16:
#The total number of votes cast
total_votes = len(pypoll_df["Ballot ID"].unique())
print(f"Total Number of Votes Cast: {total_votes}")
11/17:
#The total number of votes cast
total_votes = len(pypoll_df["Ballot ID"].unique())
print(f"Total Number of Votes Cast: {total_votes}")
print("----------------------------------------------")
11/18:
#import relevant modules
import pandas as pd

#import csv file
pypoll_df = pd.read_csv("/Users/Jerry/Documents/Homework/python-challenge/election_data.csv")

#print header for results
print("Election Results")
11/19:
#import relevant modules
import pandas as pd

#import csv file
pypoll_df = pd.read_csv("/Users/Jerry/Documents/Homework/python-challenge/election_data.csv")

#print header for results
print("Election Results")
print("----------------------------------------------")
11/20:
#A complete list of candidates who received votes
candidate_voted_for = pypoll_df["Candidate"].unique()
11/21:
#A complete list of candidates who received votes
candidate_voted_for = pypoll_df["Candidate"].unique()
11/22:
#A complete list of candidates who received votes
candidate_voted_for = pypoll_df["Candidate"].unique()
print(candidate_voted_for)
11/23: #The percentage of votes each candidate won
11/24: candidate_vote_count = pypoll_df["Candidate"].value_counts()
11/25:
candidate_vote_count = pypoll_df["Candidate"].value_counts()
print(candidate_vote_count)
12/1:
#GoodMovies activities
#import pandas
import pandas
12/2:
#GoodMovies activities
#import pandas
import pandas as pd
12/3: csv_file = pd.read_csv("/Users/Jerry/Downloads/movie_scores.csv")
12/4: movies_df = pd.read_csv("/Users/Jerry/Downloads/movie_scores.csv")
12/5: movies_df.columns
12/6: movies_df.head()
12/7: movies_df.head()
12/8: IMDb_df = movie_df.loc[:, ["FILM", "IMDB"]].head()
12/9: IMDb_df = movies_df.loc[:, ["FILM", "IMDB"]].head()
12/10: IMDb_df = movies_df.loc[:, ["FILM", "IMDB"]].head()
12/11: IMDb_df.head()
12/12:
IMDb_df = movies_df.loc[:, ["FILM", "IMDB", "IMDB_norm","IMDB_norm_round","IMDB_user_vote_count"]].head()
#team code below
#imdb_table = df.loc[:, ["FILM", "IMDB_norm","IMDB_norm_round","IMDB_user_vote_count"]]
12/13: IMDb_df.head()
12/14:
#Filter out only the good movies—any film with an IMDb score greater than or equal 
#to 7—and remove the norm ratings.
12/15:
#Filter out only the good movies—any film with an IMDb score greater than or equal 
#to 7—and remove the norm ratings.
filtered_df = IMDb_df[IMDb_df[IMDB] >= 7]
print(filtered_df)
12/16:
#Filter out only the good movies—any film with an IMDb score greater than or equal 
#to 7—and remove the norm ratings.
filtered_df = IMDb_df[IMDb_df['IMDB'] >= 7]
print(filtered_df)
12/17: #Portland Crim.ipynb
12/18:
# Import Dependencies
import pandas as pd
12/19:
# Reference the file where the CSV is located
csv_file = /Users/Jerry/Downloads/crime_incident_data2017.csv
# Import the data into a Pandas DataFrame
12/20:
# Reference the file where the CSV is located
# Import the data into a Pandas DataFrame
portland_df = read_csv("/Users/Jerry/Downloads/crime_incident_data2017.csv")
12/21:
# Reference the file where the CSV is located
# Import the data into a Pandas DataFrame
portland_df = pd.ead_csv("/Users/Jerry/Downloads/crime_incident_data2017.csv")
12/22:
# Reference the file where the CSV is located
# Import the data into a Pandas DataFrame
portland_df = pd.read_csv("/Users/Jerry/Downloads/crime_incident_data2017.csv")
12/23:
# Reference the file where the CSV is located
# Import the data into a Pandas DataFrame
portland_df = pd.read_csv("/Users/Jerry/Downloads/crime_incident_data2017.csv")
head(portland_df)
12/24:
# Reference the file where the CSV is located
# Import the data into a Pandas DataFrame
portland_df = pd.read_csv("/Users/Jerry/Downloads/crime_incident_data2017.csv")
pd.head(portland_df)
12/25:
# Reference the file where the CSV is located
# Import the data into a Pandas DataFrame
portland_df = pd.read_csv("/Users/Jerry/Downloads/crime_incident_data2017.csv")
portland_df.head()
12/26: portland_df.values_count()
12/27: portland_df.columns
12/28:
 # look for missing values
portland_df.count()
12/29:
 # look for missing values
portland_df.count()
#Address, Neighborhood, Open Data Lat, Open Data Lon, Open Data X, Open Data Y
12/30: filter_df = portland_df.dropna(how = 'any')
12/31: crime_df = portland_df.dropna(how = 'any')
12/32: crime_df.head()
12/33: crime_df.count()
12/34:
Check to see if there are any values with mispelled or similar values in "Offense Type"
crime_df["Offense Type"].value_counts()
12/35:
Check to see if there are any values with mispelled or similar values in "Offense Type"
crime_df['Offense Type'].value_counts()
12/36:
#Check to see if there are any values with mispelled or similar values in "Offense Type"
crime_df["Offense Type"].value_counts()
12/37: crime_df["Offense Type"] = crime_df["Offense Type"].replace({"Theft From Building": "Burglary", "Shoplifting": "Burglary"})
12/38: edited_df = crime_df["Offense Type"].replace({"Theft From Building": "Burglary", "Shoplifting": "Burglary"})
12/39:
edited_df = crime_df["Offense Type"].replace({"Theft From Building": "Burglary", "Shoplifting": "Burglary"})
print(edited_df)
12/40: crime_df = portland_df.dropna(how = 'any')
12/41: crime_df.head()
12/42: crime_df.count()
12/43:
crime_df = crime_df["Offense Type"].replace({"Theft From Building": "Burglary", "Shoplifting": "Burglary"})
print(crime_df)
12/44:
crime_df = crime_df["Offense Type"].replace({"Theft From Building": "Burglary", "Shoplifting": "Burglary"})
crime_df.head()
12/45:
crime_df = crime_df.replace({"Theft From Building": "Burglary", "Shoplifting": "Burglary"})
crime_df.head()
12/46:
crime_df = crime_df.replace({"Theft From Building": "Burglary", "Shoplifting": "Burglary"})
crime_df.head()
12/47: #--------------------------------------------------------------------------------------------
12/48: #in class activity
12/49:
#Replace all NaN elements in column ‘A’, ‘B’, ‘C’, and ‘D’, with 0, 1, 2, and 3 respectively.

#values = {"A": 0, "B": 1, "C": 2, "D": 3}
#df.fillna(value=values)
 #    A    B    C    D
#0  0.0  2.0  2.0  0.0
#1  3.0  4.0  2.0  1.0
#2  0.0  1.0  2.0  3.0
#3  0.0  3.0  2.0  4.0
12/50: #df.value_counts(normalize = True)
12/51:
crime_df = crime_df.replace({"Theft From Building": "Burglary", "Shoplifting": "Burglary"})
crime_df.head()
12/52:
#Check to see if there are any values with mispelled or similar values in "Offense Type"
crime_df["Offense Type"].value_counts()
12/53:
# Import Dependencies
import pandas as pd
12/54:
# Reference the file where the CSV is located
# Import the data into a Pandas DataFrame
portland_df = pd.read_csv("/Users/Jerry/Downloads/crime_incident_data2017.csv")
portland_df.head()
12/55: portland_df.columns
12/56:
 # look for missing values
portland_df.count()
#Address, Neighborhood, Open Data Lat, Open Data Lon, Open Data X, Open Data Y
12/57: crime_df = portland_df.dropna(how = 'any')
12/58: crime_df.head()
12/59: crime_df.count()
12/60:
#Check to see if there are any values with mispelled or similar values in "Offense Type"
crime_df["Offense Type"].value_counts()
12/61:
crime_df["Offense Type"] = crime_df["Offense Type"].replace({"Theft From Building": "Burglary", "Shoplifting": "Burglary"})
crime_df.head()
12/62:
crime_df = crime_df.replace({"Theft From Building": "Burglary", "Shoplifting": "Burglary"})
crime_df.head()
11/26:
candidate_vote_count = pypoll_df["Candidate"].value_counts(normalize = True)
print(candidate_vote_count)
11/27:
candidate_vote_count = pypoll_df["Candidate"].value_counts()
print(candidate_vote_count)
11/28: candidate_vote_count.head()
11/29: candidate_vote_count = pypoll_df["Candidate"].value_counts()
11/30:
candidate_vote_count = pypoll_df["Candidate"].value_counts()
candidate_vote_count.head()
11/31:
candidate_vote_percent = pypoll_df["Candidate"].value_counts(normalize = True)
candidate_vote_count.head()
11/32:
candidate_vote_percent = pypoll_df["Candidate"].value_counts(normalize = True)
candidate_vote_percent.head()
11/33: candidate_vote_count.max()
11/34: candidate_vote_count["Candidate"].max()
11/35: candidate_vote_count.max(Candidate)
11/36: type(candidate_vote_count)
11/37: candidate_vote_count["Candidate"].max
11/38: candidate_vote_count.max
11/39: candidate_vote_count.max()
11/40:
max = candidate_vote_count.max()
print(f"Winner: Diana DeGette (int{max})")
11/41:
max = candidate_vote_count.max()
print(f"Winner: Diana DeGette {max}")
11/42:
max = candidate_vote_count.max()
print(f"Winner: Diana DeGette: {max}")
11/43:
max = candidate_vote_count.max()
print(f"Winner: Diana DeGette - {max}")
11/44:
max = candidate_vote_count.max()
print(f"Winner: Diana DeGette - {max} votes")
11/45:
max = candidate_vote_count.max()
print("----------------------------------------------")
print(f"Winner: Diana DeGette - {max} votes")
11/46: type(candidate_vote_percent)
11/47:  new_df = pd.DataFrame(candidate_vote_percent)
11/48:
new_df = pd.DataFrame(candidate_vote_percent)
new_df.head()
11/49:
new_df = pd.DataFrame(candidate_vote_percent, columns = ["Candidate", "percentage"])
new_df[""]
11/50: new_df = pd.DataFrame(candidate_vote_percent, columns = ["Candidate", "percentage"])
11/51:
new_df = pd.DataFrame(candidate_vote_percent, columns = ["Candidate", "percentage"])
new_df.head()
11/52:
new_df = pd.DataFrame(candidate_vote_percent, columns = ["percentage"])
new_df.head()
11/53:
new_df = pd.DataFrame(candidate_vote_percent)
new_df.head()
11/54: new_df["Percentage"] = new_df["Candidate"] * 100
11/55:
new_df["Percentage"] = new_df["Candidate"] * 100
new_df.head()
11/56:
new_df["Percentage"] = (round(new_df["Candidate"] * 100)) + '%'
new_df.head()
11/57:
new_df["Percentage"] = ((round(new_df["Candidate"] * 100)) + '%')
new_df.head()
11/58:
new_df["Percentage"] = ((round(new_df["Candidate"] * 100))
new_df.head()
11/59:
new_df["Percentage"] = (round(new_df["Candidate"] * 100)
new_df.head()
11/60:
new_df["Percentage"] = round(new_df["Candidate"] * 100
new_df.head()
11/61: new_df["Percentage"] = round(new_df["Candidate"] * 100
11/62: new_df["Percentage"] = (round(new_df["Candidate"] * 100)
11/63: new_df["Percentage"] = new_df["Candidate"] * 100
11/64:
new_df["Percentage"] = new_df["Candidate"] * 100
new_df.head()
13/1:
#import relevant modules
import pandas as pd

#import csv file
pypoll_df = pd.read_csv("/Users/Jerry/Documents/Homework/python-challenge/election_data.csv")

#print header for results
print("Election Results")
print("----------------------------------------------")
13/2:
#The total number of votes cast
total_votes = len(pypoll_df["Ballot ID"].unique())
print(f"Total Number of Votes Cast: {total_votes}")
print("----------------------------------------------")
13/3:
#The total number of votes cast
total_votes = len(pypoll_df["Ballot ID"].unique())
print(f"Total Votes: {total_votes}")
print("----------------------------------------------")
13/4:
candidate_vote_percent = pypoll_df["Candidate"].value_counts(normalize = True)
candidate_vote_percent.head()
13/5:
#A complete list of candidates who received votes
candidate_voted_for = pypoll_df["Candidate"].unique()
print(candidate_voted_for)
13/6:
candidate_vote_count = pypoll_df["Candidate"].value_counts()
candidate_vote_count.head()
13/7: type()
13/8: type(candidate_vote_count)
13/9:
new_df = pd.DataFrame(candidate_vote_percent)
new_df.head()
13/10:
#create variabes for candidate percentages
diana_percent = 0.738122
charles_percent = 0.230485
raymon_percent = 0.031392
13/11: type(diana_percent)
13/12:
#create variabes for candidate percentages
diana_percent = (0.738122) *100
charles_percent = (0.230485) *100
raymon_percent = (0.031392) *100
13/13: type(new_df)
13/14: type(candidate_vote_percent)
13/15: d = {'Candidates': candidate_vote_percent}
13/16:
d = {'Candidates': candidate_vote_percent}
d
13/17:
d = {'Candidates': candidate_vote_percent}
pd.DataFrame(data=d, index=[0, 1, 2, 3])
13/18:
d = {'Candidates': candidate_vote_percent}
pd.DataFrame(data=d, index=[0, 1, 2)
13/19:
d = {'Candidates': candidate_vote_percent}
pd.DataFrame(data=d, index=[0, 1, 2]
13/20:
d = {'Candidates': candidate_vote_percent}
pd.DataFrame(data=d, index=[0, 1, 2, 3]
13/21:
d = {'Candidates': candidate_vote_percent}
pd.DataFrame(data=d, index=[0, 1, 2])
13/22:
d = {candidate_vote_percent}
pd.DataFrame(data=d, index=[0, 1, 2])
13/23:
new_df["Percentage"] = new_df["Candidate"] * 100
new_df.head()
13/24:
#summarize the top and the bottom of the csv file
pypoll_df.head()
13/25:
z = pypoll_df["County"].value_counts(normalize = True)
z.head()
13/26:
z = pypoll_df["County"].value_counts(normalize = True)
s = pd.DataFrame(z)
s.head()
13/27:
new_df = pd.DataFrame(candidate_vote_percent, index=[0, 1, 2, 3])
new_df.head()
13/28:
new_df = pd.DataFrame(data = candidate_vote_percent, index=[0, 1, 2, 3])
new_df.head()
13/29:
new_df = pd.DataFrame(candidate_vote_percent)
new_df.head()
13/30:
#create variabes for candidate percentages
diana_dec = (0.738122) *100
charles_dec = (0.230485) *100
raymon_dec = (0.031392) *100
13/31: diana_dec = int[(0.738122) *100]
13/32: diana_dec = ("$[int((0.738122) *100)"]
13/33: diana_dec = ("$[int((0.738122) *100)]")
13/34:
diana_dec = ("$[int((0.738122) *100)]")
diana_dec
13/35:
diana_dec = "$"((0.738122) *100))
diana_dec
13/36:
diana_dec = "$"((0.738122) *100)
diana_dec
13/37:
diana_dec = "$",((0.738122) *100)
diana_dec
13/38:
diana_dec = ("$"((0.738122) *100))
diana_dec
13/39:
#create variabes for candidate percentages
diana_dec = (0.738122) *100
charles_dec = (0.230485) *100
raymon_dec = (0.031392) *100

#Add percent signs to percentages
13/40:
#create variabes for candidate percentages
diana_dec = (0.738122) *100
charles_dec = (0.230485) *100
raymon_dec = (0.031392) *100

#Add percent signs to percentages
dper = "%" + diana_dec
13/41:
#create variabes for candidate percentages
diana_dec = (0.738122) *100
charles_dec = (0.230485) *100
raymon_dec = (0.031392) *100

#Add percent signs to percentages
dper = "%"diana_dec
13/42:
#create variabes for candidate percentages
diana_dec = (0.738122) *100
charles_dec = (0.230485) *100
raymon_dec = (0.031392) *100

#Add percent signs to percentages
dper = (f" %{diana_dec}")
13/43:
#create variabes for candidate percentages
diana_dec = (0.738122) *100
charles_dec = (0.230485) *100
raymon_dec = (0.031392) *100

#Add percent signs to percentages
dper = (f" %{diana_dec}")
cper = (f" %{charles_dec}")
rper = (f" %{raymon_dec}")
13/44:
#create variabes for candidate percentages
diana_dec = (0.738122) *100
charles_dec = (0.230485) *100
raymon_dec = (0.031392) *100

#Add percent signs to percentages
dper = (f" %{diana_dec}")
cper = (f" %{charles_dec}")
rper = (f" %{raymon_dec}")

dper
cper
rper
13/45:
#create variabes for candidate percentages
diana_dec = (0.738122) *100
charles_dec = (0.230485) *100
raymon_dec = (0.031392) *100

#Add percent signs to percentages
dper = (f" %{diana_dec}")
cper = (f" %{charles_dec}")
rper = (f" %{raymon_dec}")

dper
13/46:
#create variabes for candidate percentages
diana_dec = round((0.738122) *100)
charles_dec = (0.230485) *100
raymon_dec = (0.031392) *100

diana_dec
13/47:
#create variabes for candidate percentages
diana_dec = round(((0.738122) *100)), 3)
charles_dec = (0.230485) *100
raymon_dec = (0.031392) *100

diana_dec
13/48:
#create variabes for candidate percentages
diana_dec = round(((0.738122) *100), 3)
charles_dec = (0.230485) *100
raymon_dec = (0.031392) *100

diana_dec
13/49:
#create variabes for candidate percentages
diana_dec = round(((0.738122) *100), 3)
charles_dec = round(((0.230485) *100), 3)
raymon_dec = round(((0.031392) *100), 3)

diana_dec
13/50:
#create variabes for candidate percentages
diana_dec = round(((0.738122) *100), 3)
charles_dec = round(((0.230485) *100), 3)
raymon_dec = round(((0.031392) *100), 3)

charles_dec
13/51:
#create variabes for candidate percentages
diana_dec = round(((0.738122) *100), 3)
charles_dec = round(((0.230485) *100), 3)
raymon_dec = round(((0.031392) *100), 3)

add percent signs
dper = (f"%{diana_dec}")
cper = (f"%{charles_dec}")
rper = (f"%{raymon_dec}")
13/52:
#create variabes for candidate percentages
diana_dec = round(((0.738122) *100), 3)
charles_dec = round(((0.230485) *100), 3)
raymon_dec = round(((0.031392) *100), 3)

#add percent signs
dper = (f"%{diana_dec}")
cper = (f"%{charles_dec}")
rper = (f"%{raymon_dec}")
13/53:
#create variabes for candidate percentages
diana_dec = round(((0.738122) *100), 3)
charles_dec = round(((0.230485) *100), 3)
raymon_dec = round(((0.031392) *100), 3)

#add percent signs
dper = (f"%{diana_dec}")
cper = (f"%{charles_dec}")
rper = (f"%{raymon_dec}")

dper
13/54: prac = {"Percentage of Votes": dper}
13/55:
#create total variables
dtotal = (f"({272892})")
ctotal = (f"({85213})")
rtotal = (f"({11606})")
13/56:
#create results section
result_info = {"Candidates": ["Diana DeGette:", "Charles Casper Stockham:", "Raymon Anthony Doane:"],
                "Percentage of Votes": dper, cper, rper,
               "Total votes": dtotal, ctotal, rtotal
}
13/57:
#create results section
result_info = {"Candidates": ["Diana DeGette:", "Charles Casper Stockham:", "Raymon Anthony Doane:"],
                "Percentage of Votes": {dper, cper, rper},
               "Total votes": {dtotal, ctotal, rtotal}}
13/58:
#create results section
result_info = {"Candidates": ["Diana DeGette:", "Charles Casper Stockham:", "Raymon Anthony Doane:"],
                "Percentage of Votes": {dper, cper, rper},
               "Total votes": {dtotal, ctotal, rtotal}}
print(result_info)
13/59:
#create dictresults section
result_info = {"Candidates": ["Diana DeGette:", "Charles Casper Stockham:", "Raymon Anthony Doane:"],
                "Percentage of Votes": {dper, cper, rper},
               "Total votes": {dtotal, ctotal, rtotal}}
pd.DataFrame.from_dict(result_info)
13/60: type(dper)
13/61:
#create dictresults section
result_info = {"Candidates": ["Diana DeGette:", "Charles Casper Stockham:", "Raymon Anthony Doane:"],
                "Percentage of Votes": [dper, cper, rper],
               "Total votes": [dtotal, ctotal, rtotal]}
13/62:
#create dictresults section
result_info = {"Candidates": ["Diana DeGette:", "Charles Casper Stockham:", "Raymon Anthony Doane:"],
                "Percentage of Votes": [dper, cper, rper],
               "Total votes": [dtotal, ctotal, rtotal]}
pd.DataFrame.from_dict(result_info)
13/63: pd.DataFrame.from_dict(result_info)
13/64:
#final sheet
#print header for results
print("Election Results")
print("----------------------------------------------")
print(f"Total Votes: {total_votes}")
print("----------------------------------------------")
pd.DataFrame.from_dict(result_info)
print("----------------------------------------------")
print(f"Winner: Diana DeGette - {max} votes")
print("----------------------------------------------")
13/65:
#final sheet
#print header for results
print("Election Results")
print("----------------------------------------------")
print(f"Total Votes: {total_votes}")
print("----------------------------------------------")
pd.DataFrame.from_dict(result_info).head()
print("----------------------------------------------")
print(f"Winner: Diana DeGette - {max} votes")
print("----------------------------------------------")
13/66:
#create dictresults section
result_info = {"Candidates": ["Diana DeGette:", "Charles Casper Stockham:", "Raymon Anthony Doane:"],
                "Percentage of Votes": [dper, cper, rper],
               "Total votes": [dtotal, ctotal, rtotal]}

results_df = pd.DataFrame.from_dict(result_info)
13/67:
#final sheet
#print header for results
print("Election Results")
print("----------------------------------------------")
print(f"Total Votes: {total_votes}")
print("----------------------------------------------")
print(results_df)
print("----------------------------------------------")
print(f"Winner: Diana DeGette - {max} votes")
print("----------------------------------------------")
13/68:
max = candidate_vote_count.max()
print("----------------------------------------------")
print(f"Winner: Diana DeGette - {max} votes")
13/69:
#final sheet
#print header for results
print("Election Results")
print("----------------------------------------------")
print(f"Total Votes: {total_votes}")
print("----------------------------------------------")
print(results_df)
print("----------------------------------------------")
print(f"Winner: Diana DeGette - {max} votes")
print("----------------------------------------------")
13/70:
#import relevant modules
import pandas as pd

#import csv file
pypoll_df = pd.read_csv("/Users/Jerry/Documents/Homework/python-challenge/election_data.csv")

#print header for results
#print("Election Results")
#print("----------------------------------------------")
13/71:
#The total number of votes cast
total_votes = len(pypoll_df["Ballot ID"].unique())
#print(f"Total Votes: {total_votes}")
#print("----------------------------------------------")
13/72:
#A complete list of candidates who received votes
candidate_voted_for = pypoll_df["Candidate"].unique()
#print(candidate_voted_for)
13/73: #The percentage of votes each candidate won
13/74:
candidate_vote_percent = pypoll_df["Candidate"].value_counts(normalize = True)
#candidate_vote_percent.head()
13/75: #The total number of votes each candidate won
13/76:
candidate_vote_count = pypoll_df["Candidate"].value_counts()
#candidate_vote_count.head()
13/77:
#create total variables
dtotal = (f"({272892})")
ctotal = (f"({85213})")
rtotal = (f"({11606})")

#create variabes for candidate percentages
diana_dec = round(((0.738122) *100), 3)
charles_dec = round(((0.230485) *100), 3)
raymon_dec = round(((0.031392) *100), 3)

#add percent signs to percentages
dper = (f"%{diana_dec}")
cper = (f"%{charles_dec}")
rper = (f"%{raymon_dec}")
13/78:
#create dict for results section
result_info = {"Candidates": ["Diana DeGette:", "Charles Casper Stockham:", "Raymon Anthony Doane:"],
                "Percentage of Votes": [dper, cper, rper],
               "Total votes": [dtotal, ctotal, rtotal]}

#dataframe created by the dict named result_info
results_df = pd.DataFrame.from_dict(result_info)
13/79:
#the winner based off of popular votes
max = candidate_vote_count.max()
print("----------------------------------------------")
#print(f"Winner: Diana DeGette - {max} votes")
13/80:
#final election result sheet
print("Election Results")
print("----------------------------------------------")
print(f"Total Votes: {total_votes}")
print("----------------------------------------------")
print(results_df)
print("----------------------------------------------")
print(f"Winner: Diana DeGette - {max} votes")
print("----------------------------------------------")
14/1:
#import relevant modules
import pandas as pd

#upload cvs file
pybank_df = pd.read_csv("/Users/Jerry/Documents/Homework/python-challenge/budget_data.csv")
14/2:
print("Financial Analysis")
print("--------------------------------------------")
month_count = len(pybank_df["Date"].unique())
print("Total Months: " + str(month_count))
14/3:
#The net total amount of "Profit/Losses" over the entire period
net_total = pybank_df["Profit/Losses"].sum()
print("Total: $" + str(net_total))
14/4: pybank_df["Date"] = Feb-14
14/5: pybank_df["Date"] = "Feb-14"
14/6:
#import relevant modules
import pandas as pd

#upload cvs file
pybank_df = pd.read_csv("/Users/Jerry/Documents/Homework/python-challenge/budget_data.csv")
a
14/7:
#import relevant modules
import pandas as pd

#upload cvs file
pybank_df = pd.read_csv("/Users/Jerry/Documents/Homework/python-challenge/budget_data.csv")
14/8:
#py_bank_csv = pd.read_csv("C:\Users\19095\Downloads\budget_data.csv")
#SyntaxError: (unicode error) 'unicodeescape' codec can't decode bytes in position 2-3: truncated \UXXXXXXXX escape
#Solution found on: https://stackoverflow.com/questions/37400974/unicode-error-unicodeescape-codec-cant-decode-bytes-in-position-2-3-trunca
14/9:
#preview beginning and ending of csv file

pybank_df.head()
14/10: pybank_df.tail()
14/11:
#The greatest decrease in profits (date and amount) over the entire period
#worst_loss = pybank_df[["Date", "Profit/Losses"]].min()
worst_loss = pybank_df["Profit/Losses"].min()
print(f"Greatest decrease in Profits: {worst_loss}")
14/12:
#The greatest increase in profits (date and amount) over the entire period
#max_profits = pybank_df[["Date", "Profit/Losses"]].max()

max_profits = pybank_df["Profit/Losses"].max()

print(f"Greatest Increase in Profits: ${max_profits}")
14/13:
#The greatest increase in profits (date and amount) over the entire period
max_profits = pybank_df[["Date", "Profit/Losses"]].max()

#max_profits = pybank_df["Profit/Losses"].max()

print(f"Greatest Increase in Profits: ${max_profits}")
14/14:
#The greatest decrease in profits (date and amount) over the entire period
worst_loss = pybank_df[["Date", "Profit/Losses"]].min()
#worst_loss = pybank_df["Profit/Losses"].min()
print(f"Greatest decrease in Profits: {worst_loss}")
14/15:
#The greatest increase in profits (date and amount) over the entire period
#max_profits = pybank_df[["Date", "Profit/Losses"]].max()

max_profits = pybank_df["Profit/Losses"].max()

print(f"Greatest Increase in Profits: ${max_profits}")
14/16:
#The greatest decrease in profits (date and amount) over the entire period
#worst_loss = pybank_df[["Date", "Profit/Losses"]].min()
worst_loss = pybank_df["Profit/Losses"].min()
print(f"Greatest decrease in Profits: {worst_loss}")
14/17:
if ["Profit/Losses"] = max_profits:
    print["Date"]
14/18:
if ["Profit/Losses"] = [max_profits]:
    print["Date"]
14/19:
if ["Profit/Losses"] = (max_profits):
    print["Date"]
14/20:
if pybank_df["Profit/Losses"] = (max_profits):
    print["Date"]
14/21:
if pybank_df["Profit/Losses"] = 1141840:
    print["Date"]
14/22:
if pybank_df["Profit/Losses"] > 1000000:
    print["Date"]
14/23: type(max_profits)
14/24:
if pybank_df["Profit/Losses"] = max_profits
    print["Date"]
14/25:
if pybank_df["Profit/Losses"] = max_profits
    print[Date]
14/26:
if pybank_df[Profit/Losses] = max_profits
    print[Date]
14/27:
#df.loc[df['set_of_numbers'] <= 4, 'equal_or_lower_than_4?'] = 'True'
df.loc[pybank_df["Profit/Losses"] = max_profits]
14/28:
#df.loc[df['set_of_numbers'] <= 4, 'equal_or_lower_than_4?'] = 'True'
df.loc[pybank_df["Profit/Losses"] = max_profits]:
    print("Date")
14/29:
print("Financial Analysis")
print("--------------------------------------------")
print("Total Months: " + str(month_count))
print("Total: $" + str(net_total))
print(f"Greatest Increase in Profits: ${max_profits}")
print(f"Greatest decrease in Profits: {worst_loss}")
14/30: print(pybank_df["Date"])
14/31: print(pybank_df["Date"] = Mar-13)
14/32: print(pybank_df["Date"] = "Mar-13")
14/33: print(pybank_df["Date"] == "Mar-13")
16/1:
#Finding the difference in profit/losses between months
dif_bw_months = pybank_df["Profit/Losses"].diff()
16/2:
#import relevant modules
import pandas as pd

#upload cvs file
pybank_df = pd.read_csv("/Users/Jerry/Documents/Homework/python-challenge/budget_data.csv")
16/3:
#Finding the difference in profit/losses between months
dif_bw_months = pybank_df["Profit/Losses"].diff()
16/4:
#Finding the difference in profit/losses between months
dif_bw_months = pybank_df["Profit/Losses"].diff()
dif_bw_months
16/5:
#Finding the difference in profit/losses between months
dif_bw_months = pybank_df["Profit/Losses"].diff()
dif_bw_months
greatest_positive_change = dif_bw_months.max()
16/6:
#Finding the difference in profit/losses between months
dif_bw_months = pybank_df["Profit/Losses"].diff()
#now find the max and min of these changes
greatest_positive_change = dif_bw_months.max()
greatest_positive_change
16/7:
#Finding the difference in profit/losses between months
dif_bw_months = pybank_df["Profit/Losses"].diff()
dif_bw_months
#now find the max and min of these changes
greatest_positive_change = dif_bw_months.max()
#greatest_positive_change
16/8:
#Finding the difference in profit/losses between months
dif_bw_months = pybank_df["Profit/Losses"].diff()
dif_bw_months
#now find the max and min of these changes
greatest_positive_change = dif_bw_months.max()
#greatest_positive_change
16/9:
#Finding the difference in profit/losses between months
dif_bw_months = pybank_df["Profit/Losses"].diff()
print(dif_bw_months)
#now find the max and min of these changes
greatest_positive_change = dif_bw_months.max()
#greatest_positive_change
16/10: dif_bw_months = pybank_df("Date")
16/11: dif_bw_months = pybank_df["Date"]
16/12:
#Finding the difference in profit/losses between months
dif_bw_months = pybank_df["Profit/Losses"].diff()
print(dif_bw_months)
#now find the max and min of these changes
greatest_positive_change = dif_bw_months.max()
#greatest_positive_change
16/13:
dif_bw_months = pybank_df["Date"]
dif_bw_months
16/14:
#Finding the difference in profit/losses between months
dif_bw_months = pybank_df["Profit/Losses"].diff()
print(dif_bw_months)
#now find the max and min of these changes
greatest_positive_change = dif_bw_months.max()
#greatest_positive_change
16/15:
#Finding the difference in profit/losses between months
dif_bw_months = pybank_df["Profit/Losses"].diff()
print(dif_bw_months)
#now find the max and min of these changes
greatest_positive_change = dif_bw_months.max()
#greatest_positive_change
16/16:
dif_bw_months = {pybank_df["Date"]}
dif_bw_months
16/17:
dif_bw_months = (pybank_df["Date"], pybank_df["Profit/Losses"].diff())
dif_bw_months
16/18:
dif_bw_months = (pybank_df["Date"], pybank_df["Profit/Losses"].diff())
dif_bw_months.head()
16/19:
dif_bw_months = (pybank_df["Date"], pybank_df["Profit/Losses"].diff())
print(dif_bw_months)
16/20:
dif_bw_months = pd.DataFrame(pybank_df["Date"], pybank_df["Profit/Losses"].diff())
dif_bw_months
16/21:
dif_bw_months = pd.DataFrame((str(pybank_df["Date"])), pybank_df["Profit/Losses"].diff())
dif_bw_months
16/22:
dif_bw_months = pd.DataFrame(str(pybank_df["Date"]), pybank_df["Profit/Losses"].diff())
dif_bw_months
16/23:
dif_bw_months = pd.DataFrame(pybank_df["Date"]), pybank_df["Profit/Losses"].diff())
dif_bw_months
16/24:
dif_bw_months = pd.DataFrame(pybank_df["Date"]), pybank_df["Profit/Losses"].diff()
dif_bw_months
16/25:
#Finding the difference in profit/losses between months
dif_bw_months = pybank_df["Profit/Losses"].diff()
print(dif_bw_months)
#now find the max and min of these changes
greatest_positive_change = dif_bw_months.max()
#greatest_positive_change
16/26:
dif_bw_months = pd.DataFrame(pybank_df["Date"]), pybank_df["Profit/Losses"].diff()
dif_bw_months
16/27:
#Finding the difference in profit/losses between months
#dif_bw_months = pybank_df["Profit/Losses"].diff()
#print(dif_bw_months)
#now find the max and min of these changes
greatest_positive_change = dif_bw_months.max()
#greatest_positive_change
16/28:
#Finding the difference in profit/losses between months
#dif_bw_months = pybank_df["Profit/Losses"].diff()
#print(dif_bw_months)
#now find the max and min of these changes
greatest_positive_change = dif_bw_months[pybank_df["Profit/Losses"].diff()].max()
#greatest_positive_change
16/29:
#Finding the difference in profit/losses between months
dif_bw_months = pybank_df["Profit/Losses"].diff()
print(dif_bw_months)
#now find the max and min of these changes
greatest_positive_change = dif_bw_months.max()
#greatest_positive_change
16/30:
#Finding the difference in profit/losses between months
dif_bw_months = pybank_df["Profit/Losses"].diff()
print(dif_bw_months)
#now find the max and min of these changes
greatest_positive_change = dif_bw_months.max()
greatest_positive_change
16/31:
#Finding the difference in profit/losses between months
dif_bw_months = pybank_df["Profit/Losses"].diff()
#print(dif_bw_months)
#now find the max and min of these changes
greatest_positive_change = dif_bw_months.max()
greatest_positive_change
16/32:
#The minimum of the changes between months
greatest_negative_change = dif_bw_months.min()
16/33:
#The minimum of the changes between months
greatest_negative_change = dif_bw_months.min()
greatest_negative_change
16/34:
print("Financial Analysis")
print("--------------------------------------------")
print("Total Months: " + str(month_count))
print("Total: $" + str(net_total))
#print(f"Greatest Increase in Profits: ${max_profits}")
print(f"Greatest Increase in Profits: ${greatest_positive_change}")
#print(f"Greatest decrease in Profits: {worst_loss}")
print(f"Greatest decrease in Profits: {greatest_negative_change}")
16/35:
#import relevant modules
import pandas as pd

#upload cvs file
pybank_df = pd.read_csv("/Users/Jerry/Documents/Homework/python-challenge/budget_data.csv")
16/36:
#py_bank_csv = pd.read_csv("C:\Users\19095\Downloads\budget_data.csv")
#SyntaxError: (unicode error) 'unicodeescape' codec can't decode bytes in position 2-3: truncated \UXXXXXXXX escape
#Solution found on: https://stackoverflow.com/questions/37400974/unicode-error-unicodeescape-codec-cant-decode-bytes-in-position-2-3-trunca
16/37:
#preview beginning and ending of csv file

pybank_df.head()
16/38: pybank_df.tail()
16/39:
#Your task is to create a Python script that analyzes the records to calculate each of the following:
#The total number of months included in the dataset
pybank_df.columns
16/40:
print("Financial Analysis")
print("--------------------------------------------")
month_count = len(pybank_df["Date"].unique())
print("Total Months: " + str(month_count))
16/41:
#The net total amount of "Profit/Losses" over the entire period
net_total = pybank_df["Profit/Losses"].sum()
print("Total: $" + str(net_total))
16/42:
#The changes in "Profit/Losses" over the entire period, and then the average of those changes
avg = pybank_df["Profit/Losses"].mean()
avg_change = avg.

print(f"Average Change: ${avg_change}")

change_per_month = avg_change/ 86
print(f"Average Change per Month: ${change_per_month}")
16/43:
#The changes in "Profit/Losses" over the entire period, and then the average of those changes
avg = pybank_df["Profit/Losses"].mean()
avg_change = avg

print(f"Average Change: ${avg_change}")

change_per_month = avg_change/ 86
print(f"Average Change per Month: ${change_per_month}")
16/44:
print("Financial Analysis")
print("--------------------------------------------")
print("Total Months: " + str(month_count))
print("Total: $" + str(net_total))
#print(f"Greatest Increase in Profits: ${max_profits}")
print(f"Greatest Increase in Profits: ${greatest_positive_change}")
#print(f"Greatest decrease in Profits: {worst_loss}")
print(f"Greatest decrease in Profits: {greatest_negative_change}")
16/45:
print("Financial Analysis")
print("--------------------------------------------")
print("Total Months: " + str(month_count))
print("Total: $" + str(net_total))
#print(f"Greatest Increase in Profits: ${max_profits}")
print(f"Greatest Increase in Profits: ${greatest_positive_change}")
#print(f"Greatest decrease in Profits: {worst_loss}")
print(f"Greatest decrease in Profits: ${greatest_negative_change}")
16/46:
#The changes in "Profit/Losses" over the entire period, and then the average of those changes
dif_bw_months = pybank_df["Profit/Losses"].diff()
#print(dif_bw_months)


avg_of_the_changes = dif_bw_months.mean()
avg_of_the_changes

#print(f"Average Change: ${avg_change}")

#change_per_month = avg_change/ 86
#print(f"Average Change per Month: ${change_per_month}")
16/47:
#The changes in "Profit/Losses" over the entire period
dif_bw_months = pybank_df["Profit/Losses"].diff()
print(dif_bw_months)
16/48:
#and then the average of those changes
avg_of_the_changes = dif_bw_months.mean()
avg_of_the_changes

print(f"Average Change: ${avg_of_the_changes}")
16/49:
#and then the average of those changes
avg_of_the_changes = dif_bw_months.mean()
Rounded = round(avg_of_the_changes, 2)

print(f"Average Change: ${avg_of_the_changes}")
16/50:
#and then the average of those changes
avg_of_the_changes = dif_bw_months.mean()
rounded = round(avg_of_the_changes, 2)

print(f"Average Change: ${rounded}")
16/51:
print("Financial Analysis")
print("--------------------------------------------")
print("Total Months: " + str(month_count))
print("Total: $" + str(net_total))
print(f"Average Change: ${rounded}")
print(f"Greatest Increase in Profits: ${greatest_positive_change}")

print(f"Greatest decrease in Profits: ${greatest_negative_change}")
16/52:
print("Financial Analysis")
print("--------------------------------------------")
print("Total Months: " + str(month_count))
print("Total: $" + str(net_total))
print(f"Average Change: ${rounded}")
print(f"Greatest Increase in Profits: Aug-16 ${greatest_positive_change}")

print(f"Greatest decrease in Profits: Feb-14 ${greatest_negative_change}")
16/53:
print("Financial Analysis")
print("--------------------------------------------")
print("Total Months: " + str(month_count))
print("Total: $" + str(net_total))
print(f"Average Change: ${rounded}")
print(f"Greatest Increase in Profits: Aug-16 ${greatest_positive_change}")

print(f"Greatest decrease in Profits: Feb-14 ${greatest_negative_change}")
16/54: #pybank homework
16/55:
#import relevant modules
import pandas as pd

#upload cvs file
pybank_df = pd.read_csv("/Users/Jerry/Documents/Homework/python-challenge/budget_data.csv")
16/56:
#py_bank_csv = pd.read_csv("C:\Users\19095\Downloads\budget_data.csv")
#SyntaxError: (unicode error) 'unicodeescape' codec can't decode bytes in position 2-3: truncated \UXXXXXXXX escape
#Solution found on: https://stackoverflow.com/questions/37400974/unicode-error-unicodeescape-codec-cant-decode-bytes-in-position-2-3-trunca
16/57:
#preview beginning and ending of csv file

#pybank_df.head()
16/58: #pybank_df.tail()
16/59:
#Your task is to create a Python script that analyzes the records to calculate each of the following:
#The total number of months included in the dataset
#pybank_df.columns
16/60:
#print("Financial Analysis")
#print("--------------------------------------------")
month_count = len(pybank_df["Date"].unique())
#print("Total Months: " + str(month_count))
16/61:
#The net total amount of "Profit/Losses" over the entire period
net_total = pybank_df["Profit/Losses"].sum()
#print("Total: $" + str(net_total))
16/62:
#The changes in "Profit/Losses" over the entire period
dif_bw_months = pybank_df["Profit/Losses"].diff()
#print(dif_bw_months)
16/63:
#and then the average of those changes
avg_of_the_changes = dif_bw_months.mean()
rounded = round(avg_of_the_changes, 2)

#print(f"Average Change: ${rounded}")
16/64:
#my attempt to create a df with the column Date and the new column dif_bw_months
#dif_bw_months = pd.DataFrame(pybank_df["Date"]), pybank_df["Profit/Losses"].diff()
#dif_bw_months
16/65:
#Finding the difference in profit/losses between months
dif_bw_months = pybank_df["Profit/Losses"].diff()
#print(dif_bw_months)

#The greatest increase in profits (date and amount) over the entire period
greatest_positive_change = dif_bw_months.max()
#greatest_positive_change
16/66:
#The greatest decrease in profits (date and amount) over the entire period
greatest_negative_change = dif_bw_months.min()
#greatest_negative_change
16/67:
print("Financial Analysis")
print("--------------------------------------------")
print("Total Months: " + str(month_count))
print("Total: $" + str(net_total))
print(f"Average Change: ${rounded}")
print(f"Greatest Increase in Profits: Aug-16 ${greatest_positive_change}")

print(f"Greatest decrease in Profits: Feb-14 ${greatest_negative_change}")
17/1:
#create dict for results section
result_info = {"Candidates": ["Diana DeGette:", "Charles Casper Stockham:", "Raymon Anthony Doane:"],
                "Percentage of Votes": [dper, cper, rper],
               "Total votes": [dtotal, ctotal, rtotal]}

#dataframe created by the dictionaries named result_info
results_df = pd.DataFrame.from_dict(result_info)
17/2:
#import relevant modules
import pandas as pd

#import csv file
pypoll_df = pd.read_csv("/Users/Jerry/Documents/Homework/python-challenge/election_data.csv")

#print header for results
#print("Election Results")
#print("----------------------------------------------")
17/3:
#summarize the top and the bottom of the csv file
#pypoll_df.head()
17/4: #pypoll_df.tail()
17/5: #pypoll_df.columns
17/6:
#The total number of votes cast
total_votes = len(pypoll_df["Ballot ID"].unique())
#print(f"Total Votes: {total_votes}")
#print("----------------------------------------------")
17/7:
#A complete list of candidates who received votes
candidate_voted_for = pypoll_df["Candidate"].unique()
#print(candidate_voted_for)
17/8:
#The percentage of votes each candidate won
candidate_vote_percent = pypoll_df["Candidate"].value_counts(normalize = True)
#candidate_vote_percent.head()
17/9:
#The total number of votes each candidate won
candidate_vote_count = pypoll_df["Candidate"].value_counts()
#candidate_vote_count.head()
17/10:
#create total variables
dtotal = (f"({272892})")
ctotal = (f"({85213})")
rtotal = (f"({11606})")

#create variabes for candidate percentages
diana_dec = round(((0.738122) *100), 3)
charles_dec = round(((0.230485) *100), 3)
raymon_dec = round(((0.031392) *100), 3)

#add percent signs to percentages
dper = (f"%{diana_dec}")
cper = (f"%{charles_dec}")
rper = (f"%{raymon_dec}")
17/11:
#create dict for results section
result_info = {"Candidates": ["Diana DeGette:", "Charles Casper Stockham:", "Raymon Anthony Doane:"],
                "Percentage of Votes": [dper, cper, rper],
               "Total votes": [dtotal, ctotal, rtotal]}

#dataframe created by the dictionaries named result_info
results_df = pd.DataFrame.from_dict(result_info)
17/12:
#the winner based off of popular votes
max = candidate_vote_count.max()
#print("----------------------------------------------")
#print(f"Winner: Diana DeGette - {max} votes")
17/13:
#final election result sheet
print("Election Results")
print("----------------------------------------------")
print(f"Total Votes: {total_votes}")
print("----------------------------------------------")
print(results_df)
print("----------------------------------------------")
print(f"Winner: Diana DeGette - {max} votes")
print("----------------------------------------------")
17/14:
#The percentage of votes each candidate won
candidate_vote_percent = pypoll_df["Candidate"].value_counts(normalize = True)
candidate_vote_percent.head()
17/15:
#The total number of votes each candidate won
candidate_vote_count = pypoll_df["Candidate"].value_counts()
candidate_vote_count.head()
17/16:
#create dict for results section
result_info = {"Candidates": ["Diana DeGette:", "Charles Casper Stockham:", "Raymon Anthony Doane:"],
                "Percentage of Votes": [dper, cper, rper],
               "Total votes": [dtotal, ctotal, rtotal]}

#dataframe created by the dictionaries named result_info
results_df = pd.DataFrame.from_dict(result_info)
17/17:
#create dict for results section
result_info = {"Candidates": ["Diana DeGette:", "Charles Casper Stockham:", "Raymon Anthony Doane:"],
                "Percentage of Votes": [dper, cper, rper],
               "Total votes": [dtotal, ctotal, rtotal]}

#dataframe created by the dictionaries named result_info
results_df = pd.DataFrame.from_dict(result_info)
results_df
17/18:
#final election result sheet
print("Election Results")
print("----------------------------------------------")
print(f"Total Votes: {total_votes}")
print("----------------------------------------------")
print(results_df, index = False)
print("----------------------------------------------")
print(f"Winner: Diana DeGette - {max} votes")
print("----------------------------------------------")
17/19:
#create dict for results section
result_info = {"Candidates": ["Diana DeGette:", "Charles Casper Stockham:", "Raymon Anthony Doane:"],
                "Percentage of Votes": [dper, cper, rper],
               "Total votes": [dtotal, ctotal, rtotal]}

#dataframe created by the dictionaries named result_info
results_df = pd.DataFrame.from_dict(result_info, index = False)
results_df
17/20:
#create dict for results section
result_info = {"Candidates": ["Diana DeGette:", "Charles Casper Stockham:", "Raymon Anthony Doane:"],
                "Percentage of Votes": [dper, cper, rper],
               "Total votes": [dtotal, ctotal, rtotal]}

#dataframe created by the dictionaries named result_info
results_df = pd.DataFrame.from_dict(result_info)
results_df
17/21:
#final election result sheet
print("Election Results")
print("----------------------------------------------")
print(f"Total Votes: {total_votes}")
print("----------------------------------------------")
print(results_df)
print("----------------------------------------------")
print(f"Winner: Diana DeGette - {max} votes")
print("----------------------------------------------")
17/22:
#final election result sheet
print("Election Results")
print("----------------------------------------------")
print(f"Total Votes: {total_votes}")
print("----------------------------------------------")
print(results_df.to_string(index = False))
print("----------------------------------------------")
print(f"Winner: Diana DeGette - {max} votes")
print("----------------------------------------------")
18/1: import pandas as pd
18/2:
state_avg = read_csv("/Users/Jerry/Downloads/state_avg.csv")
state_totals = read_csv("/Users/Jerry/Downloads/state_totals.csv")
18/3:
state_avg = pd.read_csv("/Users/Jerry/Downloads/state_avg.csv")
state_totals = pd.read_csv("/Users/Jerry/Downloads/state_totals.csv")
18/4:
#print out dataframes
state_avg.head()
18/5: state_totals.head()
18/6:
#Perform an inner merge that combines both DataFrames on the "Year" and "State" columns.
inner_merge = pd.merge(state_avg, state_totals)
18/7:
#Perform an inner merge that combines both DataFrames on the "Year" and "State" columns.
inner_merge = pd.merge(state_avg, state_totals)
inner_merge
18/8:
outer_merge = pd.merge(state_avg, state_totals, on = "State", how = "inner")
outer_merge
18/9:
outer_merge = pd.merge(state_avg, state_totals, on = "Year", how = "inner")
outer_merge
18/10:
outer_merge = pd.merge(state_avg, state_totals, on = ("Year", "State"), how = "inner")
outer_merge
18/11: type(outer_merge["Year"])
18/12: type(state_totals)
18/13: type(state_totals["state_totals"])
18/14: type(state_totals["Date"])
18/15:
#Create a DataFrame that filters the data on only 2019.
filter_df = pd.DateFrame(state_avg.loc[state_avg["Year"] == 2019. :])
18/16:
#Create a DataFrame that filters the data on only 2019.
filter_df = pd.DataFrame(state_avg.loc[state_avg["Year"] == 2019. :])
18/17:
#Create a DataFrame that filters the data on only 2019.
filter_df = pd.DataFrame(state_avg.loc[state_avg["Year"]== 2019. :])
18/18:
#Create a DataFrame that filters the data on only 2019.
filter_df = pd.DataFrame(outer_merge.loc[outer_merge["Year"]== 2019. :])
18/19: #Binning Moves
18/20:
 # Create a path to the csv and read it into a Pandas DataFrame
csv_path = "Resources/movie_scores.csv"
movies_df = pd.read_csv(csv_path)

movies_df.head()
18/21:
 # Create a path to the csv and read it into a Pandas DataFrame
csv_path = "/Users/Jerry/Downloads/movie_scores.csv"
movies_df = pd.read_csv(csv_path)

movies_df.head()
18/22:
# Figure out the minimum and maximum IMDB user vote count
max_IMDB = movies_df["IMDB_user_vote_count"]
18/23:
# Figure out the minimum and maximum IMDB user vote count
max_IMDB = movies_df["IMDB_user_vote_count"]
max_IMDB.max()
18/24:
# Figure out the minimum and maximum IMDB user vote count
max_IMDB = movies_df["FILM","IMDB_user_vote_count"]
max_IMDB.max()
18/25:
# Figure out the minimum and maximum IMDB user vote count
max_IMDB = movies_df["FILM","IMDB_user_vote_count"]
max_IMDB.max()
18/26:
# Figure out the minimum and maximum IMDB user vote count
max_IMDB = movies_df["IMDB_user_vote_count"]
max_IMDB.max()
18/27: max_IMDB.min()
18/28: max_IMDB.min()
18/29: x = 37130
18/30:
# Create bins in which to place values based upon IMDB vote count
bins = (0, 37130, 74260, 111390, 148520, 185650, 222780, 259910, 297040, 334170)

# Create labels for these bins
group_names = ("Least", "far far below median", "far below median", "below median", "Median", "above median", "far above median", "far far above median", "Most")
18/31:
# Slice the data and place it into bins
movies_df["IMDB_user_vote_count_summary"] = pd.cut(movies_df["IMDB_user_vote_count"], bins, labels = group_names,include_lowest = True)
18/32: movies_df
18/33: movies_df.head()
18/34:  # Create a GroupBy object based upon "IMDB User Votes Group"
18/35:
# Place the data series into a new column inside of the DataFrame
movies_df["IMDB_user_vote_count_summary"] = pd.cut(movies_df["IMDB_user_vote_count"], bins, labels = group_names,include_lowest = True)
movies_df[["FILM","IMDB_user_vote_count","IMDB_user_vote_count_summary"]].head()
19/1: import pandas as pd
19/2: import pandas as pd
19/3:
# The path to our CSV file
csv_file = /Users/Jerry/Downloads/CrowdfundingData.csv
# Read our Crowdfunding data into pandas
df = pd.read_csv("csv_file")
19/4:
# The path to our CSV file
csv_file = "/Users/Jerry/Downloads/CrowdfundingData.csv"
# Read our Crowdfunding data into pandas
df = pd.read_csv(csv_file)
19/5:
# The path to our CSV file
csv_file = "/Users/Jerry/Downloads/CrowdfundingData.csv"
# Read our Crowdfunding data into pandas
df = pd.read_csv(csv_file)
df
19/6:
# The path to our CSV file
csv_file = "/Users/Jerry/Downloads/CrowdfundingData.csv"
# Read our Crowdfunding data into pandas
df = pd.read_csv(csv_file)
19/7:
# Get a list of all of our columns for easy reference
df
19/8:
# Get a list of all of our columns for easy reference
df.columns
19/9:
# Extract "name", "goal", "pledged", "outcome", "country", "staff_pick",
# "backers_count", and "spotlight"
new_df = df[["name", "goal", "pledged", "outcome", "country", "staff_pick", "backers_count", "spotlight"]]
19/10:
# Extract "name", "goal", "pledged", "outcome", "country", "staff_pick",
# "backers_count", and "spotlight"
new_df = df[["name", "goal", "pledged", "outcome", "country", "staff_pick", "backers_count", "spotlight"]]
19/11:
# Remove projects that made no money at all
new_df
19/12:
# Remove projects that made no money at all
filter_df = new_df[[new_df["pledged"] > 0]]
19/13:
# Remove projects that made no money at all
filter_df = df[[df["pledged"] > 0]]
19/14:
# Remove projects that made no money at all
filter_df = new_df[new_df["pledged"] > 0]
19/15:
# Remove projects that made no money at all
filter_df = new_df[new_df["pledged"] > 0]
filter_df
19/16:
# Collect only those projects that were hosted in the US
us_df = filter_df[filterd_df[country] = "US"]
# Create a list of the columns
# Create a new df for "US" with the columns above.
19/17:
# Collect only those projects that were hosted in the US
us_df = filter_df[filterd_df[country] == "US"]
# Create a list of the columns
# Create a new df for "US" with the columns above.
19/18:
# Collect only those projects that were hosted in the US
us_df = filter_df[filter_df[country] == "US"]
# Create a list of the columns
# Create a new df for "US" with the columns above.
19/19:
# Collect only those projects that were hosted in the US
us_df = filter_df[filter_df["country"] == "US"]
# Create a list of the columns
# Create a new df for "US" with the columns above.
19/20:
# Collect only those projects that were hosted in the US
us_df = filter_df[filter_df["country"] == "US"]
us_df
# Create a list of the columns
# Create a new df for "US" with the columns above.
19/21:
# Collect only those projects that were hosted in the US
us_df = filter_df[filter_df["country"] == "US"]
us_df
# Create a list of the columns
columns_list = ('id', 'name', 'blurb', 'goal', 'pledged', 'outcome', 'backers_count',
       'country', 'currency', 'launched_at', 'deadline', 'staff_pick',
       'spotlight', 'category')
# Create a new df for "US" with the columns above.
19/22:
# Collect only those projects that were hosted in the US
us_df = filter_df[filter_df["country"] == "US"]

# Create a list of the columns
columns_list = ('id', 'name', 'blurb', 'goal', 'pledged', 'outcome', 'backers_count',
       'country', 'currency', 'launched_at', 'deadline', 'staff_pick',
       'spotlight', 'category')
# Create a new df for "US" with the columns above.
19/23:
# Collect only those projects that were hosted in the US
us_df = filter_df[filter_df["country"] == "US"]

# Create a list of the columns
columns_list = ('id', 'name', 'blurb', 'goal', 'pledged', 'outcome', 'backers_count',
       'country', 'currency', 'launched_at', 'deadline', 'staff_pick',
       'spotlight', 'category')
print(columns_list)
# Create a new df for "US" with the columns above.
19/24:
# Collect only those projects that were hosted in the US
us_df = filter_df[filter_df["country"] == "US"]
us_df
# Create a list of the columns
columns_list = ('id', 'name', 'blurb', 'goal', 'pledged', 'outcome', 'backers_count',
       'country', 'currency', 'launched_at', 'deadline', 'staff_pick',
       'spotlight', 'category')
# Create a new df for "US" with the columns above.
19/25:
# Collect only those projects that were hosted in the US
us_df = filter_df[filter_df["country"] == "US"]
us_df
# Create a list of the columns
columns_list = ('id', 'name', 'blurb', 'goal', 'pledged', 'outcome', 'backers_count',
       'country', 'currency', 'launched_at', 'deadline', 'staff_pick',
       'spotlight', 'category')
# Create a new df for "US" with the columns above.
19/26:
# Collect only those projects that were hosted in the US
us_df = filter_df[filter_df["country"] == "US"]
us_df.head()
# Create a list of the columns
columns_list = ('id', 'name', 'blurb', 'goal', 'pledged', 'outcome', 'backers_count',
       'country', 'currency', 'launched_at', 'deadline', 'staff_pick',
       'spotlight', 'category')
# Create a new df for "US" with the columns above.
19/27: import pandas as pd
19/28:
# The path to our CSV file
csv_file = "/Users/Jerry/Downloads/CrowdfundingData.csv"
# Read our Crowdfunding data into pandas
df = pd.read_csv(csv_file)
19/29:
# Get a list of all of our columns for easy reference
df.columns
19/30:
# Extract "name", "goal", "pledged", "outcome", "country", "staff_pick",
# "backers_count", and "spotlight"
new_df = df[["name", "goal", "pledged", "outcome", "country", "staff_pick", "backers_count", "spotlight"]]
19/31:
# Remove projects that made no money at all
filter_df = new_df[new_df["pledged"] > 0]
filter_df
19/32:
# Collect only those projects that were hosted in the US
us_df = filter_df[filter_df["country"] == "US"]

# Create a list of the columns
columns_list = ('id', 'name', 'blurb', 'goal', 'pledged', 'outcome', 'backers_count',
       'country', 'currency', 'launched_at', 'deadline', 'staff_pick',
       'spotlight', 'category')
# Create a new df for "US" with the columns above.
19/33:
# Collect only those projects that were hosted in the US
us_df = filter_df[filter_df["country"] == "US"]
us_df
19/34:
# Create a new column that finds the average amount pledged to a project
us_df["avg_pledge_per_project"] = us_df[us_df["pledged"]/us_df["backers_count"]]
19/35:
# Create a new column that finds the average amount pledged to a project
us_df["avg_pledge_per_project"] = us_df["pledged"]/us_df["backers_count"]
19/36:
# Create a new column that finds the average amount pledged to a project
us_df["avg_pledge_per_project"] = us_df[us_df["pledged"]/us_df["backers_count"]]
19/37:
# Create a new column that finds the average amount pledged to a project
us_df["avg_pledge_per_project"] = us_df[us_df["pledged"]/ \
                                        us_df["backers_count"]]
19/38:
# Create a new column that finds the average amount pledged to a project
us_new_df["avg_pledge_per_project"] = [us_df["pledged"]/ \ us_df["backers_count"]]
19/39:
# Create a new column that finds the average amount pledged to a project
us_new_df["avg_pledge_per_project"] = [us_df["pledged"]/ \ us_df["backers_count"]
20/1:
#import relevant modules
import pandas as pd
import os

csv_file = "/Users/Jerry/Documents/Homework/python-challenge/budget_data.csv"

#upload cvs file
pybank_df = pd.read_csv(csv_file)
20/2:
#py_bank_csv = pd.read_csv("C:\Users\19095\Downloads\budget_data.csv")
#SyntaxError: (unicode error) 'unicodeescape' codec can't decode bytes in position 2-3: truncated \UXXXXXXXX escape
#Solution found on: https://stackoverflow.com/questions/37400974/unicode-error-unicodeescape-codec-cant-decode-bytes-in-position-2-3-trunca
20/3:
#preview beginning and ending of csv file

pybank_df.head()
20/4:
file
with open(csv_file, 'r') as text:
    print(text)
    lines = text.read()
    print(lines)
20/5:
with open(csv_file, 'r') as text:
    print(text)
    lines = text.read()
    print(lines)
20/6:
file = "/Users/Jerry/Documents/Homework/python-challenge/pybank_python_homework.ipynb"
with open(file, 'r') as text:z
    print(text)
    lines = text.read()
    print(lines)
20/7:
file = "/Users/Jerry/Documents/Homework/python-challenge/pybank_python_homework.ipynb"
with open(file, 'r') as text:
    print(text)
    lines = text.read()
    print(lines)
20/8:
file = "/Users/Jerry/Documents/Homework/python-challenge/pybank_python_homework.ipynb"
with open(file, 'r') as text:
    print(text)
    lines = text.read()
    print(lines)
20/9:
file = "/Users/Jerry/Documents/Homework/python-challenge/pybank_python_textfile.txt"
with open(file, 'w') as text:
    text.write("Financial Analysis")
    text.write("--------------------------------------------")
    text.write("Total Months: " + str(month_count))
    text.write("Total: $" + str(net_total))
    text.write(f"Average Change: ${rounded}")
    text.write(f"Greatest Increase in Profits: Aug-16 ${greatest_positive_change}")
    text.write(f"Greatest decrease in Profits: Feb-14 ${greatest_negative_change}")
20/10:
print("Financial Analysis")
print("--------------------------------------------")
print("Total Months: " + str(month_count))
print("Total: $" + str(net_total))
print(f"Average Change: ${rounded}")
print(f"Greatest Increase in Profits: Aug-16 ${greatest_positive_change}")

print(f"Greatest decrease in Profits: Feb-14 ${greatest_negative_change}")
20/11:
#import relevant modules
import pandas as pd
import os

csv_file = "/Users/Jerry/Documents/Homework/python-challenge/budget_data.csv"

#upload cvs file
pybank_df = pd.read_csv(csv_file)
20/12:
#py_bank_csv = pd.read_csv("C:\Users\19095\Downloads\budget_data.csv")
#SyntaxError: (unicode error) 'unicodeescape' codec can't decode bytes in position 2-3: truncated \UXXXXXXXX escape
#Solution found on: https://stackoverflow.com/questions/37400974/unicode-error-unicodeescape-codec-cant-decode-bytes-in-position-2-3-trunca
20/13:
#preview beginning and ending of csv file

pybank_df.head()
20/14: pybank_df.tail()
20/15:
#Your task is to create a Python script that analyzes the records to calculate each of the following:
#The total number of months included in the dataset
pybank_df.columns
20/16:
print("Financial Analysis")
print("--------------------------------------------")
month_count = len(pybank_df["Date"].unique())
print("Total Months: " + str(month_count))
20/17:
#The net total amount of "Profit/Losses" over the entire period
net_total = pybank_df["Profit/Losses"].sum()
print("Total: $" + str(net_total))
20/18:
#The changes in "Profit/Losses" over the entire period
dif_bw_months = pybank_df["Profit/Losses"].diff()
print(dif_bw_months)
20/19:
#and then the average of those changes
avg_of_the_changes = dif_bw_months.mean()
rounded = round(avg_of_the_changes, 2)

print(f"Average Change: ${rounded}")
20/20:
#my attempt to create a df with the column Date and the new column dif_bw_months
dif_bw_months = pd.DataFrame(pybank_df["Date"]), pybank_df["Profit/Losses"].diff()
dif_bw_months
20/21:
#Finding the difference in profit/losses between months
dif_bw_months = pybank_df["Profit/Losses"].diff()
print(dif_bw_months)

#The greatest increase in profits (date and amount) over the entire period
greatest_positive_change = dif_bw_months.max()
greatest_positive_change
20/22:
#The greatest decrease in profits (date and amount) over the entire period
greatest_negative_change = dif_bw_months.min()
greatest_negative_change
20/23:
print("Financial Analysis")
print("--------------------------------------------")
print("Total Months: " + str(month_count))
print("Total: $" + str(net_total))
print(f"Average Change: ${rounded}")
print(f"Greatest Increase in Profits: Aug-16 ${greatest_positive_change}")

print(f"Greatest decrease in Profits: Feb-14 ${greatest_negative_change}")
20/24:
file = "/Users/Jerry/Documents/Homework/python-challenge/pybank_python_textfile.txt"
with open(file, 'w') as text:
    text.write("Financial Analysis")
    text.write("--------------------------------------------")
    text.write("Total Months: " + str(month_count))
    text.write("Total: $" + str(net_total))
    text.write(f"Average Change: ${rounded}")
    text.write(f"Greatest Increase in Profits: Aug-16 ${greatest_positive_change}")
    text.write(f"Greatest decrease in Profits: Feb-14 ${greatest_negative_change}")
20/25:
file = "/Users/Jerry/Documents/Homework/python-challenge/pybank_python_textfile.txt"
with open(file, 'w') as text:
    text.writelines("Financial Analysis")
    text.writelines("--------------------------------------------")
    text.writelines("Total Months: " + str(month_count))
    text.writelines("Total: $" + str(net_total))
    text.writelines(f"Average Change: ${rounded}")
    text.writelines(f"Greatest Increase in Profits: Aug-16 ${greatest_positive_change}")
    text.writelines(f"Greatest decrease in Profits: Feb-14 ${greatest_negative_change}")
20/26:
file = "/Users/Jerry/Documents/Homework/python-challenge/pybank_python_textfile.txt"
with open(file, 'w') as text:
    text.write("Financial Analysis\n")
    text.write("--------------------------------------------\n")
    text.write("Total Months: " + str(month_count) + "\n")
    text.write("Total: $" + str(net_total) + "\n")
    text.write(f"Average Change: ${rounded}\n")
    text.write(f"Greatest Increase in Profits: Aug-16 ${greatest_positive_change}\n")
    text.write(f"Greatest decrease in Profits: Feb-14 ${greatest_negative_change}\n")
21/1: #.py file to run in terminal
21/2:
#create text file for results
file = "pypoll_python_textfile.txt"
with open(file, 'w') as text:
    text.write("Election Results\n")
    text.write("--------------------------------------------\n")
    text.write("Total Votes: {total_votes}\n")
    text.write("--------------------------------------------\n")
    text.write(results_df.to_string(index = False)\n)
    text.write("--------------------------------------------\n")
    text.write(f"Winner: Diana DeGette - {max} votes\n")
    text.write("--------------------------------------------\n")
21/3:
#create text file for results
file = "pypoll_python_textfile.txt"
with open(file, 'w') as text:
    text.write("Election Results\n")
    text.write("--------------------------------------------\n")
    text.write("Total Votes: {total_votes}\n")
    text.write("--------------------------------------------\n")
    text.write(results_df.to_string(index = False))
    text.write("--------------------------------------------\n")
    text.write(f"Winner: Diana DeGette - {max} votes\n")
    text.write("--------------------------------------------\n")
21/4:
#PyPoll
#You are tasked with helping a small, rural town modernize its vote counting process.
21/5:
#import relevant modules
import pandas as pd

#import csv file
pypoll_df = pd.read_csv("/Users/Jerry/Documents/Homework/python-challenge/election_data.csv")

#print header for results
print("Election Results")
print("----------------------------------------------")
21/6:
#summarize the top and the bottom of the csv file
pypoll_df.head()
21/7: pypoll_df.tail()
21/8: pypoll_df.columns
21/9:
#The total number of votes cast
total_votes = len(pypoll_df["Ballot ID"].unique())
print(f"Total Votes: {total_votes}")
print("----------------------------------------------")
21/10:
#A complete list of candidates who received votes
candidate_voted_for = pypoll_df["Candidate"].unique()
print(candidate_voted_for)
21/11:
#The percentage of votes each candidate won
candidate_vote_percent = pypoll_df["Candidate"].value_counts(normalize = True)
candidate_vote_percent.head()
21/12:
#The total number of votes each candidate won
candidate_vote_count = pypoll_df["Candidate"].value_counts()
candidate_vote_count.head()
21/13:
#create total variables
dtotal = (f"({272892})")
ctotal = (f"({85213})")
rtotal = (f"({11606})")

#create variabes for candidate percentages
diana_dec = round(((0.738122) *100), 3)
charles_dec = round(((0.230485) *100), 3)
raymon_dec = round(((0.031392) *100), 3)

#add percent signs to percentages
dper = (f"%{diana_dec}")
cper = (f"%{charles_dec}")
rper = (f"%{raymon_dec}")
21/14:
#create dict for results section
result_info = {"Candidates": ["Diana DeGette:", "Charles Casper Stockham:", "Raymon Anthony Doane:"],
                "Percentage of Votes": [dper, cper, rper],
               "Total votes": [dtotal, ctotal, rtotal]}

#dataframe created by the dictionaries named result_info
results_df = pd.DataFrame.from_dict(result_info)
results_df
21/15:
#the winner based off of popular votes
max = candidate_vote_count.max()
print("----------------------------------------------")
print(f"Winner: Diana DeGette - {max} votes")
21/16:
#final election result sheet
print("Election Results")
print("----------------------------------------------")
print(f"Total Votes: {total_votes}")
print("----------------------------------------------")
print(results_df.to_string(index = False))
print("----------------------------------------------")
print(f"Winner: Diana DeGette - {max} votes")
print("----------------------------------------------")
21/17: #.py file to run in terminal
21/18:
#create text file for results
file = "pypoll_python_textfile.txt"
with open(file, 'w') as text:
    text.write("Election Results\n")
    text.write("--------------------------------------------\n")
    text.write("Total Votes: {total_votes}\n")
    text.write("--------------------------------------------\n")
    text.write(results_df.to_string(index = False))
    text.write("--------------------------------------------\n")
    text.write(f"Winner: Diana DeGette - {max} votes\n")
    text.write("--------------------------------------------\n")
21/19: results = (results_df.to_string(index = False))
21/20:
#final election result sheet
print("Election Results")
print("----------------------------------------------")
print(f"Total Votes: {total_votes}")
print("----------------------------------------------")
#print(results_df.to_string(index = False))
print(f"{results}")
print("----------------------------------------------")
print(f"Winner: Diana DeGette - {max} votes")
print("----------------------------------------------")
21/21:
#create text file for results
file = "pypoll_python_textfile.txt"
with open(file, 'w') as text:
    text.write("Election Results\n")
    text.write("--------------------------------------------\n")
    text.write("Total Votes: {total_votes}\n")
    text.write("--------------------------------------------\n")
    #text.write(results_df.to_string(index = False))
    text.write(f"{results}\n")
    text.write("--------------------------------------------\n")
    text.write(f"Winner: Diana DeGette - {max} votes\n")
    text.write("--------------------------------------------\n")
22/1: #Activities
22/2:
#import important modules
import numpy as np
import matplotlib.pyplot as plt
22/3:
#create the list of average temps
avg_temps = [39, 42, 51, 62, 72, 82, 86, 84, 77, 65, 55, 44]

x_axis = np.array(0,12, 1.0)
22/4:
#create the list of average temps
avg_temps = [39, 42, 51, 62, 72, 82, 86, 84, 77, 65, 55, 44]

x_axis = np.arange(0, 12, 1.0)
22/5: plt.plot(avg_temps)
22/6: plt.plot(avg_temps, x_axis)
22/7: plt.plot(x_axis, avg_temps)
22/8:
#use list comprehension to convert fahrenheit to celsius
avg_celsius = []
for temp in avg_temps:
    if temp in avg_temps:
        newlist.append((temp - 32) * 56)
22/9:
#use list comprehension to convert fahrenheit to celsius
avg_celsius = []
for temp in avg_temps:
    if temp in avg_temps:
        avg_celsius.append((temp - 32) * 56)
22/10:
#use list comprehension to convert fahrenheit to celsius
avg_celsius = []
for temp in avg_temps:
    if temp in avg_temps:
        avg_celsius.append((temp - 32) * 56)

avg_celsius
22/11:
#use list comprehension to convert fahrenheit to celsius
avg_celsius = []
for temp in avg_temps:
    if temp in avg_temps:
        avg_celsius.append((temp - 32) * .56)

avg_celsius
22/12:
#use list comprehension to convert fahrenheit to celsius
avg_celsius = []
for temp in avg_temps:
    if temp in avg_temps:
        avg_celsius.append((temp - 32) * .56)

avg_celsius = round(avg_celsius, 2)
22/13:
#use list comprehension to convert fahrenheit to celsius
avg_celsius = []
for temp in avg_temps:
    if temp in avg_temps:
        avg_celsius.append((temp - 32) * .56)

avg_celsius
22/14:
#add avg_celsius to the line graph
plt.plot(avg_temps, avg_celsius)
22/15: avg_temp_cel = [((x-32)*0.56) for x in avg_temps]
22/16:
avg_temp_cel = [((x-32)*0.56) for x in avg_temps]
avg_temp_cel
22/17:
#add avg_celsius to the line graph
plt.plot((avg_temps), (avg_celsius))
22/18:
#add avg_celsius to the line graph
plt.plot(avg_temps, avg_celsius)
22/19:
#add avg_celsius to the line graph
plt.plot(avg_temps)
plt.plot(avg_celsius)
22/20:
#add avg_celsius to the line graph
plt.plot(x_axis, avg_temps)
plt.plot(x_axis, avg_celsius)
22/21:
#add avg_celsius to the line graph
plt.plot(x_axis, avg_temps)
plt.plot(x_axis, avg_celsius)
plt.show()
22/22:
# Give our graph axis labels
plt.xlabel("Degrees")
22/23:
#add avg_celsius to the line graph
plt.plot(x_axis, avg_temps)
plt.plot(x_axis, avg_celsius)
plt.xlabel("Degrees")
plt.ylabel("Months")
22/24:
#add avg_celsius to the line graph
plt.plot(x_axis, avg_temps)
plt.plot(x_axis, avg_celsius)
plt.xlabel("Degrees")
plt.ylabel("Months")
plt.title("Average Temperature Per Month")
22/25:
#add avg_celsius to the line graph
plt.plot(x_axis, avg_temps, marker = "o", color = 'blue', label = "fahrenheit")
plt.plot(x_axis, avg_celsius, marker = "^", color = "red", label = "celsius")
#add labels to axes and a title to the graph
plt.xlabel("Degrees")
plt.ylabel("Months")
plt.title("Average Temperature Per Month")
#add point markers and a lengend
22/26:
#add avg_celsius to the line graph
fahrenheit_handle = plt.plot(x_axis, avg_temps, marker = "o", color = 'blue', label = "fahrenheit")
celsius_handle = plt.plot(x_axis, avg_celsius, marker = "^", color = "red", label = "celsius")
#add labels to axes and a title to the graph
plt.xlabel("Degrees")
plt.ylabel("Months")
plt.title("Average Temperature Per Month")
#add point markers and a lengend
22/27:
#add avg_celsius to the line graph
fahrenheit_handle = plt.plot(x_axis, avg_temps, marker = "o", color = 'blue', label = "fahrenheit")
celsius_handle = plt.plot(x_axis, avg_celsius, marker = "^", color = "red", label = "celsius")
#add labels to axes and a title to the graph
plt.xlabel("Degrees")
plt.ylabel("Months")
plt.title("Average Temperature Per Month")
#add point markers and a lengend
plt.legend (loc = "Upper right")
22/28:
#add avg_celsius to the line graph
fahrenheit_handle = plt.plot(x_axis, avg_temps, marker = "o", color = 'blue', label = "fahrenheit")
celsius_handle = plt.plot(x_axis, avg_celsius, marker = "^", color = "red", label = "celsius")
#add labels to axes and a title to the graph
plt.xlabel("Degrees")
plt.ylabel("Months")
plt.title("Average Temperature Per Month")
#add point markers and a lengend
plt.legend (loc = "upper right")
22/29:
#add avg_celsius to the line graph
fahrenheit_handle = plt.plot(x_axis, avg_temps, marker = "o", color = 'blue', label = "fahrenheit")
celsius_handle = plt.plot(x_axis, avg_celsius, marker = "^", color = "red", label = "celsius")
#add labels to axes and a title to the graph
plt.xlabel("Degrees")
plt.ylabel("Months")
plt.title("Average Temperature Per Month")
#add point markers and a lengend
plt.legend (loc = "upper right")

#add a horizontal line
plt.hlines(25, 0, 10, alpha=0.025)
22/30:
#add avg_celsius to the line graph
fahrenheit_handle = plt.plot(x_axis, avg_temps, marker = "o", color = 'blue', label = "fahrenheit")
celsius_handle = plt.plot(x_axis, avg_celsius, marker = "^", color = "red", label = "celsius")
#add labels to axes and a title to the graph
plt.xlabel("Degrees")
plt.ylabel("Months")
plt.title("Average Temperature Per Month")
#add point markers and a lengend
plt.legend (loc = "upper right")

#add a horizontal line
plt.hlines(0, 0, 10, alpha=0.025)
22/31:
#add avg_celsius to the line graph
fahrenheit_handle = plt.plot(x_axis, avg_temps, marker = "o", color = 'blue', label = "fahrenheit")
celsius_handle = plt.plot(x_axis, avg_celsius, marker = "^", color = "red", label = "celsius")
#add labels to axes and a title to the graph
plt.xlabel("Degrees")
plt.ylabel("Months")
plt.title("Average Temperature Per Month")
#add point markers and a lengend
plt.legend (loc = "upper right")

#add a horizontal line
plt.hlines(0, 25, 10, alpha=0.025)
22/32:
#add avg_celsius to the line graph
fahrenheit_handle = plt.plot(x_axis, avg_temps, marker = "o", color = 'blue', label = "fahrenheit")
celsius_handle = plt.plot(x_axis, avg_celsius, marker = "^", color = "red", label = "celsius")
#add labels to axes and a title to the graph
plt.xlabel("Degrees")
plt.ylabel("Months")
plt.title("Average Temperature Per Month")
#add point markers and a lengend
plt.legend (loc = "upper right")

#add a horizontal line
plt.hlines(0, 0, 10, alpha=0.025)
22/33:
#add avg_celsius to the line graph
fahrenheit_handle = plt.plot(x_axis, avg_temps, marker = "o", color = 'blue', label = "fahrenheit")
celsius_handle = plt.plot(x_axis, avg_celsius, marker = "s", color = "red", label = "celsius")
#add labels to axes and a title to the graph
plt.xlabel("Degrees")
plt.ylabel("Months")
plt.title("Average Temperature Per Month")
#add point markers and a lengend
plt.legend (loc = "upper right")

#add a horizontal line
plt.hlines(0, 0, 10, alpha=0.025)
22/34:
#add avg_celsius to the line graph
fahrenheit_handle = plt.plot(x_axis, avg_temps, marker = "o", color = 'blue', label = "fahrenheit")
celsius_handle = plt.plot(x_axis, avg_celsius, marker = "x", color = "red", label = "celsius")
#add labels to axes and a title to the graph
plt.xlabel("Degrees")
plt.ylabel("Months")
plt.title("Average Temperature Per Month")
#add point markers and a lengend
plt.legend (loc = "upper right")

#add a horizontal line
plt.hlines(0, 0, 10, alpha=0.025)
22/35:
#add avg_celsius to the line graph
fahrenheit_handle = plt.plot(x_axis, avg_temps, marker = "o", color = 'blue', label = "fahrenheit")
celsius_handle = plt.plot(x_axis, avg_celsius, marker = "w", color = "red", label = "celsius")
#add labels to axes and a title to the graph
plt.xlabel("Degrees")
plt.ylabel("Months")
plt.title("Average Temperature Per Month")
#add point markers and a lengend
plt.legend (loc = "upper right")

#add a horizontal line
plt.hlines(0, 0, 10, alpha=0.025)
22/36:
#add avg_celsius to the line graph
fahrenheit_handle = plt.plot(x_axis, avg_temps, marker = "o", color = 'blue', label = "fahrenheit")
celsius_handle = plt.plot(x_axis, avg_celsius, marker = "+", color = "red", label = "celsius")
#add labels to axes and a title to the graph
plt.xlabel("Degrees")
plt.ylabel("Months")
plt.title("Average Temperature Per Month")
#add point markers and a lengend
plt.legend (loc = "upper right")

#add a horizontal line
plt.hlines(0, 0, 10, alpha=0.025)
22/37:
#add avg_celsius to the line graph
fahrenheit_handle = plt.plot(x_axis, avg_temps, marker = "o", color = 'blue', label = "fahrenheit")
celsius_handle = plt.plot(x_axis, avg_celsius, marker = "*", color = "red", label = "celsius")
#add labels to axes and a title to the graph
plt.xlabel("Degrees")
plt.ylabel("Months")
plt.title("Average Temperature Per Month")
#add point markers and a lengend
plt.legend (loc = "upper right")

#add a horizontal line
plt.hlines(0, 0, 10, alpha=0.025)
22/38:
#add avg_celsius to the line graph
fahrenheit_handle = plt.plot(x_axis, avg_temps, marker = "#", color = 'blue', label = "fahrenheit")
celsius_handle = plt.plot(x_axis, avg_celsius, marker = "*", color = "red", label = "celsius")
#add labels to axes and a title to the graph
plt.xlabel("Degrees")
plt.ylabel("Months")
plt.title("Average Temperature Per Month")
#add point markers and a lengend
plt.legend (loc = "upper right")

#add a horizontal line
plt.hlines(0, 0, 10, alpha=0.025)
22/39:
#add avg_celsius to the line graph
fahrenheit_handle = plt.plot(x_axis, avg_temps, marker = "^", color = 'blue', label = "fahrenheit")
celsius_handle = plt.plot(x_axis, avg_celsius, marker = "*", color = "red", label = "celsius")
#add labels to axes and a title to the graph
plt.xlabel("Degrees")
plt.ylabel("Months")
plt.title("Average Temperature Per Month")
#add point markers and a lengend
plt.legend (loc = "upper right")

#add a horizontal line
plt.hlines(0, 0, 10, alpha=0.025)
22/40:
#add avg_celsius to the line graph
fahrenheit_handle = plt.plot(x_axis, avg_temps, marker = "o", color = 'blue', label = "fahrenheit")
celsius_handle = plt.plot(x_axis, avg_celsius, marker = "*", color = "red", label = "celsius")
#add labels to axes and a title to the graph
plt.xlabel("Degrees")
plt.ylabel("Months")
plt.title("Average Temperature Per Month")
#add point markers and a lengend
plt.legend (loc = "upper right")

#add a horizontal line
plt.hlines(0, 0, 10, alpha=0.025)
22/41:
#add avg_celsius to the line graph
fahrenheit_handle = plt.plot(x_axis, avg_temps, marker = "o", color = 'green', label = "fahrenheit")
celsius_handle = plt.plot(x_axis, avg_celsius, marker = "*", color = "red", label = "celsius")
#add labels to axes and a title to the graph
plt.xlabel("Degrees")
plt.ylabel("Months")
plt.title("Average Temperature Per Month")
#add point markers and a lengend
plt.legend (loc = "upper right")

#add a horizontal line
plt.hlines(0, 0, 10, alpha=0.025)
22/42:
#add avg_celsius to the line graph
fahrenheit_handle = plt.plot(x_axis, avg_temps, marker = "o", color = 'green', label = "fahrenheit")
celsius_handle = plt.plot(x_axis, avg_celsius, marker = "*", color = "purple", label = "celsius")
#add labels to axes and a title to the graph
plt.xlabel("Degrees")
plt.ylabel("Months")
plt.title("Average Temperature Per Month")
#add point markers and a lengend
plt.legend (loc = "upper right")

#add a horizontal line
plt.hlines(0, 0, 10, alpha=0.025)
22/43:
#add avg_celsius to the line graph
fahrenheit_handle = plt.plot(x_axis, avg_temps, marker = "o", color = 'green', label = "fahrenheit")
celsius_handle = plt.plot(x_axis, avg_celsius, marker = "*", color = "purple", label = "celsius")
#add labels to axes and a title to the graph
plt.xlabel("Degrees")
plt.ylabel("Months")
plt.title("Average Temperature Per Month")
#add point markers and a lengend
plt.legend (loc = "upper right")

#add a horizontal line
plt.hlines(25, 0, 10, alpha=0.025)
22/44:
#add avg_celsius to the line graph
fahrenheit_handle = plt.plot(x_axis, avg_temps, marker = "o", color = 'green', label = "fahrenheit")
celsius_handle = plt.plot(x_axis, avg_celsius, marker = "*", color = "purple", label = "celsius")
#add labels to axes and a title to the graph
plt.xlabel("Degrees")
plt.ylabel("Months")
plt.title("Average Temperature Per Month")
#add point markers and a lengend
plt.legend (loc = "upper right")

#add a horizontal line
plt.hlines(25, 0, 10, alpha=0.25)
22/45:
#add avg_celsius to the line graph
fahrenheit_handle = plt.plot(x_axis, avg_temps, marker = "o", color = 'green', label = "fahrenheit")
celsius_handle = plt.plot(x_axis, avg_celsius, marker = "*", color = "purple", label = "celsius")
#add labels to axes and a title to the graph
plt.xlabel("Degrees")
plt.ylabel("Months")
plt.title("Average Temperature Per Month")
#add point markers and a lengend
plt.legend (loc = "upper right")

#add a horizontal line
plt.hlines(25, 0, 10, alpha=0.5)
22/46:
#add avg_celsius to the line graph
fahrenheit_handle = plt.plot(x_axis, avg_temps, marker = "o", color = 'green', label = "fahrenheit")
celsius_handle = plt.plot(x_axis, avg_celsius, "bo")
#celsius_handle = plt.plot(x_axis, avg_celsius, marker = "*", color = "purple", label = "celsius")
#add labels to axes and a title to the graph
plt.xlabel("Degrees")
plt.ylabel("Months")
plt.title("Average Temperature Per Month")
#add point markers and a lengend
plt.legend (loc = "upper right")

#add a horizontal line
plt.hlines(25, 0, 10, alpha=0.5)
22/47:
#add avg_celsius to the line graph
fahrenheit_handle = plt.plot(x_axis, avg_temps, marker = "o", color = 'green', label = "fahrenheit")
celsius_handle = plt.plot(x_axis, avg_celsius, "r+")
#celsius_handle = plt.plot(x_axis, avg_celsius, marker = "*", color = "purple", label = "celsius")
#add labels to axes and a title to the graph
plt.xlabel("Degrees")
plt.ylabel("Months")
plt.title("Average Temperature Per Month")
#add point markers and a lengend
plt.legend (loc = "upper right")

#add a horizontal line
plt.hlines(25, 0, 10, alpha=0.5)
22/48:
#add avg_celsius to the line graph
fahrenheit_handle = plt.plot(x_axis, avg_temps, marker = "o", color = 'green', label = "fahrenheit")
celsius_handle = plt.plot(x_axis, avg_celsius, "r+")
#celsius_handle = plt.plot(x_axis, avg_celsius, marker = "*", color = "purple", label = "celsius")
#add labels to axes and a title to the graph
plt.xlabel("Degrees")
plt.ylabel("Months")
plt.title("Average Temperature Per Month")
#add point markers and a lengend
plt.legend (loc = "upper right")

#add a horizontal line
plt.hlines(25, 0, 12, alpha=0.5)
22/49:
#add avg_celsius to the line graph
fahrenheit_handle = plt.plot(x_axis, avg_temps, marker = "o", color = 'green', label = "fahrenheit")
celsius_handle = plt.plot(x_axis, avg_celsius, "r+")
#celsius_handle = plt.plot(x_axis, avg_celsius, marker = "*", color = "purple", label = "celsius")
#add labels to axes and a title to the graph
plt.xlabel("Degrees")
plt.ylabel("Months")
plt.title("Average Temperature Per Month")
#add point markers and a lengend
plt.legend (loc = "upper right")

#add a horizontal line
plt.hlines(30, 0, 12, alpha=0.5)
22/50:
#add avg_celsius to the line graph
fahrenheit_handle = plt.plot(x_axis, avg_temps, marker = "o", color = 'green', label = "fahrenheit")
celsius_handle = plt.plot(x_axis, avg_celsius, "r+")
#celsius_handle = plt.plot(x_axis, avg_celsius, marker = "*", color = "purple", label = "celsius")
#add labels to axes and a title to the graph
plt.xlabel("Degrees")
plt.ylabel("Months")
plt.title("Average Temperature Per Month")
#add point markers and a lengend
plt.legend (loc = "upper right")

#add a horizontal line
plt.hlines(35, 0, 12, alpha=0.5)
22/51:
#Create two lists
Danger Drop: [9, 8, 90, 85, 80, 70, 70, 65, 55, 60, 70, 65, 50]
RailGun: [75, 70, 60, 65, 60, 45, 55, 50, 40, 40, 35, 35, 30]
22/52:
#Create two lists
Danger_Drop: [9, 8, 90, 85, 80, 70, 70, 65, 55, 60, 70, 65, 50]
Rail_Gun: [75, 70, 60, 65, 60, 45, 55, 50, 40, 40, 35, 35, 30]
22/53:
#Create two lists
Danger_Drop: [9, 8, 90, 85, 80, 70, 70, 65, 55, 60, 70, 65, 50]
Rail_Gun: [75, 70, 60, 65, 60, 45, 55, 50, 40, 40, 35, 35, 30]
#create x axis
x_axis2 = np.arrange(0, 13, 1.0)

py.plot(x_axis2, Danger_Drop)
22/54:
#import important modules
import numpy as np
import matplotlib.pyplot as plt
22/55:
#Create two lists
Danger_Drop: [9, 8, 90, 85, 80, 70, 70, 65, 55, 60, 70, 65, 50]
Rail_Gun: [75, 70, 60, 65, 60, 45, 55, 50, 40, 40, 35, 35, 30]
#create x axis
x_axis2 = np.arange(0, 13, 1.0)

py.plot(x_axis2, Danger_Drop)
22/56:
#import important modules
import numpy as np
import matplotlib.pyplot as plt
22/57:
#create the list of average temps
avg_temps = [39, 42, 51, 62, 72, 82, 86, 84, 77, 65, 55, 44]

x_axis = np.arange(0, 12, 1.0)
22/58:
#plot the avg_temps list
plt.plot(avg_temps)
22/59:
#Create two lists
Danger_Drop: [9, 8, 90, 85, 80, 70, 70, 65, 55, 60, 70, 65, 50]
Rail_Gun: [75, 70, 60, 65, 60, 45, 55, 50, 40, 40, 35, 35, 30]
#create x axis
x_axis2 = np.arange(0, 13, 1.0)

plt.plot(x_axis2, Danger_Drop)
22/60:
#Create two lists
Danger_Drop = [9, 8, 90, 85, 80, 70, 70, 65, 55, 60, 70, 65, 50]
Rail_Gun = [75, 70, 60, 65, 60, 45, 55, 50, 40, 40, 35, 35, 30]
#create x axis
x_axis2 = np.arange(0, 13, 1.0)

plt.plot(x_axis2, Danger_Drop)
22/61:
#Create two lists
Danger_Drop = [9, 8, 90, 85, 80, 70, 70, 65, 55, 60, 70, 65, 50]
Rail_Gun = [75, 70, 60, 65, 60, 45, 55, 50, 40, 40, 35, 35, 30]
#create x axis
x_axis2 = np.arange(0, 13, 1.0)

plt.plot(x_axis2, Danger_Drop)
plt.plot(x_axis2, Rail_Gun)
22/62:
#Create two lists
Danger_Drop = [9, 8, 90, 85, 80, 70, 70, 65, 55, 60, 70, 65, 50]
Rail_Gun = [75, 70, 60, 65, 60, 45, 55, 50, 40, 40, 35, 35, 30]
#create x axis
x_axis2 = np.arange(0, 120, 10.0)

plt.plot(x_axis2, Danger_Drop)
plt.plot(x_axis2, Rail_Gun)

plt.xlabel
22/63:
#Create two lists
Danger_Drop = [9, 8, 90, 85, 80, 70, 70, 65, 55, 60, 70, 65, 50]
Rail_Gun = [75, 70, 60, 65, 60, 45, 55, 50, 40, 40, 35, 35, 30]
#create x axis
x_axis2 = np.arange(0, 120, 10.0)

plt.plot(x_axis2, Danger_Drop)
plt.plot(x_axis2, Rail_Gun)

plt.xlabel
22/64:
#Create two lists
Danger_Drop = [9, 8, 90, 85, 80, 70, 70, 65, 55, 60, 70, 65, 50]
Rail_Gun = [75, 70, 60, 65, 60, 45, 55, 50, 40, 40, 35, 35, 30]
#create x axis
x_axis2 = np.arange(0, 120, 10.0)

plt.plot(x_axis2, Danger_Drop)
plt.plot(x_axis2, Rail_Gun)
22/65:
#Create two lists
Danger_Drop = [9, 8, 90, 85, 80, 70, 70, 65, 55, 60, 70, 65, 50]
Rail_Gun = [75, 70, 60, 65, 60, 45, 55, 50, 40, 40, 35, 35, 30]
#create x axis
x_axis2 = np.arange(0, 12, 1.0)

plt.plot(x_axis2, Danger_Drop)
plt.plot(x_axis2, Rail_Gun)
22/66:
#import important modules
import numpy as np
import matplotlib.pyplot as plt
22/67:
#create the list of average temps
avg_temps = [39, 42, 51, 62, 72, 82, 86, 84, 77, 65, 55, 44]

x_axis = np.arange(0, 12, 1.0)
22/68:
#Create two lists
Danger_Drop = [9, 8, 90, 85, 80, 70, 70, 65, 55, 60, 70, 65, 50]
Rail_Gun = [75, 70, 60, 65, 60, 45, 55, 50, 40, 40, 35, 35, 30]
#create x axis
x_axis2 = np.arange(0, 13, 1.0)

plt.plot(x_axis2, Danger_Drop)
plt.plot(x_axis2, Rail_Gun)
22/69:
#Create two lists
Danger_Drop = [9, 8, 90, 85, 80, 70, 70, 65, 55, 60, 70, 65, 50]
Rail_Gun = [75, 70, 60, 65, 60, 45, 55, 50, 40, 40, 35, 35, 30]
#create x axis
x_axis2 = np.arange(0, 13, 1.0)

plt.plot(x_axis2, Danger_Drop)
plt.plot(x_axis2, Rail_Gun)

#create labels
plt.xlabel = ("Time")
plt.ylabel = ("Speed")
plt.title = Roller Coaster Speed
22/70:
#Create two lists
Danger_Drop = [9, 8, 90, 85, 80, 70, 70, 65, 55, 60, 70, 65, 50]
Rail_Gun = [75, 70, 60, 65, 60, 45, 55, 50, 40, 40, 35, 35, 30]
#create x axis
x_axis2 = np.arange(0, 13, 1.0)

plt.plot(x_axis2, Danger_Drop)
plt.plot(x_axis2, Rail_Gun)

#create labels
plt.xlabel = ("Time")
plt.ylabel = ("Speed")
plt.title = ("Roller Coaster Speed")
22/71:
#Create two lists
Danger_Drop = [9, 8, 90, 85, 80, 70, 70, 65, 55, 60, 70, 65, 50]
Rail_Gun = [75, 70, 60, 65, 60, 45, 55, 50, 40, 40, 35, 35, 30]
#create x axis
x_axis2 = np.arange(0, 13, 1.0)

plt.plot(x_axis2, Danger_Drop)
plt.plot(x_axis2, Rail_Gun)

#create labels
plt.xlabel = ("Time")
plt.ylabel = ("Speed")
plt.title = ("Roller Coaster Speed")
22/72:
#add avg_celsius to the line graph
fahrenheit_handle = plt.plot(x_axis, avg_temps, marker = "o", color = 'green', label = "fahrenheit")
#celsius_handle = plt.plot(x_axis, avg_celsius, "r+")
celsius_handle = plt.plot(x_axis, avg_celsius, marker = "*", color = "purple", label = "celsius")
#add labels to axes and a title to the graph
plt.xlabel("Degrees")
plt.ylabel("Months")
plt.title("Average Temperature Per Month")
#add point markers and a lengend
plt.legend (loc = "upper right")

#add a horizontal line
plt.hlines(35, 0, 12, alpha=0.5)
22/73:
#Create two lists
Danger_Drop = [9, 8, 90, 85, 80, 70, 70, 65, 55, 60, 70, 65, 50]
Rail_Gun = [75, 70, 60, 65, 60, 45, 55, 50, 40, 40, 35, 35, 30]
#create x axis
x_axis2 = np.arange(0, 13, 1.0)

plt.plot(x_axis2, Danger_Drop)
plt.plot(x_axis2, Rail_Gun)

#create labels
plt.xlabel = ("Time")
plt.ylabel = ("Speed")
plt.title = ("Roller Coaster Speed")
22/74:
#add avg_celsius to the line graph
fahrenheit_handle = plt.plot(x_axis, avg_temps, marker = "o", color = 'green', label = "fahrenheit")
#celsius_handle = plt.plot(x_axis, avg_celsius, "r+")
celsius_handle = plt.plot(x_axis, avg_celsius, marker = "*", color = "purple", label = "celsius")
#add labels to axes and a title to the graph
plt.xlabel("Degrees")
plt.ylabel("Months")
plt.title("Average Temperature Per Month")
#add point markers and a lengend
plt.legend (loc = "upper right")

#add a horizontal line
plt.hlines(35, 0, 12, alpha=0.5)
22/75:
#import important modules
import numpy as np
import matplotlib.pyplot as plt
22/76:
#create the list of average temps
avg_temps = [39, 42, 51, 62, 72, 82, 86, 84, 77, 65, 55, 44]

x_axis = np.arange(0, 12, 1.0)
22/77:
#plot the avg_temps list
plt.plot(avg_temps)
22/78:
#use list comprehension to convert fahrenheit to celsius
avg_celsius = []
for temp in avg_temps:
    if temp in avg_temps:
        avg_celsius.append((temp - 32) * .56)

avg_celsius
22/79:
#add avg_celsius to the line graph
fahrenheit_handle = plt.plot(x_axis, avg_temps, marker = "o", color = 'green', label = "fahrenheit")
#celsius_handle = plt.plot(x_axis, avg_celsius, "r+")
celsius_handle = plt.plot(x_axis, avg_celsius, marker = "*", color = "purple", label = "celsius")
#add labels to axes and a title to the graph
plt.xlabel("Degrees")
plt.ylabel("Months")
plt.title("Average Temperature Per Month")
#add point markers and a lengend
plt.legend (loc = "upper right")

#add a horizontal line
plt.hlines(35, 0, 12, alpha=0.5)
22/80:
#add avg_celsius to the line graph
fahrenheit_handle = plt.plot(x_axis, avg_temps, marker = "o", color = 'green', label = "fahrenheit")
#celsius_handle = plt.plot(x_axis, avg_celsius, "r+")
celsius_handle = plt.plot(x_axis, avg_celsius, marker = "*", color = "purple", label = "celsius")
#add labels to axes and a title to the graph
plt.xlabel("Degrees")
plt.ylabel("Months")
plt.title("Average Temperature Per Month")
#add point markers and a lengend
plt.legend (loc = "upper right")

#add a horizontal line
plt.hlines(35, 0, 12, alpha=0.5)
22/81:
#import important modules
import numpy as np
import matplotlib.pyplot as plt
22/82:
#create the list of average temps
avg_temps = [39, 42, 51, 62, 72, 82, 86, 84, 77, 65, 55, 44]

x_axis = np.arange(0, 12, 1.0)
22/83:
#plot the avg_temps list
plt.plot(avg_temps)
22/84:
#use list comprehension to convert fahrenheit to celsius
avg_celsius = []
for temp in avg_temps:
    if temp in avg_temps:
        avg_celsius.append((temp - 32) * .56)

avg_celsius
22/85:
#add avg_celsius to the line graph
fahrenheit_handle = plt.plot(x_axis, avg_temps, marker = "o", color = 'green', label = "fahrenheit")
#celsius_handle = plt.plot(x_axis, avg_celsius, "r+")
celsius_handle = plt.plot(x_axis, avg_celsius, marker = "*", color = "purple", label = "celsius")
#add labels to axes and a title to the graph
plt.xlabel("Degrees")
plt.ylabel("Months")
plt.title("Average Temperature Per Month")
#add point markers and a lengend
plt.legend (loc = "upper right")

#add a horizontal line
plt.hlines(35, 0, 12, alpha=0.5)
22/86: #points_C = [(x-32) * .56 for x in x in points]
22/87:
#Create two lists
#Danger_Drop = [9, 8, 90, 85, 80, 70, 70, 65, 55, 60, 70, 65, 50]
#Rail_Gun = [75, 70, 60, 65, 60, 45, 55, 50, 40, 40, 35, 35, 30]
#create x axis
#x_axis2 = np.arange(0, 13, 1.0)

#plt.plot(x_axis2, Danger_Drop)
#plt.plot(x_axis2, Rail_Gun)

#create labels
#plt.xlabel = ("Time")
#plt.ylabel = ("Speed")
#plt.title = ("Roller Coaster Speed")
22/88:
#import important modules
import numpy as np
import matplotlib.pyplot as plt
22/89:
#create the list of average temps
avg_temps = [39, 42, 51, 62, 72, 82, 86, 84, 77, 65, 55, 44]

x_axis = np.arange(0, 12, 1.0)
22/90:
#plot the avg_temps list
plt.plot(avg_temps)
22/91:
#use list comprehension to convert fahrenheit to celsius
avg_celsius = []
for temp in avg_temps:
    if temp in avg_temps:
        avg_celsius.append((temp - 32) * .56)

avg_celsius
22/92:
#add avg_celsius to the line graph
fahrenheit_handle = plt.plot(x_axis, avg_temps, marker = "o", color = 'green', label = "fahrenheit")
#celsius_handle = plt.plot(x_axis, avg_celsius, "r+")
celsius_handle = plt.plot(x_axis, avg_celsius, marker = "*", color = "purple", label = "celsius")
#add labels to axes and a title to the graph
plt.xlabel("Degrees")
plt.ylabel("Months")
plt.title("Average Temperature Per Month")
#add point markers and a lengend
plt.legend (loc = "upper right")

#add a horizontal line
plt.hlines(35, 0, 12, alpha=0.5)
22/93:
#add avg_celsius to the line graph
fahrenheit_handle = plt.plot(x_axis, avg_temps, marker = "o", color = 'green', label = "fahrenheit")
#celsius_handle = plt.plot(x_axis, avg_celsius, "r+")
celsius_handle = plt.plot(x_axis, avg_celsius, marker = "*", color = "purple", label = "celsius")
#add labels to axes and a title to the graph
#plt.xlabel("Degrees")
plt.ylabel("Months")
plt.title("Average Temperature Per Month")
#add point markers and a lengend
plt.legend (loc = "upper right")

#add a horizontal line
plt.hlines(35, 0, 12, alpha=0.5)
22/94:
#add avg_celsius to the line graph
fahrenheit_handle = plt.plot(x_axis, avg_temps, marker = "o", color = 'green', label = "fahrenheit")
#celsius_handle = plt.plot(x_axis, avg_celsius, "r+")
celsius_handle = plt.plot(x_axis, avg_celsius, marker = "*", color = "purple", label = "celsius")
#add labels to axes and a title to the graph
#plt.xlabel("Degrees")
#plt.ylabel("Months")
plt.title("Average Temperature Per Month")
#add point markers and a lengend
plt.legend (loc = "upper right")

#add a horizontal line
plt.hlines(35, 0, 12, alpha=0.5)
22/95:
#add avg_celsius to the line graph
fahrenheit_handle = plt.plot(x_axis, avg_temps, marker = "o", color = 'green', label = "fahrenheit")
#celsius_handle = plt.plot(x_axis, avg_celsius, "r+")
celsius_handle = plt.plot(x_axis, avg_celsius, marker = "*", color = "purple", label = "celsius")
#add labels to axes and a title to the graph
#plt.xlabel("Degrees")
#plt.ylabel("Months")
#plt.title("Average Temperature Per Month")
#add point markers and a lengend
plt.legend (loc = "upper right")

#add a horizontal line
plt.hlines(35, 0, 12, alpha=0.5)
22/96:
#Create two lists
Danger_Drop = [9, 8, 90, 85, 80, 70, 70, 65, 55, 60, 70, 65, 50]
Rail_Gun = [75, 70, 60, 65, 60, 45, 55, 50, 40, 40, 35, 35, 30]
#create x axis
x_axis2 = np.arange(0, 13, 1.0)

plt.plot(x_axis2, Danger_Drop)
plt.plot(x_axis2, Rail_Gun)

#create labels
plt.xlabel = ("Time")
plt.ylabel = ("Speed")
plt.title = ("Roller Coaster Speed")
22/97:
#Create two lists
Danger_Drop = [9, 8, 90, 85, 80, 70, 70, 65, 55, 60, 70, 65, 50]
Rail_Gun = [75, 70, 60, 65, 60, 45, 55, 50, 40, 40, 35, 35, 30]
#create x axis
x_axis2 = np.arange(0, 13, 1.0)

plt.plot(x_axis2, Danger_Drop)
plt.plot(x_axis2, Rail_Gun)

#create labels
plt.xlabel("Time")
plt.ylabel("Speed")
plt.title("Roller Coaster Speed")
22/98:
#Create two lists
Danger_Drop = [9, 8, 90, 85, 80, 70, 70, 65, 55, 60, 70, 65, 50]
Rail_Gun = [75, 70, 60, 65, 60, 45, 55, 50, 40, 40, 35, 35, 30]
#create x axis
x_axis2 = np.arange(0, 13, 1.0)

plt_handle = plt.plot(x_axis2, Danger_Drop)
plt_handle = plt.plot(x_axis2, Rail_Gun)

#create labels
plt.xlabel("Time")
plt.ylabel("Speed")
plt.title("Roller Coaster Speed")
22/99:
#import important modules
import numpy as np
import matplotlib.pyplot as plt
22/100:
#Create two lists
Danger_Drop = [9, 8, 90, 85, 80, 70, 70, 65, 55, 60, 70, 65, 50]
Rail_Gun = [75, 70, 60, 65, 60, 45, 55, 50, 40, 40, 35, 35, 30]
#create x axis
x_axis2 = np.arange(0, 13, 1.0)

plt_handle = plt.plot(x_axis2, Danger_Drop)
plt_handle = plt.plot(x_axis2, Rail_Gun)

#create labels
plt.xlabel("Time")
plt.ylabel("Speed")
plt.title("Roller Coaster Speed")
22/101:
#Create two lists
Danger_Drop = [9, 8, 90, 85, 80, 70, 70, 65, 55, 60, 70, 65, 50]
Rail_Gun = [75, 70, 60, 65, 60, 45, 55, 50, 40, 40, 35, 35, 30]
#create x axis
x_axis2 = np.arange(0, 13, 1.0)

plt_handle = plt.plot(x_axis2, Danger_Drop)
plt_handle = plt.plot(x_axis2, Rail_Gun)

#create labels
plt.xlabel(Time)
plt.ylabel(Speed)
plt.title("Roller Coaster Speed")
22/102:
#Create two lists
Danger_Drop = [9, 8, 90, 85, 80, 70, 70, 65, 55, 60, 70, 65, 50]
Rail_Gun = [75, 70, 60, 65, 60, 45, 55, 50, 40, 40, 35, 35, 30]
#create x axis
x_axis2 = np.arange(0, 13, 1.0)

plt_handle = plt.plot(x_axis2, Danger_Drop)
plt_handle = plt.plot(x_axis2, Rail_Gun)

#create labels
plt.xlabel(Time)
plt.ylabel(Speed)
plt.title(Roller Coaster Speed)
22/103:
#Create two lists
Danger_Drop = [9, 8, 90, 85, 80, 70, 70, 65, 55, 60, 70, 65, 50]
Rail_Gun = [75, 70, 60, 65, 60, 45, 55, 50, 40, 40, 35, 35, 30]
#create x axis
x_axis2 = np.arange(0, 13, 1.0)

plt_handle = plt.plot(x_axis2, Danger_Drop)
plt_handle = plt.plot(x_axis2, Rail_Gun)

#create labels
plt.xlabel('Time')
plt.ylabel(Speed)
plt.title(Roller Coaster Speed)
22/104:
#Create two lists
Danger_Drop = [9, 8, 90, 85, 80, 70, 70, 65, 55, 60, 70, 65, 50]
Rail_Gun = [75, 70, 60, 65, 60, 45, 55, 50, 40, 40, 35, 35, 30]
#create x axis
x_axis2 = np.arange(0, 13, 1.0)

plt_handle = plt.plot(x_axis2, Danger_Drop)
plt_handle = plt.plot(x_axis2, Rail_Gun)

#create labels
plt.xlabel('Time')
plt.ylabel('Speed')
plt.title('Roller Coaster Speed')
22/105:
#import important modules
import numpy as np
import matplotlib.pyplot as plt
22/106:
#add avg_celsius to the line graph
fahrenheit_handle = plt.plot(x_axis, avg_temps, marker = "o", color = 'green', label = "fahrenheit")
#celsius_handle = plt.plot(x_axis, avg_celsius, "r+")
celsius_handle = plt.plot(x_axis, avg_celsius, marker = "*", color = "purple", label = "celsius")
#add labels to axes and a title to the graph
plt.xlabel("Degrees")
plt.ylabel("Months")
plt.title("Average Temperature Per Month")
#add point markers and a lengend
plt.legend (loc = "upper right")

#add a horizontal line
plt.hlines(35, 0, 12, alpha=0.5)
22/107:
#import important modules
import numpy as np
import matplotlib.pyplot as plt
22/108:
#Create two lists
Danger_Drop = [9, 8, 90, 85, 80, 70, 70, 65, 55, 60, 70, 65, 50]
Rail_Gun = [75, 70, 60, 65, 60, 45, 55, 50, 40, 40, 35, 35, 30]
#create x axis
x_axis2 = np.arange(0, 13, 1.0)

plt_handle = plt.plot(x_axis2, Danger_Drop)
plt_handle = plt.plot(x_axis2, Rail_Gun)

#create labels
plt.xlabel('Time')
plt.ylabel('Speed')
plt.title('Roller Coaster Speed')
22/109:
#Create two lists
Danger_Drop = [9, 8, 90, 85, 80, 70, 70, 65, 55, 60, 70, 65, 50]
Rail_Gun = [75, 70, 60, 65, 60, 45, 55, 50, 40, 40, 35, 35, 30]
#create x axis
x_axis2 = np.arange(0, 13, 1.0)
22/110:
#Create two lists
Danger_Drop = [9, 8, 90, 85, 80, 70, 70, 65, 55, 60, 70, 65, 50]
Rail_Gun = [75, 70, 60, 65, 60, 45, 55, 50, 40, 40, 35, 35, 30]
#create x axis
x_axis2 = np.arange(0, 13, 1.0)

plt.plot(x_axis2, Danger_Drop)
22/111:
#Create two lists
Danger_Drop = [9, 8, 90, 85, 80, 70, 70, 65, 55, 60, 70, 65, 50]
Rail_Gun = [75, 70, 60, 65, 60, 45, 55, 50, 40, 40, 35, 35, 30]
#create x axis
x_axis2 = np.arange(0, 13, 1.0)

plt.plot(x_axis2, Danger_Drop)
22/112:
#Create two lists
Danger_Drop = [9, 8, 90, 85, 80, 70, 70, 65, 55, 60, 70, 65, 50]
Rail_Gun = [75, 70, 60, 65, 60, 45, 55, 50, 40, 40, 35, 35, 30]
#create x axis
x_axis2 = np.arange(0, 13, 1.0)

plt.plot(x_axis2, Danger_Drop)
plt.plot(x_axis2, Rail_Gun)
22/113:
#Create two lists
Danger_Drop = [9, 8, 90, 85, 80, 70, 70, 65, 55, 60, 70, 65, 50]
Rail_Gun = [75, 70, 60, 65, 60, 45, 55, 50, 40, 40, 35, 35, 30]
#create x axis
x_axis2 = np.arange(0, 13, 1.0)

plt.plot(x_axis2, Danger_Drop)
plt.plot(x_axis2, Rail_Gun)

plt.xlabel("Time")
22/114:
plt_handle = plt.plot(x_axis2, Danger_Drop)
plt_handle = plt.plot(x_axis2, Rail_Gun)

#create labels
plt.xlabel =('Time')
plt.ylabel =('Speed')
plt.title =('Roller Coaster Speed')
22/115:
#add avg_celsius to the line graph
fahrenheit_handle = plt.plot(x_axis, avg_temps, marker = "o", color = 'green', label = "fahrenheit")
#celsius_handle = plt.plot(x_axis, avg_celsius, "r+")
celsius_handle = plt.plot(x_axis, avg_celsius, marker = "*", color = "purple", label = "celsius")
#add labels to axes and a title to the graph
plt.xlabel("Degrees")
plt.ylabel("Months")
plt.title("Average Temperature Per Month")
#add point markers and a lengend
plt.legend (loc = "upper right")

#add a horizontal line
plt.hlines(35, 0, 12, alpha=0.5)
22/116:
plt_handle = plt.plot(x_axis2, Danger_Drop)
plt_handle = plt.plot(x_axis2, Rail_Gun)

#create labels
plt.xlabel =('Time')
plt.ylabel =('Speed')
plt.title =('Roller Coaster Speed')
23/1:
#Create two lists
Danger_Drop = [9, 8, 90, 85, 80, 70, 70, 65, 55, 60, 70, 65, 50]
Rail_Gun = [75, 70, 60, 65, 60, 45, 55, 50, 40, 40, 35, 35, 30]
#create x axis
x_axis2 = np.arange(0, 13, 1.0)

plt.plot(x_axis2, Danger_Drop)
plt.plot(x_axis2, Rail_Gun)

plt.xlabel("Time")
23/2:
#import important modules
import numpy as np
import matplotlib.pyplot as plt
23/3:
#Create two lists
Danger_Drop = [9, 8, 90, 85, 80, 70, 70, 65, 55, 60, 70, 65, 50]
Rail_Gun = [75, 70, 60, 65, 60, 45, 55, 50, 40, 40, 35, 35, 30]
#create x axis
x_axis2 = np.arange(0, 13, 1.0)

plt.plot(x_axis2, Danger_Drop)
plt.plot(x_axis2, Rail_Gun)

plt.xlabel("Time")
23/4:
#Create two lists
Danger_Drop = [9, 8, 90, 85, 80, 70, 70, 65, 55, 60, 70, 65, 50]
Rail_Gun = [75, 70, 60, 65, 60, 45, 55, 50, 40, 40, 35, 35, 30]
#create x axis
x_axis2 = np.arange(0, 13, 1.0)

plt.plot(x_axis2, Danger_Drop)
plt.plot(x_axis2, Rail_Gun)

plt.xlabel("Time")
plt.ylabel =('Speed')
plt.title =('Roller Coaster Speed')
23/5:
#Create two lists
Danger_Drop = [9, 8, 90, 85, 80, 70, 70, 65, 55, 60, 70, 65, 50]
Rail_Gun = [75, 70, 60, 65, 60, 45, 55, 50, 40, 40, 35, 35, 30]
#create x axis
x_axis2 = np.arange(0, 13, 1.0)

plt.plot(x_axis2, Danger_Drop)
plt.plot(x_axis2, Rail_Gun)

plt.xlabel("Time")
plt.ylabel('Speed')
plt.title('Roller Coaster Speed')
23/6:
#Create two lists
Danger_Drop = [9, 8, 90, 85, 80, 70, 70, 65, 55, 60, 70, 65, 50]
Rail_Gun = [75, 70, 60, 65, 60, 45, 55, 50, 40, 40, 35, 35, 30]
#create x axis
x_axis2 = np.arange(0, 13, 1.0)

plt.plot(x_axis2, Danger_Drop)
plt.plot(x_axis2, Rail_Gun)

plt.xlabel("Time")
plt.ylabel("Speed")
plt.title("Roller Coaster Speed")
23/7:
#Create two lists
Danger_Drop = [9, 8, 90, 85, 80, 70, 70, 65, 55, 60, 70, 65, 50]
Rail_Gun = [75, 70, 60, 65, 60, 45, 55, 50, 40, 40, 35, 35, 30]
#create x axis
x_axis2 = np.arange(0, 13, 1.0)

plt.plot(x_axis2, Danger_Drop)
plt.plot(x_axis2, Rail_Gun)

plt.xlabel("Time")
plt.ylabel("Speed")
plt.title("Roller_Coaster_Speed")
23/8:
#Create two lists
Danger_Drop = [9, 8, 90, 85, 80, 70, 70, 65, 55, 60, 70, 65, 50]
Rail_Gun = [75, 70, 60, 65, 60, 45, 55, 50, 40, 40, 35, 35, 30]
#create x axis
x_axis2 = np.arange(0, 13, 1.0)

danger_handle = plt.plot(x_axis2, Danger_Drop)
rail_handle = plt.plot(x_axis2, Rail_Gun)

plt.xlabel("Time")
plt.ylabel("Speed")
plt.title("Roller_Coaster_Speed")
23/9:
#Create two lists
Danger_Drop = [9, 8, 90, 85, 80, 70, 70, 65, 55, 60, 70, 65, 50]
Rail_Gun = [75, 70, 60, 65, 60, 45, 55, 50, 40, 40, 35, 35, 30]
#create x axis
x_axis2 = np.arange(0, 13, 1.0)

danger_handle = plt.plot(x_axis2, Danger_Drop)
rail_handle = plt.plot(x_axis2, Rail_Gun)

#plt.xlabel("Time")
#plt.ylabel("Speed")
#plt.title("Roller_Coaster_Speed")
23/10:
#Create two lists
Danger_Drop = [9, 8, 90, 85, 80, 70, 70, 65, 55, 60, 70, 65, 50]
Rail_Gun = [75, 70, 60, 65, 60, 45, 55, 50, 40, 40, 35, 35, 30]
#create x axis
x_axis2 = np.arange(0, 13, 1.0)

danger_handle = plt.plot(x_axis2, Danger_Drop)
rail_handle = plt.plot(x_axis2, Rail_Gun)

plt.xlabel("Time")
#plt.ylabel("Speed")
#plt.title("Roller_Coaster_Speed")
23/11:
#Create two lists
Danger_Drop = [9, 8, 90, 85, 80, 70, 70, 65, 55, 60, 70, 65, 50]
Rail_Gun = [75, 70, 60, 65, 60, 45, 55, 50, 40, 40, 35, 35, 30]
#create x axis
x_axis2 = np.arange(0, 13, 1.0)

danger_handle = plt.plot(x_axis2, Danger_Drop)
rail_handle = plt.plot(x_axis2, Rail_Gun)

plt.xlabel("Time")
plt.ylabel("Speed")
#plt.title("Roller_Coaster_Speed")
22/117:
#add avg_celsius to the line graph
fahrenheit_handle = plt.plot(x_axis, avg_temps, marker = "o", color = 'green', label = "fahrenheit")
#celsius_handle = plt.plot(x_axis, avg_celsius, "r+")
celsius_handle = plt.plot(x_axis, avg_celsius, marker = "*", color = "purple", label = "celsius")
#add labels to axes and a title to the graph
plt.xlabel("Degrees")
plt.ylabel("Months")
plt.title("Average Temperature Per Month")
#add point markers and a lengend
plt.legend (loc = "upper right")

#add a horizontal line
plt.hlines(35, 0, 12, alpha=0.5)
22/118:
#add avg_celsius to the line graph
fahrenheit_handle = plt.plot(x_axis, avg_temps, marker = "o", color = 'green', label = "fahrenheit")
#celsius_handle = plt.plot(x_axis, avg_celsius, "r+")
celsius_handle = plt.plot(x_axis, avg_celsius, marker = "*", color = "purple", label = "celsius")
#add labels to axes and a title to the graph
plt.xlabel("Degrees")
plt.ylabel("Months")
plt.title("Average Temperature Per Month")
#add point markers and a lengend
plt.legend (loc = "upper right")

#add a horizontal line
plt.hlines(35, 0, 12, alpha=0.5)
22/119:
#add avg_celsius to the line graph
fahrenheit_handle = plt.plot(x_axis, avg_temps, marker = "o", color = 'green', label = "fahrenheit")
#celsius_handle = plt.plot(x_axis, avg_celsius, "r+")
celsius_handle = plt.plot(x_axis, avg_celsius, marker = "*", color = "purple", label = "celsius")
#add labels to axes and a title to the graph
#plt.xlabel("Degrees")
#plt.ylabel("Months")
#plt.title("Average Temperature Per Month")
#add point markers and a lengend
plt.legend (loc = "upper right")

#add a horizontal line
plt.hlines(35, 0, 12, alpha=0.5)
23/12:
#import important modules
import numpy as np
import matplotlib.pyplot as plt
23/13:
#Create two lists
Danger_Drop = [9, 8, 90, 85, 80, 70, 70, 65, 55, 60, 70, 65, 50]
Rail_Gun = [75, 70, 60, 65, 60, 45, 55, 50, 40, 40, 35, 35, 30]
#create x axis
x_axis2 = np.arange(0, 13, 1.0)

danger_handle = plt.plot(x_axis2, Danger_Drop)
rail_handle = plt.plot(x_axis2, Rail_Gun)

plt.xlabel("Time")
plt.ylabel("Speed")
#plt.title("Roller_Coaster_Speed")
23/14:
#Create two lists
Danger_Drop = [9, 8, 90, 85, 80, 70, 70, 65, 55, 60, 70, 65, 50]
Rail_Gun = [75, 70, 60, 65, 60, 45, 55, 50, 40, 40, 35, 35, 30]
#create x axis
x_axis2 = np.arange(0, 13, 1.0)

danger_handle = plt.plot(x_axis2, Danger_Drop)
rail_handle = plt.plot(x_axis2, Rail_Gun)

plt.xlabel("Time")
plt.ylabel("gun")
#plt.title("Roller_Coaster_Speed")
23/15:
#Create two lists
Danger_Drop = [9, 8, 90, 85, 80, 70, 70, 65, 55, 60, 70, 65, 50]
Rail_Gun = [75, 70, 60, 65, 60, 45, 55, 50, 40, 40, 35, 35, 30]
#create x axis
x_axis2 = np.arange(0, 13, 1.0)

danger_handle = plt.plot(x_axis2, Danger_Drop)
rail_handle = plt.plot(x_axis2, Rail_Gun)

plt.xlabel("Time")
#plt.ylabel("Speed")
plt.title("Roller_Coaster_Speed")
23/16:
#Create two lists
Danger_Drop = [9, 8, 90, 85, 80, 70, 70, 65, 55, 60, 70, 65, 50]
Rail_Gun = [75, 70, 60, 65, 60, 45, 55, 50, 40, 40, 35, 35, 30]
#create x axis
x_axis2 = np.arange(0, 13, 1.0)

danger_handle = plt.plot(x_axis2, Danger_Drop)
rail_handle = plt.plot(x_axis2, Rail_Gun)

plt.xlabel("Time")
plt.ylabel("Speed")
plt.title("Roller_Coaster_Speed")

plt.show()
23/17:
#Create two lists
Danger_Drop = [9, 8, 90, 85, 80, 70, 70, 65, 55, 60, 70, 65, 50]
Rail_Gun = [75, 70, 60, 65, 60, 45, 55, 50, 40, 40, 35, 35, 30]
#create x axis
x_axis2 = np.arange(0, 13, 1.0)

danger_handle = plt.plot(x_axis2, Danger_Drop)
rail_handle = plt.plot(x_axis2, Rail_Gun)

plt.xlabel("Time")
plt.ylabel(Speed)
plt.title("Roller_Coaster_Speed")

plt.show()
23/18:
#Create two lists
Danger_Drop = [9, 8, 90, 85, 80, 70, 70, 65, 55, 60, 70, 65, 50]
Rail_Gun = [75, 70, 60, 65, 60, 45, 55, 50, 40, 40, 35, 35, 30]
#create x axis
x_axis2 = np.arange(0, 13, 1.0)

danger_handle = plt.plot(x_axis2, Danger_Drop)
rail_handle = plt.plot(x_axis2, Rail_Gun)

plt.xlabel("Time")
plt.ylabel("Speed")
plt.title("Roller Coaster Speed")
23/19:
#Create two lists
Danger_Drop = [9, 8, 90, 85, 80, 70, 70, 65, 55, 60, 70, 65, 50]
Rail_Gun = [75, 70, 60, 65, 60, 45, 55, 50, 40, 40, 35, 35, 30]
#create x axis
x_axis2 = np.arange(0, 13, 1.0)

danger_handle = plt.plot(x_axis2, Danger_Drop)
rail_handle = plt.plot(x_axis2, Rail_Gun)

plt.xlabel("Time")
#plt.ylabel("Speed")
#plt.title("Roller Coaster Speed")
23/20:
#Create two lists
Danger_Drop = [9, 8, 90, 85, 80, 70, 70, 65, 55, 60, 70, 65, 50]
Rail_Gun = [75, 70, 60, 65, 60, 45, 55, 50, 40, 40, 35, 35, 30]
#create x axis
x_axis2 = np.arange(0, 13, 1.0)

danger_handle = plt.plot(x_axis2, Danger_Drop)
rail_handle = plt.plot(x_axis2, Rail_Gun)

plt.xlabel("Time")
plt.ylabel("Speed")
plt.title("Roller Coaster Speed")
23/21:
#import important modules
import numpy as np
import matplotlib.pyplot as plt
23/22:
#Create two lists
Danger_Drop = [9, 8, 90, 85, 80, 70, 70, 65, 55, 60, 70, 65, 50]
Rail_Gun = [75, 70, 60, 65, 60, 45, 55, 50, 40, 40, 35, 35, 30]
#create x axis
x_axis2 = np.arange(0, 13, 1.0)

danger_handle = plt.plot(x_axis2, Danger_Drop)
rail_handle = plt.plot(x_axis2, Rail_Gun)

plt.xlabel("Time")
#plt.ylabel("Speed")
#plt.title("Roller Coaster Speed")
23/23:
#Create two lists
Danger_Drop = [9, 8, 90, 85, 80, 70, 70, 65, 55, 60, 70, 65, 50]
Rail_Gun = [75, 70, 60, 65, 60, 45, 55, 50, 40, 40, 35, 35, 30]
#create x axis
x_axis2 = np.arange(0, 13, 1.0)

danger_handle = plt.plot(x_axis2, Danger_Drop)
rail_handle = plt.plot(x_axis2, Rail_Gun)

plt.xlabel("Time")
plt.ylabel("Speed")
plt.title("Roller Coaster Speed")
23/24:
#import important modules
import numpy as np
import matplotlib.pyplot as plt
23/25:
#Create two lists
Danger_Drop = [9, 8, 90, 85, 80, 70, 70, 65, 55, 60, 70, 65, 50]
Rail_Gun = [75, 70, 60, 65, 60, 45, 55, 50, 40, 40, 35, 35, 30]
#create x axis
x_axis2 = np.arange(0, 13, 1.0)

danger_handle, = plt.plot(x_axis2, Danger_Drop)
rail_handle, = plt.plot(x_axis2, Rail_Gun)

plt.xlabel("Time")
#plt.ylabel("Speed")
#plt.title("Roller Coaster Speed")
23/26:
#Create two lists
Danger_Drop = [9, 8, 90, 85, 80, 70, 70, 65, 55, 60, 70, 65, 50]
Rail_Gun = [75, 70, 60, 65, 60, 45, 55, 50, 40, 40, 35, 35, 30]
#create x axis
x_axis2 = np.arange(0, 13, 1.0)

danger_handle, = plt.plot(x_axis2, Danger_Drop)
rail_handle, = plt.plot(x_axis2, Rail_Gun)

plt.xlabel("Time")
plt.ylabel("Speed")
#plt.title("Roller Coaster Speed")
23/27:
#import important modules
import numpy as np
import matplotlib.pyplot as plt
%matplotlib notebook
23/28:
#Create two lists
Danger_Drop = [9, 8, 90, 85, 80, 70, 70, 65, 55, 60, 70, 65, 50]
Rail_Gun = [75, 70, 60, 65, 60, 45, 55, 50, 40, 40, 35, 35, 30]
#create x axis
x_axis2 = np.arange(0, 13, 1.0)

danger_handle, = plt.plot(x_axis2, Danger_Drop)
rail_handle, = plt.plot(x_axis2, Rail_Gun)

plt.xlabel("Time")
plt.ylabel("Speed")
#plt.title("Roller Coaster Speed")
23/29:
plt.xlabel("Time")
plt.ylabel("Speed")
plt.title("Roller Coaster Speed")
24/1:
#import important modules
import numpy as np
import matplotlib.pyplot as plt
%matplotlib notebook
24/2:
#Create two lists
Danger_Drop = [9, 8, 90, 85, 80, 70, 70, 65, 55, 60, 70, 65, 50]
Rail_Gun = [75, 70, 60, 65, 60, 45, 55, 50, 40, 40, 35, 35, 30]
#create x axis
x_axis2 = np.arange(0, 13, 1.0)

danger_handle, = plt.plot(x_axis2, Danger_Drop)
rail_handle, = plt.plot(x_axis2, Rail_Gun)

#plt.xlabel("Time")
#plt.ylabel("Speed")
#plt.title("Roller Coaster Speed")
24/3:
plt.xlabel("Time")
plt.ylabel("Speed")
plt.title("Roller Coaster Speed")
25/1:
#import important modules
import numpy as np
import matplotlib.pyplot as plt
25/2:
#create the list of average temps
avg_temps = [39, 42, 51, 62, 72, 82, 86, 84, 77, 65, 55, 44]

x_axis = np.arange(0, 12, 1.0)
25/3:
#plot the avg_temps list
plt.plot(avg_temps)
25/4:
#use list comprehension to convert fahrenheit to celsius
avg_celsius = []
for temp in avg_temps:
    if temp in avg_temps:
        avg_celsius.append((temp - 32) * .56)

avg_celsius
25/5:
#add avg_celsius to the line graph
fahrenheit_handle = plt.plot(x_axis, avg_temps, marker = "o", color = 'green', label = "fahrenheit")
#celsius_handle = plt.plot(x_axis, avg_celsius, "r+")
celsius_handle = plt.plot(x_axis, avg_celsius, marker = "*", color = "purple", label = "celsius")
#add labels to axes and a title to the graph
#plt.xlabel("Degrees")
#plt.ylabel("Months")
#plt.title("Average Temperature Per Month")
#add point markers and a lengend
plt.legend (loc = "upper right")

#add a horizontal line
plt.hlines(35, 0, 12, alpha=0.5)
25/6:
#add avg_celsius to the line graph
fahrenheit_handle = plt.plot(x_axis, avg_temps, marker = "o", color = 'green', label = "fahrenheit")
#celsius_handle = plt.plot(x_axis, avg_celsius, "r+")
celsius_handle = plt.plot(x_axis, avg_celsius, marker = "*", color = "purple", label = "celsius")
#add labels to axes and a title to the graph
plt.xlabel("Degrees")
plt.ylabel("Months")
plt.title("Average Temperature Per Month")
#add point markers and a lengend
plt.legend (loc = "upper right")

#add a horizontal line
plt.hlines(35, 0, 12, alpha=0.5)
24/4:
plt.xlabel("Coaster Time")
plt.ylabel("Speed (mph)")
plt.title("Roller Coaster Speed")
24/5:
#Create two lists
Danger_Drop = [9, 8, 90, 85, 80, 70, 70, 65, 55, 60, 70, 65, 50]
Rail_Gun = [75, 70, 60, 65, 60, 45, 55, 50, 40, 40, 35, 35, 30]
#create x axis
x_axis2 = np.arange(0, 13, 1.0)

danger_handle, = plt.plot(x_axis2, Danger_Drop, color = "red")
rail_handle, = plt.plot(x_axis2, Rail_Gun, color = "blue")

#plt.xlabel("Time")
#plt.ylabel("Speed")
#plt.title("Roller Coaster Speed")
24/6:
plt.xlabel("Coaster Time")
plt.ylabel("Speed (mph)")
plt.title("Roller Coaster Speed")

plt.grid()
24/7:
#Create two lists
Danger_Drop = [9, 8, 90, 85, 80, 70, 70, 65, 55, 60, 70, 65, 50]
Rail_Gun = [75, 70, 60, 65, 60, 45, 55, 50, 40, 40, 35, 35, 30]
#create x axis
x_axis2 = np.arange(10, 100, 10.0)

danger_handle, = plt.plot(x_axis2, Danger_Drop, color = "red")
rail_handle, = plt.plot(x_axis2, Rail_Gun, color = "blue")



#plt.xlabel("Time")
#plt.ylabel("Speed")
#plt.title("Roller Coaster Speed")
24/8:
#Create two lists
Danger_Drop = [9, 8, 90, 85, 80, 70, 70, 65, 55, 60, 70, 65, 50]
Rail_Gun = [75, 70, 60, 65, 60, 45, 55, 50, 40, 40, 35, 35, 30]
#create x axis
x_axis2 = (np.arange(10, 100, 10.0))

danger_handle, = plt.plot(x_axis2, Danger_Drop, color = "red")
rail_handle, = plt.plot(x_axis2, Rail_Gun, color = "blue")



#plt.xlabel("Time")
#plt.ylabel("Speed")
#plt.title("Roller Coaster Speed")
24/9:
#Create two lists
Danger_Drop = [9, 8, 90, 85, 80, 70, 70, 65, 55, 60, 70, 65, 50]
Rail_Gun = [75, 70, 60, 65, 60, 45, 55, 50, 40, 40, 35, 35, 30]
#create x axis
plt.yticks(np.arange(10, 100, 10.0))

danger_handle, = plt.plot(x_axis2, Danger_Drop, color = "red")
rail_handle, = plt.plot(x_axis2, Rail_Gun, color = "blue")



#plt.xlabel("Time")
#plt.ylabel("Speed")
#plt.title("Roller Coaster Speed")
24/10:
#Create two lists
Danger_Drop = [9, 8, 90, 85, 80, 70, 70, 65, 55, 60, 70, 65, 50]
Rail_Gun = [75, 70, 60, 65, 60, 45, 55, 50, 40, 40, 35, 35, 30]
#create x axis
x_axis2 = np.arange(1, 13, 1.0)

danger_handle, = plt.plot(x_axis2, Danger_Drop, color = "red")
rail_handle, = plt.plot(x_axis2, Rail_Gun, color = "blue")



#plt.xlabel("Time")
#plt.ylabel("Speed")
#plt.title("Roller Coaster Speed")
24/11:
#Create two lists
Danger_Drop = [9, 8, 90, 85, 80, 70, 70, 65, 55, 60, 70, 65, 50]
Rail_Gun = [75, 70, 60, 65, 60, 45, 55, 50, 40, 40, 35, 35, 30]
#create x axis
x_axis2 = np.arange(1, 13, 1.0)

danger_handle, = plt.plot(x_axis2, Danger_Drop, color = "red")
rail_handle, = plt.plot(x_axis2, Rail_Gun, color = "blue")



#plt.xlabel("Time")
#plt.ylabel("Speed")
#plt.title("Roller Coaster Speed")
24/12:
#Create two lists
Danger_Drop = [9, 8, 90, 85, 80, 70, 70, 65, 55, 60, 70, 65, 50]
Rail_Gun = [75, 70, 60, 65, 60, 45, 55, 50, 40, 40, 35, 35, 30]
#create x axis
x_axis2 = np.arange(1, 12, 1.0)

danger_handle, = plt.plot(x_axis2, Danger_Drop, color = "red")
rail_handle, = plt.plot(x_axis2, Rail_Gun, color = "blue")



#plt.xlabel("Time")
#plt.ylabel("Speed")
#plt.title("Roller Coaster Speed")
24/13:
#Create two lists
Danger_Drop = [9, 8, 90, 85, 80, 70, 70, 65, 55, 60, 70, 65, 50]
Rail_Gun = [75, 70, 60, 65, 60, 45, 55, 50, 40, 40, 35, 35, 30]
#create x axis
x_axis2 = np.arange(1, 13, 1.0)

danger_handle, = plt.plot(x_axis2, Danger_Drop, color = "red")
rail_handle, = plt.plot(x_axis2, Rail_Gun, color = "blue")



#plt.xlabel("Time")
#plt.ylabel("Speed")
#plt.title("Roller Coaster Speed")
26/1:
#import important modules
import numpy as np
import matplotlib.pyplot as plt
%matplotlib notebook
26/2:
#Create two lists
Danger_Drop = [9, 8, 90, 85, 80, 70, 70, 65, 55, 60, 70, 65, 50]
Rail_Gun = [75, 70, 60, 65, 60, 45, 55, 50, 40, 40, 35, 35, 30]
#create x axis
x_axis2 = np.arange(1, 13, 1.0)

danger_handle, = plt.plot(x_axis2, Danger_Drop, color = "red")
rail_handle, = plt.plot(x_axis2, Rail_Gun, color = "blue")



#plt.xlabel("Time")
#plt.ylabel("Speed")
#plt.title("Roller Coaster Speed")
26/3:
#Create two lists
Danger_Drop = [9, 8, 90, 85, 80, 70, 70, 65, 55, 60, 70, 65, 50]
Rail_Gun = [75, 70, 60, 65, 60, 45, 55, 50, 40, 40, 35, 35, 30]
#create x axis
#x_axis2 = np.arange(1, 13, 1.0)

danger_handle, = plt.plot(x_axis2, Danger_Drop, color = "red")
rail_handle, = plt.plot(x_axis2, Rail_Gun, color = "blue")



#plt.xlabel("Time")
#plt.ylabel("Speed")
#plt.title("Roller Coaster Speed")
26/4:
#Create two lists
Danger_Drop = [9, 8, 90, 85, 80, 70, 70, 65, 55, 60, 70, 65, 50]
Rail_Gun = [75, 70, 60, 65, 60, 45, 55, 50, 40, 40, 35, 35, 30]
#create x axis
x_axis2 = np.arange(1, 13, 1.0)

danger_handle, = plt.plot(x_axis2, Danger_Drop, color = "red")
rail_handle, = plt.plot(x_axis2, Rail_Gun, color = "blue")



#plt.xlabel("Time")
#plt.ylabel("Speed")
#plt.title("Roller Coaster Speed")
26/5:
#import important modules
import numpy as np
import matplotlib.pyplot as plt
%matplotlib notebook
26/6:
#Create two lists
Danger_Drop = [9, 8, 90, 85, 80, 70, 70, 65, 55, 60, 70, 65, 50]
Rail_Gun = [75, 70, 60, 65, 60, 45, 55, 50, 40, 40, 35, 35, 30]
#create x axis
x_axis2 = np.arange(1, 13, 1.0)

danger_handle, = plt.plot(x_axis2, Danger_Drop, color = "red")
rail_handle, = plt.plot(x_axis2, Rail_Gun, color = "blue")



#plt.xlabel("Time")
#plt.ylabel("Speed")
#plt.title("Roller Coaster Speed")
26/7:
plt.xlabel("Coaster Time")
plt.ylabel("Speed (mph)")
plt.title("Roller Coaster Speed")

plt.grid()
27/1: %matplotlib notebook
27/2:
#Load dependencies
import matplotlib.pyplot as pit
import numpy as np
27/3:
cities = ["San Francisco", "Omaha", "New Orleans", "Cincinnati", "Pittsburgh"]
cars_in_cities = [214.7, 564.4, 416.5, 466.7, 350.6]
x_axis = np.arange(len(cars_in_cities))
27/4:
 # Create a bar chart based upon the above data
plt.bar(cars_in_cities, cities)
27/5:
#Load dependencies
import matplotlib.pyplot as plt
import numpy as np
27/6:
cities = ["San Francisco", "Omaha", "New Orleans", "Cincinnati", "Pittsburgh"]
cars_in_cities = [214.7, 564.4, 416.5, 466.7, 350.6]
x_axis = np.arange(len(cars_in_cities))
27/7:
 # Create a bar chart based upon the above data
plt.bar(cars_in_cities, cities)
27/8:
 # Create a bar chart based upon the above data
plt.bar(cars_in_cities, cities, linewidth = 0)
27/9:
 # Create a bar chart based upon the above data
plt.bar(cars_in_cities, cities, linewidth = 10)
27/10:
 # Create a bar chart based upon the above data
plt.bar(cars_in_cities, cities, linewidth = 10)
27/11:
 # Create a bar chart based upon the above data
plt.bar(cars_in_cities, cities, width = 5)
27/12:
 # Create a bar chart based upon the above data
plt.bar(cars_in_cities, cities, width = 10)
27/13: # Create the ticks for our bar chart's x axis
27/14:  # Set the limits of the x axis
27/15:
 # Give the chart a title, x label, and y label
plt.xlabel("Number of Cars")
28/1:
#District Summary
#Create a high-level snapshot, in a DataFrame, of the district's key metrics
28/2:
#import dependencies
import pandas as pd
28/3:
#import csv files
csv_students = "/Users/Jerry/Documents/Homework/students_complete.csv"
csv_schools = "/Users/Jerry/Documents/Homework/schools_complete.csv"
csv_purchases = "/Users/Jerry/Documents/Homework/purchase_data.csv"
28/4:
#import csv files
csv_students = "/Users/Jerry/Documents/Homework/students_complete.csv"
csv_schools = "/Users/Jerry/Documents/Homework/schools_complete.csv"
csv_purchases = "/Users/Jerry/Documents/Homework/purchase_data.csv"

students_df = pd.DataFrame(csv_students)
schools_df = pd.DataFrame(csv_schools)
purchases_df = pd.DataFrame(csv_purchases)
28/5:
#import csv files
csv_students = "/Users/Jerry/Documents/Homework/students_complete.csv"
csv_schools = "/Users/Jerry/Documents/Homework/schools_complete.csv"
csv_purchases = "/Users/Jerry/Documents/Homework/purchase_data.csv"

pd.read_csv()

students_df = pd.read_csv(csv_students)
schools_df = pd.read_csv(csv_schools)
purchases_df = pd.read_csv(csv_purchases)
28/6:
#import csv files
csv_students = "/Users/Jerry/Documents/Homework/students_complete.csv"
csv_schools = "/Users/Jerry/Documents/Homework/schools_complete.csv"
csv_purchases = "/Users/Jerry/Documents/Homework/purchase_data.csv"

students_df = pd.read_csv(csv_students)
schools_df = pd.read_csv(csv_schools)
purchases_df = pd.read_csv(csv_purchases)
28/7: students_df.head()
28/8: schools_df.head()
28/9: purchases_df.head()
28/10: total_schools = schools_df.count_values()
28/11: total_schools = schools_df.value_counts()
28/12:
total_schools = schools_df.value_counts()
total_schools
28/13: schools_df.tail()
28/14: schools_df.head()
28/15:
total_schools = schools_df["school_name"].sum()
total_schools
28/16:
total_schools = schools_df["school_name"].count()
total_schools
28/17:
total_schools = schools_df["school_name"].count()
total_schools
(f"Total School: {total_schools}")
28/18:
total_schools = schools_df["school_name"].count()
total_schools
(f"Total Schools: {total_schools}")
28/19: total_students = students_df["Student ID"].count_values()
28/20: total_students = students_df["Student ID"].value_counts()
28/21:
total_students = students_df["Student ID"].value_counts()
total_students
28/22:
total_students = students_df["Student ID"].count()
total_students
28/23: students_df.tail()
28/24:
total_students = students_df["Student ID"].count()
total_students
(f"Total students: {total_students}")
28/25: schools_df.tail()
28/26: total_budget = schools_df["budget"].sum()
28/27:
total_budget = schools_df["budget"].sum()
(f"Total Budget: {total_budget}"")
28/28:
total_budget = schools_df["budget"].sum()
(f"Total Budget: {total_budget}")
28/29:
avg_math_score = students_df["Average math score"].mean()
#(f" {}")
(f"Average math score: {avg_math_score}")
28/30:
avg_math_score = students_df["math_score"].mean()
#(f" {}")
(f"Average math score: {avg_math_score}")
28/31:
avg_math_score = students_df["math_score"].mean()
#(f" {}")
round(avg_math_score, 2)
(f"Average math score: {avg_math_score}")
28/32:
avg_math_score = round(students_df["math_score"].mean())
#(f" {}")

(f"Average math score: {avg_math_score}")
28/33:
avg_math_score = round((students_df["math_score"].mean()), 2)
#(f" {}")

(f"Average math score: {avg_math_score}")
28/34:
avg_reading_score = round((students_df["reading_score"].mean()), 2)
(f"Average reading score {avg_reading_score}")
28/35:
# % passing math (the percentage of students who passed math)
#create a for loop to add students who have a passing math score
math_passing = 0

for scores in students_df["math_score"]:
    if scores >= 70:
        math_passing = math_passing + 1
28/36: math_passing
28/37:
# % passing math (the percentage of students who passed math)
#create a for loop to count the students who have a passing math score
math_passing = 0

for scores in students_df["math_score"]:
    if scores >= 70:
        math_passing = math_passing + 1
        
#now compare math_passing to total students 
percent_passing_math = math_passing / total_students
28/38: percent_passing_math
28/39:
# % passing math (the percentage of students who passed math)
#create a for loop to count the students who have a passing math score
math_passing = 0

for scores in students_df["math_score"]:
    if scores >= 70:
        math_passing = math_passing + 1
        
#now compare math_passing to total students 
percent_passing_math = ((math_passing / total_students), 2)
28/40: percent_passing_math
28/41:
# % passing math (the percentage of students who passed math)
#create a for loop to count the students who have a passing math score
math_passing = 0

for scores in students_df["math_score"]:
    if scores >= 70:
        math_passing = math_passing + 1
        
#now compare math_passing to total students 
percent_passing_math = round((math_passing / total_students), 2)
28/42: percent_passing_math
28/43:
percent_passing_math
(f"The percentage of students who passed math %{percent_passing_math}")
28/44: math_passing
28/45:
percent_passing_math
(f"The percentage of students who passed math: %{percent_passing_math}")
28/46:
#% passing reading (the percentage of students who passed reading)

#create a variable to hold the number of students passing reading
reading_passing = 0

#create a for loop to count the number of students who passed reading 
for scores in students_df["reading_score"]:
    if scores >= 70:
        reading_passing = reading_passing + 1
        
reading_passing
28/47:
#% passing reading (the percentage of students who passed reading)

#create a variable to hold the number of students passing reading
reading_passing = 0

#create a for loop to count the number of students who passed reading 
for scores in students_df["reading_score"]:
    if scores >= 70:
        reading_passing = reading_passing + 1
        
reading_passing

percent_passing_reading = round((reading_passing / total_students), 2)
28/48:
#% passing reading (the percentage of students who passed reading)

#create a variable to hold the number of students passing reading
reading_passing = 0

#create a for loop to count the number of students who passed reading 
for scores in students_df["reading_score"]:
    if scores >= 70:
        reading_passing = reading_passing + 1
        
reading_passing

percent_passing_reading = round((reading_passing / total_students), 2)

percent_passing_reading
28/49: f"The percentage of students who passed reading: %{percent_passing_reading}")
28/50: f"The percentage of students who passed reading: %{percent_passing_reading}"
28/51:
# % overall passing (the percentage of students who passed math AND reading

#A variable to hold the students who pass math and reading
passing_both = 0

#A for loop to count the number of students who pass math and reading

for rscore, mscore in zip(students_df["reading_score"].rscore, students_df["math_score"].mscore):
    if rscore >= 70, mscore >=70:
        passing_both = passing_both + 1
28/52:
# % overall passing (the percentage of students who passed math AND reading

#A variable to hold the students who pass math and reading
passing_both = 0

#A for loop to count the number of students who pass math and reading

for rscore, mscore in zip(students_df["reading_score"].rscore, students_df["math_score"].mscore):
    if rscore >= 70 AND mscore >=70:
        passing_both = passing_both + 1
28/53:
# % overall passing (the percentage of students who passed math AND reading

#A variable to hold the students who pass math and reading
passing_both = 0

#A for loop to count the number of students who pass math and reading

for rscore, mscore in zip(students_df["reading_score"].rscore, students_df["math_score"].mscore):
    if rscore >= 70 
        mscore >=70:
        passing_both = passing_both + 1
28/54:
# % overall passing (the percentage of students who passed math AND reading

#A variable to hold the students who pass math and reading
passing_both = 0

#A for loop to count the number of students who pass math and reading

for rscore, mscore in zip(students_df["reading_score"].rscore, students_df["math_score"].mscore):
    if rscore >= 70 
        if mscore >=70:
        passing_both = passing_both + 1
28/55:
# % overall passing (the percentage of students who passed math AND reading

#A variable to hold the students who pass math and reading
passing_both = 0

#A for loop to count the number of students who pass math and reading

for rscore, mscore in zip(students_df["reading_score"].rscore, students_df["math_score"].mscore):
    if rscore >= 70: 
        if mscore >=70:
            passing_both = passing_both + 1
28/56:
#import csv files
csv_students = "/Users/Jerry/Documents/Homework/students_complete.csv"
csv_schools = "/Users/Jerry/Documents/Homework/schools_complete.csv"
csv_purchases = "/Users/Jerry/Documents/Homework/purchase_data.csv"

students_df = pd.read_csv(csv_students)
schools_df = pd.read_csv(csv_schools)
purchases_df = pd.read_csv(csv_purchases)

#combine the data into a singe dataset
school_data_complete = pd.merge( students_df, schools_df, how = "left", on=["school_name", "shcool_name"])
28/57:
#import csv files
csv_students = "/Users/Jerry/Documents/Homework/students_complete.csv"
csv_schools = "/Users/Jerry/Documents/Homework/schools_complete.csv"
csv_purchases = "/Users/Jerry/Documents/Homework/purchase_data.csv"

students_df = pd.read_csv(csv_students)
schools_df = pd.read_csv(csv_schools)
purchases_df = pd.read_csv(csv_purchases)

#combine the data into a singe dataset
school_data_complete = pd.merge(students_df, schools_df, how = "left", on=["school_name", "school_name"])
28/58: students_df.tail()
28/59: school_data_complete.head()
28/60: type(total_schools)
28/61:
d = {'Total Schools':[total_schools], 'Total Students':[total_students], 'Total Budget':[total_budget], 'Average Math Score':[avg_math_score], 'Average Reading Score':[avg_reading_score], '% Passing Math':[percent_passing_math], '% Passing Reading':[percent_passing_reading], '% Overall Passing':[0], }
district_summary_df = pd.DataFrame(data = d)
28/62: district_summary_df
28/63: #School Summary
28/64:
#School Summary
school_data_complete.head()
28/65:
#import dependencies
import pandas as pd
28/66:
#import csv files
csv_students = "/Users/Jerry/Documents/Homework/students_complete.csv"
csv_schools = "/Users/Jerry/Documents/Homework/schools_complete.csv"
csv_purchases = "/Users/Jerry/Documents/Homework/purchase_data.csv"

students_df = pd.read_csv(csv_students)
schools_df = pd.read_csv(csv_schools)
purchases_df = pd.read_csv(csv_purchases)

#combine the data into a singe dataset
school_data_complete = pd.merge(students_df, schools_df, how = "left", on=["school_name", "school_name"])
28/67:
#School Summary
school_data_complete.head()
28/68: schools_df.tail()
28/69:
#import dependencies
import pandas as pd
import numpy as np
28/70: schools_df
28/71: schools_df.columns
28/72: schools_df["school_name"].unique()
28/73: school_array = schools_df["school_name"].unique()
28/74:
#Create an overview table that summarizes key metrics about each school, including:
#school_array = np.array(['School ID', 'school_name', 'type', 'size', 'budget'])
type(school_array)
28/75:
#Create an overview table that summarizes key metrics about each school, including:
#school_array = np.array(['School ID', 'school_name', 'type', 'size', 'budget'])
df2 = pd.DataFrame(school_array, columns = ['School Name'])
28/76: df2
28/77: df2
28/78: df2
28/79: schools_df
28/80: schools_df.head()
28/81:
school_array = schools_df[["school_name", "type"]].unique()

#school_type_array = schools_df["school_name"].unique()
28/82:
school_array = schools_df["school_name"].unique()

#school_type_array = schools_df["school_name"].unique()
28/83: school_array
28/84:
#Create an overview table that summarizes key metrics about each school, including:
#school_array = np.array(['School ID', 'school_name', 'type', 'size', 'budget'])
df2 = pd.DataFrame(school_array, columns = ['School type', 'Total Students', 'Total School Budget', 'Per Student Budget', 'Average Math Score', 'Average Reading Score', '% Passing Math', '% Passing Reading', '% Overall Passing'])
28/85:
data = np.array([[1], [2], [3], [4], [5], [6], [7], [8], [9], [10], [11], [12], [13], [14], [15]])
df3 = pd.DataFrame(data, columns = ['School type', 'Total Students'], index = [school_array])
28/86:
data = np.array([[1], [2], [3], [4], [5], [6], [7], [8], [9], [10], [11], [12], [13], [14], [15]])
#df3 = pd.DataFrame(data, columns = ['School type', 'Total Students'], index = [school_array])
28/87:
data = np.array([[1], [2], [3], [4], [5], [6], [7], [8], [9], [10], [11], [12], [13], [14], [15]])
df3 = pd.DataFrame(data, columns = ['School type'], index = [school_array])
28/88: df_3
28/89: df3
28/90:
data = np.array([[1], [2], [3], [4], [5], [6], [7], [8], [9], [10], [11], [12], [13], [14], [15]])
df3 = pd.DataFrame(data, columns = ['School type'], index = [school_array])
df3
28/91:
#Create an overview table that summarizes key metrics about each school, including:

df2 = pd.DataFrame(school_array, columns = ['School type', 'Total Students', 'Total School Budget', 'Per Student Budget', 'Average Math Score', 'Average Reading Score', '% Passing Math', '% Passing Reading', '% Overall Passing'])

df2
28/92:
#Create an overview table that summarizes key metrics about each school, including:

df2 = pd.DataFrame(school_array, columns = ['School type']
#, 'Total Students', 'Total School Budget', 'Per Student Budget', 'Average Math Score', 'Average Reading Score', '% Passing Math', '% Passing Reading', '% Overall Passing'])

df2
28/93:
school_array = schools_df["school_name"].unique()

#school_type_array = schools_df["school_name"].unique()
28/94:
#Create an overview table that summarizes key metrics about each school, including:

df2 = pd.DataFrame(school_array, columns = ['School type']
#, 'Total Students', 'Total School Budget', 'Per Student Budget', 'Average Math Score', 'Average Reading Score', '% Passing Math', '% Passing Reading', '% Overall Passing'])

df2
28/95:
#Create an overview table that summarizes key metrics about each school, including:

df2 = pd.DataFrame(school_array, columns = ['School type'])
#, 'Total Students', 'Total School Budget', 'Per Student Budget', 'Average Math Score', 'Average Reading Score', '% Passing Math', '% Passing Reading', '% Overall Passing'])

df2
28/96:
#Create an overview table that summarizes key metrics about each school, including:
d = 'school type'
df2 = pd.DataFrame(school_array, columns = [d])
#, 'Total Students', 'Total School Budget', 'Per Student Budget', 'Average Math Score', 'Average Reading Score', '% Passing Math', '% Passing Reading', '% Overall Passing'])

df2
28/97: district_summary_df
29/1: #car activity
29/2: #import depencies
29/3:
#import depencies
import matplotlib.pyplot as plt
29/4:
#import depencies
import matplotlib.pyplot as plt
import numpy as np
29/5:
#import depencies
import matplotlib.pyplot as plt
import numpy as np
%matplotlib notebook
29/6:
cities = ["San Francisco", "Omaha", "New Orleans", "Cincinnati", "Pittsburgh"]
cars_in_cities = [214.7, 564.4, 416.5, 466.7, 350.6]
x_axis = np.arange(len(cars_in_cities))
29/7:
# Create a bar chart based upon the above data
#syntax plt.bar(x, y, width, bottom, align)
plt.bar(cities, cars_in_cities)
29/8:
# Create a bar chart based upon the above data
#syntax plt.bar(x, y, width, bottom, align)
plt.bar(cities, cars_in_cities, align = "left")
29/9:
# Create a bar chart based upon the above data
#syntax plt.bar(x, y, width, bottom, align)
plt.bar(cities, cars_in_cities, align = "center")
29/10:
# Create a bar chart based upon the above data
#syntax plt.bar(x, y, width, bottom, align)
plt.bar(cities, cars_in_cities, width = .5, align = "center")
29/11:
# Create a bar chart based upon the above data
#syntax plt.bar(x, y, width, bottom, align)
plt.bar(cities, cars_in_cities, width = 1, align = "center")
29/12:
# Create a bar chart based upon the above data
#syntax plt.bar(x, y, width, bottom, align)
plt.bar(cities, cars_in_cities, width = .75, align = "center")
29/13:
tick_locations = [value for value in x_axis]
plt.xticks(tick_locations, cities)
29/14: plt.xlim(-0.75, len(axis)-.0.25)
29/15: plt.xlim(-0.75, len(axis)-0.25)
29/16: plt.xlim(-0.75, len(x_axis)-0.25)
29/17: #plt.ylim
29/18:
#plt.title
#plt.xlabel
#plt.ylabel
29/19: #
29/20: #Warmup Activity
29/21:
# DATA SET 1
gyms = ["Crunch", "Planet Fitness", "NY Sports Club", "Rickie's Gym"]
members = [49, 92, 84, 53]

#create a x axis
x_axis2 = np.arange(len(gyms))
29/22: bar_graph = plt.bar(x_axis2, members)
29/23: plt.bar(x_axis2, members)
30/1:
#import depencies
import matplotlib.pyplot as plt
import numpy as np
%matplotlib notebook
30/2:
#Warmup Activity
#pyplot warmup

#Determine what chart or plot fits with the starter code for each dataset.
#Complete the code block to create a plot for each of the datasets.
#Be sure to provide each plot with a title and labels.
30/3:
# DATA SET 1
gyms = ["Crunch", "Planet Fitness", "NY Sports Club", "Rickie's Gym"]
members = [49, 92, 84, 53]

#create a x axis
x_axis2 = np.arange(len(gyms))
30/4: plt.bar(x_axis2, members)
29/24:
#import depencies
import matplotlib.pyplot as plt
import numpy as np
%matplotlib notebook
29/25:
cities = ["San Francisco", "Omaha", "New Orleans", "Cincinnati", "Pittsburgh"]
cars_in_cities = [214.7, 564.4, 416.5, 466.7, 350.6]
x_axis = np.arange(len(cars_in_cities))
29/26:
# Create a bar chart based upon the above data
#syntax plt.bar(x, y, width, bottom, align)
plt.bar(cities, cars_in_cities, width = .75, align = "center")
29/27:
tick_locations = [value for value in x_axis]
plt.xticks(tick_locations, cities)
29/28: plt.xlim(-0.75, len(x_axis)-0.25)
29/29: #DON'T RUN NEXT ACTIVITY IN SAME KERNEL, IT WILL MESS UP THE ABOVE ACTIVITIES GRAPHS. GRAPHS WIL BE COMBINED
29/30:
#Data Set 2
x_lim = 2 * np.pi
x_axis = np.arange(0, x_lim, 0.1)
sin = np.sin(x_axis)

#use plts
29/31:
#Data Set 2
x_lim = 2 * np.pi
x_axis3 = np.arange(0, x_lim, 0.1)
sin = np.sin(x_axis)

#use plts
29/32: plt.pie(members, explode = explode, labels = gyms, color = colors, shadow = True)
29/33:
# DATA SET 3
gyms = ["Crunch", "Planet Fitness", "NY Sports Club", "Rickie's Gym"]
members = [49, 92, 84, 53]
x_axis = np.arange(0, len(gyms))
colors = ["yellowgreen", "red", "lightcoral", "lightskyblue"]
explode = (0, 0.05, 0, 0)
29/34: plt.pie(members, explode = explode, labels = gyms, color = colors, shadow = True)
29/35: plt.pie(members, explode = explode, labels = gyms, colors = colors, shadow = True)
29/36:
#import depencies
import matplotlib.pyplot as plt
import numpy as np
%matplotlib notebook
29/37:
#import depencies
import matplotlib.pyplot as plt
import numpy as np
%matplotlib notebook
29/38:
# DATA SET 3
gyms = ["Crunch", "Planet Fitness", "NY Sports Club", "Rickie's Gym"]
members = [49, 92, 84, 53]
x_axis = np.arange(0, len(gyms))
colors = ["yellowgreen", "red", "lightcoral", "lightskyblue"]
explode = (0, 0.05, 0, 0)
29/39: plt.pie(members, explode = explode, labels = gyms, colors = colors, shadow = True)
29/40: plt.pie(members, explode = explode, labels = gyms, colors = colors, autopct = "%1.1f%%", shadow = True)
29/41: plt.pie(members, explode = explode, labels = gyms, colors = colors, autopct = "%1.1f%%", shadow = True, startangle = 140)
29/42: plt.pie(members, explode = explode, labels = gyms, colors = colors, autopct = "%1.1f%%", shadow = True, startangle = 90)
29/43: plt.pie(members, explode = explode, labels = gyms, colors = colors, autopct = "%1.1f%%", shadow = True, startangle = 270)
29/44: plt.pie(members, explode = explode, labels = gyms, colors = colors, autopct = "%1.1f%%", shadow = True, startangle = 90)
29/45: plt.pie(members, explode = explode, labels = gyms, colors = colors, autopct = "%1.1f%%", shadow = True, startangle = 140)
29/46:
#import depencies
import matplotlib.pyplot as plt
import numpy as np
%matplotlib notebook
29/47:
# DATA SET 4
x_axis = np.arange(0, 10, 0.1)
times = []
for x in x_axis:
    times.append(x * x + np.random.randint(0, np.ceil(max(x_axis))))
29/48:
plt.pie(members, explode = explode, labels = gyms, colors = colors, autopct = "%1.1f%%", shadow = True, startangle = 140)

plt.axis("equal")
29/49:
plt.pie(members, explode = explode, labels = gyms, colors = colors, autopct = "%1.1f%%", shadow = True, startangle = 140)

plt.axis("equal")

plt.show()
29/50: plt.scatter(x_axis, times, marker= "o", color="blue")
29/51:
#import depencies
import matplotlib.pyplot as plt
import numpy as np
%matplotlib notebook
29/52:
# DATA SET 4
x_axis = np.arange(0, 10, 0.1)
times = []
for x in x_axis:
    times.append(x * x + np.random.randint(0, np.ceil(max(x_axis))))
29/53: plt.scatter(x_axis, times, marker= "o", color="blue")
29/54:
plt.scatter(x_axis, times, marker= "o", color="blue")
plt.title = "This is the title"
30/5:
#import depencies
import matplotlib.pyplot as plt
import numpy as np
%matplotlib notebook
30/6:
#Use Pandas to load the union_settlements_1995.csv dataset.
csv_file = "/Users/Jerry/Downloads/union_settlements_1995.csv"
30/7:
#Use Pandas to load the union_settlements_1995.csv dataset.
csv_file = "/Users/Jerry/Downloads/union_settlements_1995.csv"
union_df = pd.read_csv(csv_file)
30/8:
#import depencies
import matplotlib.pyplot as plt
import numpy as np
%matplotlib notebook
30/9:
#Use Pandas to load the union_settlements_1995.csv dataset.
csv_file = "/Users/Jerry/Downloads/union_settlements_1995.csv"
union_df = pd.read_csv(csv_file)
30/10:
#Use Pandas to load the union_settlements_1995.csv dataset.
csv_file = "/Users/Jerry/Downloads/union_settlements_1995.csv"
union_df = pd.read_csv(csv_file)
30/11:
#import depencies
import matplotlib.pyplot as plt
import numpy as np
import pandas as pd
%matplotlib notebook
30/12:
#Use Pandas to load the union_settlements_1995.csv dataset.
csv_file = "/Users/Jerry/Downloads/union_settlements_1995.csv"
union_df = pd.read_csv(csv_file)
30/13:
#Use Pandas to load the union_settlements_1995.csv dataset.
csv_file = "/Users/Jerry/Downloads/union_settlements_1995.csv"
union_df = pd.read_csv(csv_file)
union_df.head()
30/14:
 # Get total settlements by union
(len(union_df["NEGOTIATION NUMBER"])).count
30/15:
 # Get total settlements by union
(len(union_df["NEGOTIATION NUMBER"]))
30/16:
 # Get total settlements by union
len(union_df["NEGOTIATION NUMBER"])
30/17:
 # Get total settlements by union
num_of_settlements = len(union_df["NEGOTIATION NUMBER"])
30/18: num_sets = union_df["COMPANY IDENTIFYING INFORMATION"].value_counts()
30/19: union_df["COMPANY IDENTIFYING INFORMATION"].value_counts()
30/20: union_df.columns()
30/21: union_df.columns
30/22: union_df["COMPANY IDENTIFYING INFORMATION"].value_counts()
30/23: union_df["UNION"]
30/24: union_df["UNION"].value_counts()
30/25: num_of_settlements = len(union_df["NEGOTIATION NUMBER"])
30/26:
 # Get total settlements by union
union_df["UNION"].value_counts()
30/27:
 # Get total settlements by union
union_settlements = union_df["UNION"].value_counts()
30/28:
 # Get total settlements by union
union_settlements = union_df["UNION"].value_counts()
union_settlements
30/29: type(union_settlements)
30/30: np.arange(len(union_settlements))
30/31: x_axis = np.arange(len(union_settlements))
30/32: union_df["UNION"].unique()
30/33:
x_axis = np.arange(len(union_settlements))
unions = ['ELEVATOR CONSTRUCTORS', 'ACTORS EQUITY ASSOCIATION',
       'BAKERY, CONFECTIONERY WORKERS INTERNATIONAL UNION OF AMERICA',
       'AIR LINE PILOTS', 'CLOTHING AND TEXTILE WORKERS', 'AUTO WORKERS']
30/34:
# Configure plot, figsize, title, and axis labels
plt.bar(x_axis, union_settlements, color = "r", align = "center")

# Configure x-tick rotation


# Show plot
30/35:
# Configure plot, figsize, title, and axis labels
plt.bar(x_axis, union_settlements, color = "r", align = "center")

# Configure x-tick rotation
tick_locations = [value for value in x_axis]

# Show plot
30/36:
# Configure plot, figsize, title, and axis labels
plt.bar(x_axis, union_settlements, color = "r", align = "center")

# Configure x-tick rotation
tick_locations = [value for value in x_axis]
plt.xticks(tick_locations, unions)
# Show plot
30/37:
# Configure plot, figsize, title, and axis labels
plt.bar(x_axis, union_settlements, color = "r", align = "center")

# Configure x-tick rotation
tick_locations = [value for value in x_axis]
plt.xticks(tick_locations, unions, rotation = 45)
# Show plot
30/38:
 # Get total settlements by union
union_settlements = union_df["UNION"].value_counts()
union_settlements = union_settlements.set_index("UNION")
30/39:
 # Get total settlements by union
union_settlements = union_df["UNION"].value_counts()
union_settlements
30/40: union_settlements
30/41: union_table["Union Name"] = union_settlements
30/42: union_table = union_df['UNION']
30/43:
union_table = union_df['UNION']
union_table
30/44: plt.tight_layout()
30/45:
#import depencies
import matplotlib.pyplot as plt
import numpy as np
import pandas as pd
%matplotlib notebook
30/46:
#03-Stu_Settlements-PlottingPandas
#Union Settlements
#Create a bar chart that visualizes the total number of major collective bargaining settlements by union.

#In other words, you need to determine how many settlements were made by each union.
30/47:
#Use Pandas to load the union_settlements_1995.csv dataset.
csv_file = "/Users/Jerry/Downloads/union_settlements_1995.csv"
union_df = pd.read_csv(csv_file)
union_df.head()
30/48:
 # Get total settlements by union
union_settlements = union_df["UNION"].value_counts()
union_settlements
30/49:
x_axis = np.arange(len(union_settlements))
unions = ['ELEVATOR CONSTRUCTORS', 'ACTORS EQUITY ASSOCIATION',
       'BAKERY, CONFECTIONERY WORKERS INTERNATIONAL UNION OF AMERICA',
       'AIR LINE PILOTS', 'CLOTHING AND TEXTILE WORKERS', 'AUTO WORKERS']
30/50:
# Configure plot, figsize, title, and axis labels
plt.bar(x_axis, union_settlements, color = "r", align = "center")

# Configure x-tick rotation
tick_locations = [value for value in x_axis]
plt.xticks(tick_locations, unions, rotation = 45)
plt.title("Number of Settlements by Union")
plt
# Show plot
30/51:
# Configure plot, figsize, title, and axis labels
plt.bar(x_axis, union_settlements, color = "r", align = "center")

# Configure x-tick rotation
tick_locations = [value for value in x_axis]
plt.xticks(tick_locations, unions, rotation = 45)
plt.title("Number of Settlements by Union")
# Show plot
31/1:
#import dependcies
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
%matplotlib notebook
31/2: csv_file = "/Users/Jerry/Downloads/library_usage.csv"
31/3:
csv_file = "/Users/Jerry/Downloads/library_usage.csv"
library_df = pd.read_csv(csv_file)
31/4: library_df.head()
31/5: library.columns
31/6: library_df.columns
31/7: library_df["Patron Type Definition"].unique()
31/8: patron_data = library_df["Patron Type Definition"].value_counts()
31/9:
patron_data = library_df["Patron Type Definition"].value_counts()
patron_data
31/10:
#Create a bar chart by using Pandas and Matplotlib that visualizes how many patrons checked
#out items by patron type.

active_patrons = library_df.loc[library_df["Total Checkouts"] > 0, :]
31/11: active_patrons
31/12: active_patrons["Patron Type Definition"].value_counts()
31/13: active_data = active_patrons["Patron Type Definition"].value_counts()
31/14:
active_data = active_patrons["Patron Type Definition"].value_counts()
active_data
31/15:
active_data.plot(kind = "bar", color = "b", figsize=(8,6),
                title = "Use of the library by patron group",
                 xlabel = "Patrons",
                 ylabel = "Number of Patrons")
31/16:
figure_1 = active_data.plot(kind = "bar", color = "b", figsize=(8,6),
                title = "Use of the library by patron group",
                 xlabel = "Patrons",
                 ylabel = "Number of Patrons")
31/17: plt.tight_layout()
31/18:
csv_file = "library_usage.csv"
library_df = pd.read_csv(csv_file)
31/19:
csv_file = "/Users/Jerry/Downloads/library_usage.csv"
library_df = pd.read_csv(csv_file)
28/98:
# % overall passing (the percentage of students who passed math AND reading

#A variable to hold the students who pass math and reading
passing_both = 0

#A for loop to count the number of students who pass math and reading

for rscore, mscore in zip(students_df["reading_score"].rscore, students_df["math_score"].mscore):
    if rscore >= 70: 
        if mscore >=70:
            #if (rscore >= 70 && mscore >= 70):
            passing_both = passing_both + 1
28/99: students_df.tail()
28/100: students_df
28/101:
new_students_df = students_df[["Student ID", "reading_score", "math_score"]]

#students_df.loc[students_df['']]
28/102: students_df
28/103:
new_students_df = students_df[["Student ID", "reading_score", "math_score"]]
new_students_df = students_df.loc[students_df['reading_score'] >= 70]
28/104: new_students_df
28/105:
new_students_df = students_df[["Student ID", "reading_score", "math_score"]]
new_students_df = students_df.loc[students_df['reading_score'] >= 70]
28/106: new_students_df
28/107:
new_students_df = students_df[["Student ID", "reading_score", "math_score"]]
new_students_df = students_df.loc[students_df['reading_score'] >= 70]
28/108: new_students_df
28/109:
new_students_df = students_df[["Student ID", "reading_score", "math_score"]]
new_students_table = students_df.loc[students_df['reading_score'] >= 70]
28/110: new_students_table
28/111:
new_students_df = students_df[["Student ID", "reading_score", "math_score"]]
#new_students_table = students_df.loc[students_df['reading_score'] >= 70]
28/112: new_students_table
28/113:
#import dependencies
import pandas as pd
import numpy as np
28/114:
#import csv files
csv_students = "/Users/Jerry/Documents/Homework/students_complete.csv"
csv_schools = "/Users/Jerry/Documents/Homework/schools_complete.csv"
csv_purchases = "/Users/Jerry/Documents/Homework/purchase_data.csv"

students_df = pd.read_csv(csv_students)
schools_df = pd.read_csv(csv_schools)
purchases_df = pd.read_csv(csv_purchases)

#combine the data into a singe dataset
school_data_complete = pd.merge(students_df, schools_df, how = "left", on=["school_name", "school_name"])
28/115: new_students_df
28/116:
new_students_df = students_df[["Student ID", "reading_score", "math_score"]]
new_students_table = students_df.loc[students_df['reading_score'] >= 70]
28/117:
new_students_df = students_df[["Student ID", "reading_score", "math_score"]]
new_students_table = new_students_df.loc[new_students_df['reading_score'] >= 70]
28/118: new_students_df
28/119: new_students_df.head()
28/120: new_students_df.tails()
28/121: new_students_df.tails()
28/122: new_students_df.head()
28/123: new_students_df.tail()
28/124: new_students_df.head()
28/125: new_students_df.tail()
28/126:
#Total students
total_students = students_df["Student ID"].count()
total_students
(f"Total students: {total_students}")
28/127:
#% passing reading (the percentage of students who passed reading)

#create a variable to hold the number of students passing reading
reading_passing = 0

#create a for loop to count the number of students who passed reading 
for scores in students_df["reading_score"]:
    if scores >= 70:
        reading_passing = reading_passing + 1
        
# check if reading_passing populates correctly
#reading passing

#The percent of student who passed reading district wide
percent_passing_reading = round((reading_passing / total_students), 2)

#check if percent_passing_reading populates correctly
percent_passing_reading
28/128:
#% passing reading (the percentage of students who passed reading)

#create a variable to hold the number of students passing reading
reading_passing = 0

#create a for loop to count the number of students who passed reading 
for scores in students_df["reading_score"]:
    if scores >= 70:
        reading_passing = reading_passing + 1
        
# check if reading_passing populates correctly
#reading_passing

#The percent of student who passed reading district wide
percent_passing_reading = round((reading_passing / total_students), 2)

#check if percent_passing_reading populates correctly
percent_passing_reading

reading_passing
28/129:
new_students_df = students_df[["Student ID", "reading_score", "math_score"]]
new_students_table = new_students_df.loc[new_students_df['reading_score'] > 70, :]
28/130: new_students_df.tail()
28/131:
new_students_df = students_df[["Student ID", "reading_score", "math_score"]]
new_students_table = new_students_df.loc[new_students_df['math_score'] >= 70, :]
28/132: new_students_df.tail()
28/133:
new_students_df = students_df[["Student ID", "reading_score", "math_score"]]
new_students_table = new_students_df.loc[new_students_df['math_score'] > 95, :]
28/134: new_students_df.tail()
28/135:
new_students_df = students_df[["Student ID", "reading_score", "math_score"]]
new_students_table = new_students_df.loc[new_students_df['math_score'] >= 70, :]
28/136: new_students_table.tail()
28/137:
new_students_df = students_df[["Student ID", "reading_score", "math_score"]]
students_table = new_students_df.iloc[new_students_df['math_score'] >= 70, :]
28/138:
new_students_df = students_df[["Student ID", "reading_score", "math_score"]]
students_table = new_students_df.loc[new_students_df['math_score'] >= 70, :]
28/139: students_table["Student ID"].count()
28/140:
# % passing math (the percentage of students who passed math)

#create a for loop to count the students who have a passing math score
math_passing = 0

for scores in students_df["math_score"]:
    if scores >= 70:
        math_passing = math_passing + 1
        
#now compare math_passing to total students 
percent_passing_math = round((math_passing / total_students), 2)

math_passing
28/141:
new_students_df = students_df[["Student ID", "reading_score", "math_score"]]
students_table = new_students_df.loc[new_students_df["math_score"] >= 70, :]
students_table = new_students_table.loc[new_students_table["reading_score"] >= 70, :]
28/142:
students_table["Student ID"].count()
#29370
28/143:

new_students_df = students_df[["Student ID", "reading_score", "math_score"]]
students_table = new_students_df.loc[new_students_df["math_score"] >= 70, :]
students_table = new_students_table.loc[new_students_table["reading_score"] >= 70, :]

students_table
28/144:
# % overall passing (the percentage of students who passed math AND reading

#Filter main df "students_df" to essential columns
filtered_students_df = students_df[["Student ID", "reading_score", "math_score"]]

#Filter new 
students_table = filtered_students_df.loc[filtered_students_df["math_score"] >= 70, :]
students_table = students_table.loc[students_table["reading_score"] >= 70, :]
28/145:


students_table
28/146: students_table["Student ID"].count()
28/147:
# % overall passing (the percentage of students who passed math AND reading

#Filter main df "students_df" to essential columns
filtered_students_df = students_df[["Student ID", "reading_score", "math_score"]]

#Filter out students who didn't pass math with a 70 or higher
students_table = filtered_students_df.loc[filtered_students_df["math_score"] >= 70, :]

#filter out students who didn't pass reading either with a 70 or higher

students_table = students_table.loc[students_table["reading_score"] >= 70, :]

#run check to see number of students who passed math AND reading
#create a variable for this number
passing_mr = students_table["Student ID"].count()
28/148:
# % overall passing (the percentage of students who passed math AND reading

#Filter main df "students_df" to essential columns
filtered_students_df = students_df[["Student ID", "reading_score", "math_score"]]

#Filter out students who didn't pass math with a 70 or higher
students_table = filtered_students_df.loc[filtered_students_df["math_score"] >= 70, :]

#filter out students who didn't pass reading either with a 70 or higher

students_table = students_table.loc[students_table["reading_score"] >= 70, :]

#run check to see number of students who passed math AND reading
#create a variable for total number
passing_mr = students_table["Student ID"].count()

#compare this number with total number of students. 
#note m = math and r = reading
percentage_passing_mr = passing_mr / total_students
28/149: percentage_passing_mr
28/150:
# % overall passing (the percentage of students who passed math AND reading

#Filter main df "students_df" to essential columns
filtered_students_df = students_df[["Student ID", "reading_score", "math_score"]]

#Filter out students who didn't pass math with a 70 or higher
students_table = filtered_students_df.loc[filtered_students_df["math_score"] >= 70, :]

#filter out students who didn't pass reading either with a 70 or higher

students_table = students_table.loc[students_table["reading_score"] >= 70, :]

#run a check to see the number of students who passed math AND reading
#create a variable for this number
passing_mr = students_table["Student ID"].count()

#compare this number with total number of students. 
#note m = math and r = reading
percentage_passing_mr = round((passing_mr / total_students), 2)
28/151: percentage_passing_mr
28/152:
#Create a dataframe to hold the above results
#check data type of total_students
##type(total_schools)

d = {'Total Schools':[total_schools], 'Total Students':[total_students], 'Total Budget':[total_budget], 'Average Math Score':[avg_math_score], 'Average Reading Score':[avg_reading_score], '% Passing Math':[percent_passing_math], '% Passing Reading':[percent_passing_reading], '% Overall Passing':[percentage_passing_mr]}
district_summary_df = pd.DataFrame(data = d)
#data = d, index = [0,1,2,3]
28/153: district_summary_df
28/154:
#Create a dataframe to hold the above results
#check data type of total_students
##type(total_schools)

d = {'Total Schools':[total_schools], 'Total Students':[total_students], 
     'Total Budget':[total_budget], 'Average Math Score':[avg_math_score], 
     'Average Reading Score':[avg_reading_score], '% Passing Math':[percent_passing_math], 
     '% Passing Reading':[percent_passing_reading], '% Overall Passing':[percentage_passing_mr]}
district_summary_df = pd.DataFrame(data = d)
#data = d, index = [0,1,2,3]
28/155: district_summary_df
28/156:
#% passing reading (the percentage of students who passed reading)

#create a variable to hold the number of students passing reading
reading_passing = 0

#create a for loop to count the number of students who passed reading 
for scores in students_df["reading_score"]:
    if scores >= 70:
        reading_passing = reading_passing + 1
        
# check if reading_passing populates correctly
#reading_passing

#The percent of student who passed reading district wide
percent_passing_reading = round((reading_passing / total_students), 2)

#check if percent_passing_reading populates correctly
percent_passing_reading
28/157: f"The percentage of students who passed reading: %{percent_passing_reading}"
28/158:
# % passing math (the percentage of students who passed math)

#create a for loop to count the students who have a passing math score
math_passing = 0

for scores in students_df["math_score"]:
    if scores >= 70:
        math_passing = math_passing + 1
        
#now compare math_passing to total students 
percent_passing_math = round((math_passing / total_students), 2)
28/159:
percent_passing_math
(f"The percentage of students who passed math: %{percent_passing_math}")
28/160:
#Average reading score
avg_reading_score = round((students_df["reading_score"].mean()), 2)
(f"Average reading score {avg_reading_score}")
28/161:
#Average math score
#round to the hundrednth decimal place
avg_math_score = round((students_df["math_score"].mean()), 2)
#(f" {}")

(f"Average math score: {avg_math_score}")
28/162:
#Total budget
total_budget = schools_df["budget"].sum()
(f"Total Budget: {total_budget}")
28/163:
#Total schools
total_schools = schools_df["school_name"].count()
total_schools
(f"Total Schools: {total_schools}")
28/164: school_data_complete.head()
28/165: schools_df.tail()
28/166: school_array = schools_df["school_name"].unique()
28/167:
#school_array = 
schools_df["school_name"]
28/168:
school_array = schools_df["school_name"].sort_values(by = "school_name", ascending = True)

#How to sort a column by ascending order 
#df.sort_values(by='col1', ascending=True)
28/169:
school_array = schools_df["school_name"].sort_values(ascending = True)

#How to sort a column by ascending order 
#df.sort_values(by='col1', ascending=True)
28/170:
school_array = schools_df["school_name"].sort_values(ascending = True)

#How to sort a column by ascending order 
#df.sort_values(by='col1', ascending=True)
28/171:
school_array = schools_df["school_name"].sort_values(ascending = True)

#How to sort a column by ascending order 
#df.sort_values(by='col1', ascending=True)
school_array
28/172:
data = np.array([[1], [2], [3], [4], [5], [6], [7], [8], [9], [10], [11], [12], [13], [14], [15]])

#use df3 to check if the index component works
df3 = pd.DataFrame(data, columns = ['School type'], index = [school_array])
df3
28/173: schools_df["type"].sum()
28/174:
#schools_df["type"].sum()
#schools_df.head()
28/175:
#schools_df["type"].sum()
schools_df.head()
28/176:
#schools_df["size"].sum()
schools_df.head()
28/177:
schools_df["size"].sum()
#schools_df.head()
28/178:
#schools_df["size"].sum()
schools_df.head()
28/179:
#bailey_list = 
students_df[["school_name", "type", "size", "budget"]]
28/180:
#bailey_list = 
filtered_schools_df = schools_df[["school_name", "type", "size", "budget"]]
28/181:
#bailey_list = 
filtered_schools_df = schools_df[["school_name", "type", "size", "budget"]]

pd.merge(df3, filtered_schools_df, how = "left", on=["school_name", "school_name"])
28/182:
#bailey_list = 
filtered_schools_df = schools_df[["school_name", "type", "size", "budget"]]

df3 = pd.merge(df3, filtered_schools_df, how = "left", on=["school_name", "school_name"])

#df3.set_index('ID', inplace=True)
28/183:
#bailey_list = 
filtered_schools_df = schools_df[["school_name", "type", "size", "budget"]]

df3 = pd.merge(df3, filtered_schools_df, how = "left", on=["school_name", "school_name"])

df3.set_index('School_name', inplace=True)
28/184:
#bailey_list = 
filtered_schools_df = schools_df[["school_name", "type", "size", "budget"]]

df3 = pd.merge(df3, filtered_schools_df, how = "left", on=["school_name", "school_name"])

df3.set_index('school_name', inplace=True)
28/185:
#bailey_list = 
filtered_schools_df = schools_df[["school_name", "type", "size", "budget"]]

df3 = pd.merge(df3, filtered_schools_df, how = "left", on=["school_name", "school_name"])

df3.set_index('school_name', inplace=True)
df3
28/186:
#bailey_list = 
filtered_schools_df = schools_df[["school_name", "type", "size", "budget"]]

#df3 = pd.merge(df3, filtered_schools_df, how = "left", on=["school_name", "school_name"])

#df3.set_index('school_name', inplace=True)
df3
28/187:
#bailey_list = 
filtered_schools_df = schools_df[["school_name", "type", "size", "budget"]]

df3 = pd.merge(df3, filtered_schools_df, how = "left", on=["school_name", "school_name"])

#df3.set_index('school_name', inplace=True)
df3
28/188:
#bailey_list = 
filtered_schools_df = schools_df[["school_name", "type", "size", "budget"]]

df3 = pd.merge(df3, filtered_schools_df, how = "right", on=["school_name", "school_name"])

#df3.set_index('school_name', inplace=True)
df3
28/189:
data = np.array([[1], [2], [3], [4], [5], [6], [7], [8], [9], [10], [11], [12], [13], [14], [15]])

#use df3 to check if the index component works
df3 = pd.DataFrame(data, columns = ['School type'], index = [school_array])
df3
28/190:
#bailey_list = 
filtered_schools_df = schools_df[["school_name", "type", "size", "budget"]]

#df3 = pd.merge(df3, filtered_schools_df, how = "right", on=["school_name", "school_name"])

#df3.set_index('school_name', inplace=True)
df3
28/191:
#bailey_list = 
filtered_schools_df = schools_df[["school_name", "type", "size", "budget"]]

df4 = pd.merge(df3, filtered_schools_df, how = "right", on=["school_name", "school_name"])

#df3.set_index('school_name', inplace=True)
df3
28/192:
#bailey_list = 
filtered_schools_df = schools_df[["school_name", "type", "size", "budget"]]

df4 = pd.merge(df3, filtered_schools_df, how = "right", on=["school_name", "school_name"])

#df3.set_index('school_name', inplace=True)
df4
28/193:
#bailey_list = 
filtered_schools_df = schools_df[["school_name", "type", "size", "budget"]]

df4 = pd.merge(df3, filtered_schools_df, how = "right", on=["school_name", "school_name"])

#df4.set_index('school_name', inplace=True)
df4
28/194:
#bailey_list = 
filtered_schools_df = schools_df[["school_name", "type", "size", "budget"]]

df4 = pd.merge(df3, filtered_schools_df, how = "right", on=["school_name", "school_name"])

df4.set_index('school_name', inplace=True)
df4
28/195:
#bailey_list = 
filtered_schools_df = schools_df[["school_name", "type", "size", "budget"]]

df4 = pd.merge(df3, filtered_schools_df, how = "right", on=["school_name", "school_name"])

df4["school_name"].sort_values(ascending = True)

df4.set_index('school_name', inplace=True)

df4
28/196:
#bailey_list = 
filtered_schools_df = schools_df[["school_name", "type", "size", "budget"]]

#df4 = pd.merge(df3, filtered_schools_df, how = "right", on=["school_name", "school_name"])

#df4["school_name"].sort_values(ascending = True)

#df4.set_index('school_name', inplace=True)

df4
28/197:
#bailey_list = 
filtered_schools_df = schools_df[["school_name", "type", "size", "budget"]]

df4 = pd.merge(df3, filtered_schools_df, how = "right", on=["school_name", "school_name"])

#df4["school_name"].sort_values(ascending = True)

#df4.set_index('school_name', inplace=True)

df4
28/198:
#bailey_list = 
filtered_schools_df = schools_df[["school_name", "type", "size", "budget"]]

df4 = pd.merge(df3, filtered_schools_df, how = "right", on=["school_name", "school_name"])

df4["school_name"].sort_values(ascending = True)

#df4.set_index('school_name', inplace=True)

df4
28/199:
#bailey_list = 
filtered_schools_df = schools_df[["school_name", "type", "size", "budget"]]

df4 = pd.merge(df3, filtered_schools_df, how = "right", on=["school_name", "school_name"])

df4["school_name"].sort_values(ascending = True)

#df4.set_index('school_name', inplace=True)

df4
28/200:
#Create an overview table that summarizes key metrics about each school, including:

#How to sort a column by ascending order 
#df.sort_values(by='col1', ascending=True)
school_array = schools_df["school_name"].sort_values(ascending = True)

#column= 'School type', 'Total Students', 'Total School Budget', 'Per Student Budget', 'Average Math Score', 'Average Reading Score', '% Passing Math', '% Passing Reading', '% Overall Passing'])
28/201:
#Create an overview table that summarizes key metrics about each school, including:

#How to sort a column by ascending order 
#df.sort_values(by='col1', ascending=True)
school_array = schools_df["school_name"].sort_values(ascending = True)

#column= 'School type', 'Total Students', 'Total School Budget', 'Per Student Budget', 'Average Math Score', 'Average Reading Score', '% Passing Math', '% Passing Reading', '% Overall Passing'])
school_array
28/202:
#bailey_list = 
filtered_schools_df = schools_df[["school_name", "type", "size", "budget"]]

df4 = pd.merge(df3, filtered_schools_df, how = "right", on=["school_name", "school_name"])

df4.sort_values(by="school_name", ascending=True)

#df4.set_index('school_name', inplace=True)

df4
28/203:
#bailey_list = 
filtered_schools_df = schools_df[["school_name", "type", "size", "budget"]]

df4 = pd.merge(df3, filtered_schools_df, how = "right", on=["school_name", "school_name"])

df4.sort_values(by="school_name", ascending=True)

#df4.set_index('school_name', inplace=True)

df4
28/204:
#bailey_list = 
filtered_schools_df = schools_df[["school_name", "type", "size", "budget"]]

df4 = pd.merge(df3, filtered_schools_df, how = "right", on=["school_name", "school_name"])

df4.sort_values(by = 'school_name', ascending=True)

#df4.set_index('school_name', inplace=True)

df4
28/205:
#bailey_list = 
filtered_schools_df = schools_df[["school_name", "type", "size", "budget"]]

df4 = pd.merge(df3, filtered_schools_df, how = "right", on=["school_name", "school_name"])

df5 = df4.sort_values(by = 'school_name', ascending=True)

#df4.set_index('school_name', inplace=True)

df5
28/206:
#bailey_list = 
filtered_schools_df = schools_df[["school_name", "type", "size", "budget"]]

df4 = pd.merge(df3, filtered_schools_df, how = "right", on=["school_name", "school_name"])

df5 = df4.sort_values(by = 'school_name', ascending=True)

df5.set_index('school_name', inplace=True)

df5
28/207:
#bailey_list = 
filtered_schools_df = schools_df[["school_name", "type", "size", "budget"]]

df4 = pd.merge(df3, filtered_schools_df, how = "right", on=["school_name", "school_name"])

df4 = df4.sort_values(by = 'school_name', ascending=True)

df4.set_index('school_name', inplace=True)

df4
28/208:
#import dependencies
import pandas as pd
import numpy as np
28/209:
#import csv files
csv_students = "/Users/Jerry/Documents/Homework/students_complete.csv"
csv_schools = "/Users/Jerry/Documents/Homework/schools_complete.csv"
csv_purchases = "/Users/Jerry/Documents/Homework/purchase_data.csv"

students_df = pd.read_csv(csv_students)
schools_df = pd.read_csv(csv_schools)
purchases_df = pd.read_csv(csv_purchases)

#combine the data into a singe dataset
school_data_complete = pd.merge(students_df, schools_df, how = "left", on=["school_name", "school_name"])
28/210:
#Total schools
total_schools = schools_df["school_name"].count()
total_schools
(f"Total Schools: {total_schools}")
28/211:
#Total students
total_students = students_df["Student ID"].count()
total_students
(f"Total students: {total_students}")
28/212:
#Total budget
total_budget = schools_df["budget"].sum()
(f"Total Budget: {total_budget}")
28/213:
#Average math score
#round to the hundrednth decimal place
avg_math_score = round((students_df["math_score"].mean()), 2)
#(f" {}")

(f"Average math score: {avg_math_score}")
28/214:
#Average reading score
avg_reading_score = round((students_df["reading_score"].mean()), 2)
(f"Average reading score {avg_reading_score}")
28/215:
# % passing math (the percentage of students who passed math)

#create a for loop to count the students who have a passing math score
math_passing = 0

for scores in students_df["math_score"]:
    if scores >= 70:
        math_passing = math_passing + 1
        
#now compare math_passing to total students 
percent_passing_math = round((math_passing / total_students), 2)
28/216:
#% passing reading (the percentage of students who passed reading)

#create a variable to hold the number of students passing reading
reading_passing = 0

#create a for loop to count the number of students who passed reading 
for scores in students_df["reading_score"]:
    if scores >= 70:
        reading_passing = reading_passing + 1
        
# check if reading_passing populates correctly
#reading_passing

#The percent of student who passed reading district wide
percent_passing_reading = round((reading_passing / total_students), 2)

#check if percent_passing_reading populates correctly
percent_passing_reading
28/217:
# % passing math (the percentage of students who passed math)

#create a for loop to count the students who have a passing math score
math_passing = 0

for scores in students_df["math_score"]:
    if scores >= 70:
        math_passing = math_passing + 1
        
#now compare math_passing to total students 
percent_passing_math = round((math_passing / total_students), 2)
28/218:
#% passing reading (the percentage of students who passed reading)

#create a variable to hold the number of students passing reading
reading_passing = 0

#create a for loop to count the number of students who passed reading 
for scores in students_df["reading_score"]:
    if scores >= 70:
        reading_passing = reading_passing + 1
        
# check if reading_passing populates correctly
#reading_passing

#The percent of student who passed reading district wide
percent_passing_reading = round((reading_passing / total_students), 2)

#check if percent_passing_reading populates correctly
percent_passing_reading
28/219:
# % overall passing (the percentage of students who passed math AND reading

#Filter main df "students_df" to essential columns
filtered_students_df = students_df[["Student ID", "reading_score", "math_score"]]

#Filter out students who didn't pass math with a 70 or higher
students_table = filtered_students_df.loc[filtered_students_df["math_score"] >= 70, :]

#filter out students who didn't pass reading either with a 70 or higher

students_table = students_table.loc[students_table["reading_score"] >= 70, :]

#run a check to see the number of students who passed math AND reading
#create a variable for this number
passing_mr = students_table["Student ID"].count()

#compare this number with total number of students. 
#note m = math and r = reading
percentage_passing_mr = round((passing_mr / total_students), 2)
28/220: percentage_passing_mr
28/221:
#Create a dataframe to hold the above results
#check data type of total_students
##type(total_schools)

d = {'Total Schools':[total_schools], 'Total Students':[total_students], 
     'Total Budget':[total_budget], 'Average Math Score':[avg_math_score], 
     'Average Reading Score':[avg_reading_score], '% Passing Math':[percent_passing_math], 
     '% Passing Reading':[percent_passing_reading], '% Overall Passing':[percentage_passing_mr]}
district_summary_df = pd.DataFrame(data = d)

#data = d, index = [0,1,2,3]
28/222: district_summary_df
28/223:
#bailey_list = 
filtered_schools_df = schools_df[["school_name", "type", "size", "budget"]]

df4 = pd.merge(df3, filtered_schools_df, how = "right", on=["school_name", "school_name"])

df4 = df4.sort_values(by = 'school_name', ascending=True)

df4.set_index('school_name', inplace=True)

df4
28/224:
#bailey_list = 
filtered_schools_df = schools_df[["school_name", "type", "size", "budget"]]

#df4 = pd.merge(df3, filtered_schools_df, how = "right", on=["school_name", "school_name"])

#df4 = df4.sort_values(by = 'school_name', ascending=True)
filtered_schools_df = filtered_schools_df.sort_values(by = 'school_name', ascending=True)
#df4.set_index('school_name', inplace=True)
filtered_schools_df.set_index('school_name', inplace=True)
#df4
filtered_schools_df
28/225:
#schools_df["size"].sum()
schools_df.head()
28/226:
#Create an overview table that summarizes key metrics about each school, including:

#create a two column df with school name and total budget
merge_total_stu_budget = schools_df[["school_name", "budget"]]
28/227:
#Create an overview table that summarizes key metrics about each school, including:

#create a two column df with school name and total budget
merge_total_stu_budget = schools_df[["school_name", "budget"]]
merge_total_stu_budget
28/228:
#Create an overview table that summarizes key metrics about each school, including:

#create a two column df with school name and total budget
merge_total_stu_budget = schools_df[["school_name", "budget", "size"]]
merge_total_stu_budget
28/229:
#Create an overview table that summarizes key metrics about each school, including:

#create a two column df with school name and total budget
merge_total_stu_budget = schools_df[["school_name", "budget", "size"]]
merge_total_stu_budget["Per student budget"] = (schools_df["budget"])/(schools_df["size"])
28/230:
#Create an overview table that summarizes key metrics about each school, including:

#create a two column df with school name and total budget
merge_total_stu_budget = schools_df[["school_name", "budget", "size"]]
merge_total_stu_budget["Per student budget"] = (schools_df["budget"])/(schools_df["size"])
merge_total_stu_budget
28/231:
#Create an overview table that summarizes key metrics about each school, including:

#create a two column df with school name and total budget
budget = schools_df[["school_name", "budget", "size"]]
budget["Per student budget"] = (schools_df["budget"])/(schools_df["size"])
budget
#merge_total_stu_budget = budget[["school_name", "Per student budget"]]
28/232:
#Create an overview table that summarizes key metrics about each school, including:

#create a two column df with school name and total budget
budget = schools_df[["school_name", "budget", "size"]]
budget["per student budget"] = (schools_df["budget"])/(schools_df["size"])
budget
merge_total_stu_budget = budget[["school_name", "per student budget"]]
28/233:
#Create an overview table that summarizes key metrics about each school, including:

#create a two column df with school name and total budget
budget = schools_df[["school_name", "budget", "size"]]
budget["per student budget"] = (schools_df["budget"])/(schools_df["size"])
budget
merge_total_stu_budget = budget[["school_name", "per student budget"]]
merge_total_stu_budget
28/234:
#School Summary
school_data_complete.head()
28/235:
#Create a df with avg math and reading score, % passing in math and reading, overall passing
#grades_df = 
bailey_df = school_data_complete.loc[school_data_complete["school_name"] = "Bailey High School", :]
bailey_df
28/236:
#Create a df with avg math and reading score, % passing in math and reading, overall passing
#grades_df = 
bailey_df = school_data_complete.loc[school_data_complete["school_name"]] = "Bailey High School", :]
bailey_df
28/237:
#Create a df with avg math and reading score, % passing in math and reading, overall passing
#grades_df = 
bailey_df = school_data_complete.loc[school_data_complete["school_name"] = "Bailey High School", :]
bailey_df

#students_table = filtered_students_df.loc[filtered_students_df["math_score"] >= 70, :]
28/238:
#Create a df with avg math and reading score, % passing in math and reading, overall passing
#grades_df = 
bailey_df = school_data_complete.loc[school_data_complete["school_name"] == "Bailey High School", :]
bailey_df

#students_table = filtered_students_df.loc[filtered_students_df["math_score"] >= 70, :]
28/239:
#Create a df with avg math and reading score, % passing in math and reading, overall passing
#grades_df = 
bailey_df = school_data_complete.loc[school_data_complete["school_name"] == "Bailey High School", :]
#bailey_df

bailey_df["reading_score"].sum()
28/240:
#Create a df with avg math and reading score, % passing in math and reading, overall passing
#grades_df = 
bailey_df = school_data_complete.loc[school_data_complete["school_name"] == "Bailey High School", :]
#bailey_df

(bailey_df["reading_score"].sum())/(bailey_df["size"])
28/241:
#Create a df with avg math and reading score, % passing in math and reading, overall passing
#grades_df = 
bailey_df = school_data_complete.loc[school_data_complete["school_name"] == "Bailey High School", :]
#bailey_df

b_size = 4976

(bailey_df["reading_score"].sum())/(b_size)
28/242:
#Create a df with avg math and reading score, % passing in math and reading, overall passing
#grades_df = 
bailey_df = school_data_complete.loc[school_data_complete["school_name"] == "Bailey High School", :]
#bailey_df

b_size = 4976

round((bailey_df["reading_score"].sum())/(b_size), 2)
28/243:
#Create a df with avg math and reading score, % passing in math and reading, overall passing
#grades_df = 
bailey_df = school_data_complete.loc[school_data_complete["school_name"] == "Bailey High School", :]
#bailey_df

b_size = 4976

(bailey_df["reading_score"].sum())/(b_size)
28/244:
#Create a df with avg math and reading score, % passing in math and reading, overall passing
#grades_df = 
bailey_df = school_data_complete.loc[school_data_complete["school_name"] == "Bailey High School", :]
#bailey_df

b_size = 4976

round((bailey_df["reading_score"].sum())/(b_size), 6)
28/245:
#Create an overview table that summarizes key metrics about each school, including:

#create a two column df with school name and total budget 
#create a column for per student budget
budget = schools_df[["school_name", "budget", "size"]]
budget["per student budget"] = (schools_df["budget"])/(schools_df["size"])
#budget
#merge this df with the final df later on
merge_total_stu_budget = budget[["school_name", "per student budget"]]
merge_total_stu_budget
28/246:
#Create an overview table that summarizes key metrics about each school, including:

#create a two column df with school name, size and total budget 
#create a column for per student budget
budget = schools_df[["school_name", "budget", "size"]]
budget["per student budget"] = (schools_df["budget"])/(schools_df["size"])
budget
#merge this df with the final df later on
merge_total_stu_budget = budget[["school_name", "per student budget"]]
#merge_total_stu_budget
28/247:
#Create an overview table that summarizes key metrics about each school, including:

#create a two column df with school name, size and total budget 
#create a column for per student budget
budget = schools_df[["school_name", "budget", "size"]]
budget["per student budget"] = (schools_df["budget"])/(schools_df["size"])
budget
#merge this df with the final df later on
merge_total_stu_budget = budget[["school_name", "per student budget"]]
#merge_total_stu_budget
28/248:
#Create an overview table that summarizes key metrics about each school, including:

#create a two column df with school name, size and total budget 
#create a column for per student budget
budget = schools_df[["school_name", "budget", "size"]]
budget["per student budget"] = (schools_df["budget"])/(schools_df["size"])
#budget
#merge this df with the final df later on
merge_total_stu_budget = budget[["school_name", "per student budget"]]
merge_total_stu_budget
28/249:
#Create an overview table that summarizes key metrics about each school, including:

#create a two column df with school name, size and total budget 
#create a column for per student budget
budget = schools_df[["school_name", "budget", "size"]]
budget["per student budget"] = (schools_df["budget"])/(schools_df["size"])
#budget
#merge this df with the final df later on
merge_total_stu_budget = budget[["school_name", "per student budget"]]
merge_total_stu_budget
28/250:

filtered_schools_df = schools_df[["school_name", "type", "size", "budget"]]

filtered_schools_df = pd.merge(filtered_schools_df, merge_total_stu_budget, how = "left", on=["school_name", "school_name"])

#filtered_schools_df = filtered_schools_df.sort_values(by = 'school_name', ascending=True)

#filtered_schools_df.set_index('school_name', inplace=True)

filtered_schools_df
28/251:

filtered_schools_df = schools_df[["school_name", "type", "size", "budget"]]

filtered_schools_df = pd.merge(filtered_schools_df, merge_total_stu_budget, how = "left", on=["school_name", "school_name"])

filtered_schools_df = filtered_schools_df.sort_values(by = 'school_name', ascending=True)

#filtered_schools_df.set_index('school_name', inplace=True)

filtered_schools_df
28/252:

filtered_schools_df = schools_df[["school_name", "type", "size", "budget"]]

filtered_schools_df = pd.merge(filtered_schools_df, merge_total_stu_budget, how = "left", on=["school_name", "school_name"])

filtered_schools_df = filtered_schools_df.sort_values(by = 'school_name', ascending=True)

filtered_schools_df.set_index('school_name', inplace=True)

filtered_schools_df
28/253:
#Create a df with avg math and reading score, % passing in math and reading, overall passing
#grades_df = 
bailey_df = school_data_complete.loc[school_data_complete["school_name"] == "Bailey High School", :]
#bailey_df

b_size = 4976

br_score = round((bailey_df["reading_score"].sum())/(b_size), 6)
bm_score = round((bailey_df["math_score"].sum())/(b_size), 6)

#cabrera_df = school_data_complete.loc[school_data_complete["school_name"] == "Cabrera High School", :]
28/254:
#Create a df with avg math and reading score, % passing in math and reading, overall passing
#grades_df = 
bailey_df = school_data_complete.loc[school_data_complete["school_name"] == "Bailey High School", :]
#bailey_df

b_size = 4976

br_score = round((bailey_df["reading_score"].sum())/(b_size), 6)
bm_score = round((bailey_df["math_score"].sum())/(b_size), 6)

#cabrera_df = school_data_complete.loc[school_data_complete["school_name"] == "Cabrera High School", :]


bm_score
28/255: students_df
28/256:
#m_avg = bailey_df[""].mean()
#r_avg = bailey_df[""].mean()
bm_avg = bailey_df["reading_score"].mean()
br_avg = bailey_df["math_score"].mean()
28/257:
#m_avg = bailey_df[""].mean()
#r_avg = bailey_df[""].mean()
bm_avg = bailey_df["reading_score"].mean()
br_avg = bailey_df["math_score"].mean()

bm_avg
28/258:
#m_avg = bailey_df[""].mean()
#r_avg = bailey_df[""].mean()
bm_avg = bailey_df["reading_score"].mean()
br_avg = bailey_df["math_score"].mean()

bm_avg
br_avg
28/259:
#Create a df with avg math and reading score, % passing in math and reading, overall passing

#first obtain 
bailey_df = school_data_complete.loc[school_data_complete["school_name"] == "Bailey High School", :]
bailey_df

#bm_avg = bailey_df["reading_score"].mean()
#br_avg = bailey_df["math_score"].mean()
32/1:
#import dependencies
import pandas as pd
import numpy as np
32/2:
#Create an overview table that summarizes key metrics about each school, including:

#create a two column df with school name, size and total budget 
#create a column for per student budget
budget = schools_df[["school_name", "budget", "size"]]
budget["per student budget"] = (schools_df["budget"])/(schools_df["size"])
#budget
#merge this df with the final df later on
merge_total_stu_budget = budget[["school_name", "per student budget"]]
merge_total_stu_budget
32/3:
#import dependencies
import pandas as pd
import numpy as np
32/4:
#import csv files
csv_students = "/Users/Jerry/Documents/Homework/students_complete.csv"
csv_schools = "/Users/Jerry/Documents/Homework/schools_complete.csv"
csv_purchases = "/Users/Jerry/Documents/Homework/purchase_data.csv"

students_df = pd.read_csv(csv_students)
schools_df = pd.read_csv(csv_schools)
purchases_df = pd.read_csv(csv_purchases)

#combine the data into a singe dataset
school_data_complete = pd.merge(students_df, schools_df, how = "left", on=["school_name", "school_name"])
32/5:
#Create an overview table that summarizes key metrics about each school, including:

#create a two column df with school name, size and total budget 
#create a column for per student budget
budget = schools_df[["school_name", "budget", "size"]]
budget["per student budget"] = (schools_df["budget"])/(schools_df["size"])
#budget
#merge this df with the final df later on
merge_total_stu_budget = budget[["school_name", "per student budget"]]
merge_total_stu_budget
32/6:
#Create a df with avg math and reading score, % passing in math and reading, overall passing

#first create adf with just the bailery school
bailey_df = school_data_complete.loc[school_data_complete["school_name"] == "Bailey High School", :]

#next find the averages of reading and math scores
bm_avg = bailey_df["reading_score"].mean()
br_avg = bailey_df["math_score"].mean()

#find the % passing Math in bailey high
32/7: school_data_complete.head()
32/8: schools_df
32/9:
#Create a df with avg math and reading score, % passing in math and reading, overall passing

#first create adf with just the bailery school
bailey_df = school_data_complete.loc[school_data_complete["school_name"] == "Bailey High School", :]

#next find the averages of reading and math scores
bm_avg = bailey_df["reading_score"].mean()
br_avg = bailey_df["math_score"].mean()

#find the % passing Math in bailey high
#create a for loop to count the students who have a passing math score
bailey_m_passing = 0

for scores in bailey_df["math_score"]:
    if scores >= 70:
        bailey_m_passing = bailey_m_passing + 1
bailey_m_passing
#now compare math_passing to total students 
#bailey_percent_m = round((bailey_m_passing / total_students), 6)
32/10:
#Create a df with avg math and reading score, % passing in math and reading, overall passing

#first create adf with just the bailery school
bailey_df = school_data_complete.loc[school_data_complete["school_name"] == "Bailey High School", :]

#next find the averages of reading and math scores
bm_avg = bailey_df["reading_score"].mean()
br_avg = bailey_df["math_score"].mean()

#find the % passing Math in bailey high
#create a for loop to count the students who have a passing math score
bailey_m_passing = 0

for scores in bailey_df["math_score"]:
    if scores >= 70:
        bailey_m_passing = bailey_m_passing + 1
bailey_m_passing
#now compare math_passing to total students 
bailey_percent_m = round((bailey_m_passing / size[0]), 6)
32/11:
#Create a df with avg math and reading score, % passing in math and reading, overall passing

#first create adf with just the bailery school
bailey_df = school_data_complete.loc[school_data_complete["school_name"] == "Bailey High School", :]

#next find the averages of reading and math scores
bm_avg = bailey_df["reading_score"].mean()
br_avg = bailey_df["math_score"].mean()

#find the % passing Math in bailey high
#create a for loop to count the students who have a passing math score
bailey_m_passing = 0

for scores in bailey_df["math_score"]:
    if scores >= 70:
        bailey_m_passing = bailey_m_passing + 1
bailey_m_passing
#now compare math_passing to total students 
bailey_percent_m = round((bailey_m_passing / bailey_df["size[0]"]), 6)
32/12:
#Create a df with avg math and reading score, % passing in math and reading, overall passing

#first create adf with just the bailery school
bailey_df = school_data_complete.loc[school_data_complete["school_name"] == "Bailey High School", :]

#next find the averages of reading and math scores
bm_avg = bailey_df["reading_score"].mean()
br_avg = bailey_df["math_score"].mean()

#find the % passing Math in bailey high
#create a for loop to count the students who have a passing math score
bailey_m_passing = 0

for scores in bailey_df["math_score"]:
    if scores >= 70:
        bailey_m_passing = bailey_m_passing + 1
bailey_m_passing
#now compare math_passing to total students 
bailey_percent_m = round((bailey_m_passing / bailey_df["size"]), 6)
32/13:
#Create a df with avg math and reading score, % passing in math and reading, overall passing

#first create adf with just the bailery school
bailey_df = school_data_complete.loc[school_data_complete["school_name"] == "Bailey High School", :]

#next find the averages of reading and math scores
bm_avg = bailey_df["reading_score"].mean()
br_avg = bailey_df["math_score"].mean()

#find the % passing Math in bailey high
#create a for loop to count the students who have a passing math score
bailey_m_passing = 0

for scores in bailey_df["math_score"]:
    if scores >= 70:
        bailey_m_passing = bailey_m_passing + 1
bailey_m_passing
#now compare math_passing to total students 
bailey_percent_m = round((bailey_m_passing / bailey_df["size"]), 6)
bailey_percent_m
32/14:
#Create a df with avg math and reading score, % passing in math and reading, overall passing

#first create adf with just the bailery school
bailey_df = school_data_complete.loc[school_data_complete["school_name"] == "Bailey High School", :]

#next find the averages of reading and math scores
bm_avg = bailey_df["reading_score"].mean()
br_avg = bailey_df["math_score"].mean()

#find the % passing Math in bailey high
#create a for loop to count the students who have a passing math score
bailey_m_passing = 0

for scores in bailey_df["math_score"]:
    if scores >= 70:
        bailey_m_passing = bailey_m_passing + 1
bailey_m_passing
#now compare math_passing to total students 
bailey_percent_m = round((bailey_m_passing / bailey_df["size"][0]), 6)
bailey_percent_m
32/15:
#Create a df with avg math and reading score, % passing in math and reading, overall passing

#first create adf with just the bailery school
bailey_df = school_data_complete.loc[school_data_complete["school_name"] == "Bailey High School", :]

#next find the averages of reading and math scores
bm_avg = bailey_df["reading_score"].mean()
br_avg = bailey_df["math_score"].mean()

#find the % passing Math in bailey high
#create a for loop to count the students who have a passing math score
bailey_m_passing = 0

for scores in bailey_df["math_score"]:
    if scores >= 70:
        bailey_m_passing = bailey_m_passing + 1
bailey_m_passing
#now compare math_passing to total students 
bailey_percent_m = round((bailey_m_passing / bailey_df["size"]), 6)
bailey_percent_m[0]
32/16:
#Create a df with avg math and reading score, % passing in math and reading, overall passing

#first create adf with just the bailery school
bailey_df = school_data_complete.loc[school_data_complete["school_name"] == "Bailey High School", :]

#next find the averages of reading and math scores
bm_avg = bailey_df["reading_score"].mean()
br_avg = bailey_df["math_score"].mean()

#find the % passing Math in bailey high
#create a for loop to count the students who have a passing math score
bailey_m_passing = 0

for scores in bailey_df["math_score"]:
    if scores >= 70:
        bailey_m_passing = bailey_m_passing + 1
bailey_m_passing
#now compare math_passing to total students 
bailey_percent_m = round((bailey_m_passing / bailey_df["size"]), 6)
bailey_percent_m
32/17:
#Create a df with avg math and reading score, % passing in math and reading, overall passing

#first create adf with just the bailery school
bailey_df = school_data_complete.loc[school_data_complete["school_name"] == "Bailey High School", :]

#next find the averages of reading and math scores
bm_avg = bailey_df["reading_score"].mean()
br_avg = bailey_df["math_score"].mean()

#find the % passing Math in bailey high
#create a for loop to count the students who have a passing math score
bailey_m_passing = 0

for scores in bailey_df["math_score"]:
    if scores >= 70:
        bailey_m_passing = bailey_m_passing + 1
bailey_m_passing
#now compare math_passing to total students 
bailey_percent_m = round((bailey_m_passing / bailey_df.ix[0, 'size']), 6)
bailey_percent_m
#df.ix['B',4]
32/18:
#Cabrera High School
#first create adf with just the cabrera school
cabrera_df = school_data_complete.loc[school_data_complete["school_name"] == "Cabrera High School", :]
32/19:
#Cabrera High School
#first create adf with just the cabrera school
cabrera_df = school_data_complete.loc[school_data_complete["school_name"] == "Cabrera High School", :]

#next find the averages of reading and math scores
cm_avg = cabrera_df["reading_score"].mean()
cr_avg = cabrera_df["math_score"].mean()
32/20:
#Cabrera High School
#first create adf with just the cabrera school
cabrera_df = school_data_complete.loc[school_data_complete["school_name"] == "Cabrera High School", :]

#next find the averages of reading and math scores
cm_avg = cabrera_df["reading_score"].mean()
cr_avg = cabrera_df["math_score"].mean()

#find the % passing Math in cabrera high
#create a for loop to count the students who have a passing math score
cabrera_m_passing = 0

for scores in cabrera_df["math_score"]:
    if scores >= 70:
        cabrera_m_passing = cabrera_m_passing + 1
cabrera_m_passing
32/21:
#Create a df with avg math and reading score, % passing in math and reading, overall passing

#first create adf with just the bailery school
bailey_df = school_data_complete.loc[school_data_complete["school_name"] == "Bailey High School", :]

#next find the averages of reading and math scores
bm_avg = bailey_df["reading_score"].mean()
br_avg = bailey_df["math_score"].mean()

#find the % passing Math in bailey high
#create a for loop to count the students who have a passing math score
bailey_m_passing = 0

for scores in bailey_df["math_score"]:
    if scores >= 70:
        bailey_m_passing = bailey_m_passing + 1
bailey_m_passing
#now compare math_passing to total students 
#bailey_percent_m = round((bailey_m_passing / ), 6)
32/22:
#Cabrera High School
#first create adf with just the cabrera school
cabrera_df = school_data_complete.loc[school_data_complete["school_name"] == "Cabrera High School", :]

#next find the averages of reading and math scores
cm_avg = cabrera_df["reading_score"].mean()
cr_avg = cabrera_df["math_score"].mean()

#find the % passing Math in cabrera high
#create a for loop to count the students who have a passing math score
cabrera_m_passing = 0

for scores in cabrera_df["math_score"]:
    if scores >= 70:
        cabrera_m_passing = cabrera_m_passing + 1
cabrera_m_passing
#now compare math_passing to total students 
#cabrera_percent_m = round((cabrera_m_passing / ), 6)
32/23:
#Figueroa High School
#first create adf with just the Figueroa school
figueroa_df = school_data_complete.loc[school_data_complete["school_name"] == "Figueroa High School", :]

#next find the averages of reading and math scores
figm_avg = figueroa_df["reading_score"].mean()
figr_avg = figueroa_df["math_score"].mean()

#find the % passing Math in figueroa high
#create a for loop to count the students who have a passing math score
figueroa_m_passing = 0

for scores in figueroa_df["math_score"]:
    if scores >= 70:
        figueroa_m_passing = figueroa_m_passing + 1
figueroa_m_passing
#now compare math_passing to total students 
#figueroa_percent_m = round((figueroa_m_passing / ), 6)
32/24:
#Ford High School
#first create adf with just the Ford school
ford_df = school_data_complete.loc[school_data_complete["school_name"] == "Ford High School", :]

#next find the averages of reading and math scores
figm_avg = ford_df["reading_score"].mean()
figr_avg = ford_df["math_score"].mean()

#find the % passing Math in ford high
#create a for loop to count the students who have a passing math score
ford_m_passing = 0

for scores in ford_df["math_score"]:
    if scores >= 70:
        ford_m_passing = ford_m_passing + 1
ford_m_passing
#now compare math_passing to total students 
#ford_percent_m = round((figueroa_m_passing / ), 6)
32/25:
#import dependencies
import pandas as pd
import numpy as np
32/26:
#import csv files
csv_students = "/Users/Jerry/Documents/Homework/students_complete.csv"
csv_schools = "/Users/Jerry/Documents/Homework/schools_complete.csv"
csv_purchases = "/Users/Jerry/Documents/Homework/purchase_data.csv"

students_df = pd.read_csv(csv_students)
schools_df = pd.read_csv(csv_schools)
purchases_df = pd.read_csv(csv_purchases)

#combine the data into a singe dataset
school_data_complete = pd.merge(students_df, schools_df, how = "left", on=["school_name", "school_name"])
32/27:
#Create a df with avg math and reading score, % passing in math and reading, overall passing

#first create adf with just the bailery school
bailey_df = school_data_complete.loc[school_data_complete["school_name"] == "Bailey High School", :]

#next find the averages of reading and math scores
bm_avg = bailey_df["reading_score"].mean()
br_avg = bailey_df["math_score"].mean()

#find the % passing Math in bailey high
#create a for loop to count the students who have a passing math score
bailey_m_passing = 0

for scores in bailey_df["math_score"]:
    if scores >= 70:
        bailey_m_passing = bailey_m_passing + 1
bailey_m_passing
#now compare math_passing to total students 
#bailey_percent_m = round((bailey_m_passing / ), 6)
32/28:
#Cabrera High School
#first create adf with just the cabrera school
cabrera_df = school_data_complete.loc[school_data_complete["school_name"] == "Cabrera High School", :]

#next find the averages of reading and math scores
cm_avg = cabrera_df["reading_score"].mean()
cr_avg = cabrera_df["math_score"].mean()

#find the % passing Math in cabrera high
#create a for loop to count the students who have a passing math score
cabrera_m_passing = 0

for scores in cabrera_df["math_score"]:
    if scores >= 70:
        cabrera_m_passing = cabrera_m_passing + 1
cabrera_m_passing
#now compare math_passing to total students 
#cabrera_percent_m = round((cabrera_m_passing / ), 6)
32/29:
#Figueroa High School
#first create adf with just the Figueroa school
figueroa_df = school_data_complete.loc[school_data_complete["school_name"] == "Figueroa High School", :]

#next find the averages of reading and math scores
figm_avg = figueroa_df["reading_score"].mean()
figr_avg = figueroa_df["math_score"].mean()

#find the % passing Math in figueroa high
#create a for loop to count the students who have a passing math score
figueroa_m_passing = 0

for scores in figueroa_df["math_score"]:
    if scores >= 70:
        figueroa_m_passing = figueroa_m_passing + 1
figueroa_m_passing
#now compare math_passing to total students 
#figueroa_percent_m = round((figueroa_m_passing / ), 6)
32/30:
#Ford High School
#first create adf with just the Ford school
ford_df = school_data_complete.loc[school_data_complete["school_name"] == "Ford High School", :]

#next find the averages of reading and math scores
form_avg = ford_df["reading_score"].mean()
forr_avg = ford_df["math_score"].mean()

#find the % passing Math in ford high
#create a for loop to count the students who have a passing math score
ford_m_passing = 0

for scores in ford_df["math_score"]:
    if scores >= 70:
        ford_m_passing = ford_m_passing + 1
ford_m_passing
#now compare math_passing to total students 
#ford_percent_m = round((figueroa_m_passing / ), 6)
32/31:
#Bailey High School
#Create a df with avg math and reading score, % passing in math and reading, overall passing

#first create a df with just the bailery school
bailey_df = school_data_complete.loc[school_data_complete["school_name"] == "Bailey High School", :]

#next find the averages of reading and math scores
bm_avg = bailey_df["reading_score"].mean()
br_avg = bailey_df["math_score"].mean()

#find the % passing Math 
#create a for loop to count the students who have a passing math score
bailey_m_passing = 0

for scores in bailey_df["math_score"]:
    if scores >= 70:
        bailey_m_passing = bailey_m_passing + 1
bailey_m_passing

#% passing reading (the percentage of students who passed reading)
#create a variable to hold the number of students passing reading

bailey_r_passing = 0

#create a for loop to count the number of students who passed reading 
for scores in bailey_df["reading_score"]:
    if scores >= 70:
        bailey_r_passing = bailey_r_passing + 1
32/32:
#Cabrera High School
#first create adf with just the cabrera school
cabrera_df = school_data_complete.loc[school_data_complete["school_name"] == "Cabrera High School", :]

#next find the averages of reading and math scores
cm_avg = cabrera_df["reading_score"].mean()
cr_avg = cabrera_df["math_score"].mean()

#find the % passing Math in cabrera high
#create a for loop to count the students who have a passing math score
cabrera_m_passing = 0

for scores in cabrera_df["math_score"]:
    if scores >= 70:
        cabrera_m_passing = cabrera_m_passing + 1
cabrera_m_passing

#% passing reading (the percentage of students who passed reading)
#create a variable to hold the number of students passing reading

cabrera_r_passing = 0

#create a for loop to count the number of students who passed reading 
for scores in cabrera_df["reading_score"]:
    if scores >= 70:
        cabrera_r_passing = cabrera_r_passing + 1
32/33:
#Figueroa High School
#first create adf with just the Figueroa school
figueroa_df = school_data_complete.loc[school_data_complete["school_name"] == "Figueroa High School", :]

#next find the averages of reading and math scores
figm_avg = figueroa_df["reading_score"].mean()
figr_avg = figueroa_df["math_score"].mean()

#find the % passing Math in figueroa high
#create a for loop to count the students who have a passing math score
figueroa_m_passing = 0

for scores in figueroa_df["math_score"]:
    if scores >= 70:
        figueroa_m_passing = figueroa_m_passing + 1
figueroa_m_passing

#% passing reading (the percentage of students who passed reading)
#create a variable to hold the number of students passing reading

figueroa_r_passing = 0

#create a for loop to count the number of students who passed reading 
for scores in figueroa_df["reading_score"]:
    if scores >= 70:
        figueroa_r_passing = figueroa_r_passing + 1
32/34:
#Ford High School
#first create adf with just the Ford school
ford_df = school_data_complete.loc[school_data_complete["school_name"] == "Ford High School", :]

#next find the averages of reading and math scores
form_avg = ford_df["reading_score"].mean()
forr_avg = ford_df["math_score"].mean()

#find the % passing Math in ford high
#create a for loop to count the students who have a passing math score
ford_m_passing = 0

for scores in ford_df["math_score"]:
    if scores >= 70:
        ford_m_passing = ford_m_passing + 1
ford_m_passing

#% passing reading (the percentage of students who passed reading)
#create a variable to hold the number of students passing reading

ford_r_passing = 0

#create a for loop to count the number of students who passed reading 
for scores in ford_df["reading_score"]:
    if scores >= 70:
        ford_r_passing = ford_r_passing + 1
32/35:
#Griffin High School
#first create adf with just the Griffin school
griffin_df = school_data_complete.loc[school_data_complete["school_name"] == "Griffin High School", :]

#next find the averages of reading and math scores
gm_avg = griffin_df["reading_score"].mean()
gr_avg = griffin_df["math_score"].mean()

#find the % passing Math in griffin high
#create a for loop to count the students who have a passing math score
griffin_m_passing = 0

for scores in griffin_df["math_score"]:
    if scores >= 70:
        griffin_m_passing = griffin_m_passing + 1
griffin_m_passing

#% passing reading (the percentage of students who passed reading)
#create a variable to hold the number of students passing reading
griffin_r_passing = 0

#create a for loop to count the number of students who passed reading 
for scores in griffin_df["reading_score"]:
    if scores >= 70:
        griffin_r_passing = griffin_r_passing + 1
32/36:
#Hernandez High School
#Create a df with avg math and reading score, % passing in math and reading, overall passing

#first create a df with just the one school
hernandez_df = school_data_complete.loc[school_data_complete["school_name"] == "Hernandez High School", :]

#next find the averages of reading and math scores
herm_avg = hernandez_df["reading_score"].mean()
herr_avg = hernandez_df["math_score"].mean()

#find the % passing Math 
#create a for loop to count the students who have a passing math score
hernandez_m_passing = 0

for scores in hernandez_df["math_score"]:
    if scores >= 70:
        hernandez_m_passing = hernandez_m_passing + 1
hernandez_m_passing

#% passing reading (the percentage of students who passed reading)
#create a variable to hold the number of students passing reading

hernandez_r_passing = 0

#create a for loop to count the number of students who passed reading 
for scores in hernandez_df["reading_score"]:
    if scores >= 70:
        hernandez_r_passing = hernandez_r_passing + 1
32/37:
#Bailey High School
#Create a df with avg math and reading score, % passing in math and reading, overall passing

#first create a df with just the one school
bailey_df = school_data_complete.loc[school_data_complete["school_name"] == "Bailey High School", :]

#next find the averages of reading and math scores
br_avg = bailey_df["reading_score"].mean()
bm_avg = bailey_df["math_score"].mean()

#find the % passing Math 
#create a for loop to count the students who have a passing math score
bailey_m_passing = 0

for scores in bailey_df["math_score"]:
    if scores >= 70:
        bailey_m_passing = bailey_m_passing + 1
bailey_m_passing

#% passing reading (the percentage of students who passed reading)
#create a variable to hold the number of students passing reading

bailey_r_passing = 0

#create a for loop to count the number of students who passed reading 
for scores in bailey_df["reading_score"]:
    if scores >= 70:
        bailey_r_passing = bailey_r_passing + 1
32/38:
#Cabrera High School
#first create adf with just the cabrera school
cabrera_df = school_data_complete.loc[school_data_complete["school_name"] == "Cabrera High School", :]

#next find the averages of reading and math scores
cr_avg = cabrera_df["reading_score"].mean()
cm_avg = cabrera_df["math_score"].mean()

#find the % passing Math in cabrera high
#create a for loop to count the students who have a passing math score
cabrera_m_passing = 0

for scores in cabrera_df["math_score"]:
    if scores >= 70:
        cabrera_m_passing = cabrera_m_passing + 1
cabrera_m_passing

#% passing reading (the percentage of students who passed reading)
#create a variable to hold the number of students passing reading

cabrera_r_passing = 0

#create a for loop to count the number of students who passed reading 
for scores in cabrera_df["reading_score"]:
    if scores >= 70:
        cabrera_r_passing = cabrera_r_passing + 1
32/39:
#Figueroa High School
#first create adf with just the Figueroa school
figueroa_df = school_data_complete.loc[school_data_complete["school_name"] == "Figueroa High School", :]

#next find the averages of reading and math scores
figr_avg = figueroa_df["reading_score"].mean()
figm_avg = figueroa_df["math_score"].mean()

#find the % passing Math in figueroa high
#create a for loop to count the students who have a passing math score
figueroa_m_passing = 0

for scores in figueroa_df["math_score"]:
    if scores >= 70:
        figueroa_m_passing = figueroa_m_passing + 1
figueroa_m_passing

#% passing reading (the percentage of students who passed reading)
#create a variable to hold the number of students passing reading

figueroa_r_passing = 0

#create a for loop to count the number of students who passed reading 
for scores in figueroa_df["reading_score"]:
    if scores >= 70:
        figueroa_r_passing = figueroa_r_passing + 1
32/40:
#Ford High School
#first create adf with just the Ford school
ford_df = school_data_complete.loc[school_data_complete["school_name"] == "Ford High School", :]

#next find the averages of reading and math scores
forr_avg = ford_df["reading_score"].mean()
form_avg = ford_df["math_score"].mean()

#find the % passing Math in ford high
#create a for loop to count the students who have a passing math score
ford_m_passing = 0

for scores in ford_df["math_score"]:
    if scores >= 70:
        ford_m_passing = ford_m_passing + 1
ford_m_passing

#% passing reading (the percentage of students who passed reading)
#create a variable to hold the number of students passing reading

ford_r_passing = 0

#create a for loop to count the number of students who passed reading 
for scores in ford_df["reading_score"]:
    if scores >= 70:
        ford_r_passing = ford_r_passing + 1
32/41:
#Griffin High School
#first create adf with just the Griffin school
griffin_df = school_data_complete.loc[school_data_complete["school_name"] == "Griffin High School", :]

#next find the averages of reading and math scores
gr_avg = griffin_df["reading_score"].mean()
gm_avg = griffin_df["math_score"].mean()

#find the % passing Math in griffin high
#create a for loop to count the students who have a passing math score
griffin_m_passing = 0

for scores in griffin_df["math_score"]:
    if scores >= 70:
        griffin_m_passing = griffin_m_passing + 1
griffin_m_passing

#% passing reading (the percentage of students who passed reading)
#create a variable to hold the number of students passing reading
griffin_r_passing = 0

#create a for loop to count the number of students who passed reading 
for scores in griffin_df["reading_score"]:
    if scores >= 70:
        griffin_r_passing = griffin_r_passing + 1
32/42:
#Hernandez High School
#Create a df with avg math and reading score, % passing in math and reading, overall passing

#first create a df with just the one school
hernandez_df = school_data_complete.loc[school_data_complete["school_name"] == "Hernandez High School", :]

#next find the averages of reading and math scores
herr_avg = hernandez_df["reading_score"].mean()
herm_avg = hernandez_df["math_score"].mean()

#find the % passing Math 
#create a for loop to count the students who have a passing math score
hernandez_m_passing = 0

for scores in hernandez_df["math_score"]:
    if scores >= 70:
        hernandez_m_passing = hernandez_m_passing + 1
hernandez_m_passing

#% passing reading (the percentage of students who passed reading)
#create a variable to hold the number of students passing reading

hernandez_r_passing = 0

#create a for loop to count the number of students who passed reading 
for scores in hernandez_df["reading_score"]:
    if scores >= 70:
        hernandez_r_passing = hernandez_r_passing + 1
32/43:
#Holden High School
#Create a df with avg math and reading score, % passing in math and reading, overall passing

#first create a df with just the one school
holden_df = school_data_complete.loc[school_data_complete["school_name"] == "Holden High School", :]

#next find the averages of reading and math scores
holr_avg = holden_df["reading_score"].mean()
holm_avg = holden_df["math_score"].mean()

#find the % passing Math 
#create a for loop to count the students who have a passing math score
holden_m_passing = 0

for scores in holden_df["math_score"]:
    if scores >= 70:
        holden_m_passing = holden_m_passing + 1
holden_m_passing

#% passing reading (the percentage of students who passed reading)
#create a variable to hold the number of students passing reading

holden_r_passing = 0

#create a for loop to count the number of students who passed reading 
for scores in holden_df["reading_score"]:
    if scores >= 70:
        holden_r_passing = holden_r_passing + 1
32/44:
#Holden High School
#Create a df with avg math and reading score, % passing in math and reading, overall passing

#first create a df with just the one school
holden_df = school_data_complete.loc[school_data_complete["school_name"] == "Holden High School", :]

#next find the averages of reading and math scores
holr_avg = holden_df["reading_score"].mean()
holm_avg = holden_df["math_score"].mean()

#find the % passing Math 
#create a for loop to count the students who have a passing math score
holden_m_passing = 0

for scores in holden_df["math_score"]:
    if scores >= 70:
        holden_m_passing = holden_m_passing + 1
holden_m_passing

#% passing reading (the percentage of students who passed reading)
#create a variable to hold the number of students passing reading

holden_r_passing = 0

#create a for loop to count the number of students who passed reading 
for scores in holden_df["reading_score"]:
    if scores >= 70:
        holden_r_passing = holden_r_passing + 1
32/45:
#Huang High School
#Create a df with avg math and reading score, % passing in math and reading, overall passing

#first create a df with just the one school
huang_df = school_data_complete.loc[school_data_complete["school_name"] == "Huang High School", :]

#next find the averages of reading and math scores
huar_avg = huang_df["reading_score"].mean()
huam_avg = huang_df["math_score"].mean()

#find the % passing Math 
#create a for loop to count the students who have a passing math score
huang_m_passing = 0

for scores in huang_df["math_score"]:
    if scores >= 70:
        huang_m_passing = huang_m_passing + 1
huang_m_passing

#% passing reading (the percentage of students who passed reading)
#create a variable to hold the number of students passing reading

huang_r_passing = 0

#create a for loop to count the number of students who passed reading 
for scores in huang_df["reading_score"]:
    if scores >= 70:
        huang_r_passing = huang_r_passing + 1
32/46:
#Johnson High School
#Create a df with avg math and reading score, % passing in math and reading, overall passing

#first create a df with just the one school
johnson_df = school_data_complete.loc[school_data_complete["school_name"] == "Johnson High School", :]

#next find the averages of reading and math scores
jr_avg = johnson_df["reading_score"].mean()
jm_avg = johnson_df["math_score"].mean()

#find the % passing Math 
#create a for loop to count the students who have a passing math score
johnson_m_passing = 0

for scores in johnson_df["math_score"]:
    if scores >= 70:
        johnson_m_passing = johnson_m_passing + 1
johnson_m_passing

#% passing reading (the percentage of students who passed reading)
#create a variable to hold the number of students passing reading

johnson_r_passing = 0

#create a for loop to count the number of students who passed reading 
for scores in johnson_df["reading_score"]:
    if scores >= 70:
        johnson_r_passing = johnson_r_passing + 1
32/47:
#Pena High School
#Create a df with avg math and reading score, % passing in math and reading, overall passing

#first create a df with just the one school
pena_df = school_data_complete.loc[school_data_complete["school_name"] == "Pena High School", :]

#next find the averages of reading and math scores
pr_avg = pena_df["reading_score"].mean()
pm_avg = pena_df["math_score"].mean()

#find the % passing Math 
#create a for loop to count the students who have a passing math score
pena_m_passing = 0

for scores in pena_df["math_score"]:
    if scores >= 70:
        pena_m_passing = pena_m_passing + 1

#% passing reading (the percentage of students who passed reading)
#create a variable to hold the number of students passing reading

pena_r_passing = 0

#create a for loop to count the number of students who passed reading 
for scores in pena_df["reading_score"]:
    if scores >= 70:
        pena_r_passing = pena_r_passing + 1
32/48:
#Rodriguez High School
#Create a df with avg math and reading score, % passing in math and reading, overall passing

#first create a df with just the one school
rodriguez_df = school_data_complete.loc[school_data_complete["school_name"] == "Rodriguez High School", :]

#next find the averages of reading and math scores
rr_avg = rodriguez_df["reading_score"].mean()
rm_avg = rodriguez_df["math_score"].mean()

#find the % passing Math 
#create a for loop to count the students who have a passing math score
rodriguez_m_passing = 0

for scores in rodriguez_df["math_score"]:
    if scores >= 70:
        rodriguez_m_passing = rodriguez_m_passing + 1

#% passing reading (the percentage of students who passed reading)
#create a variable to hold the number of students passing reading

rodriguez_r_passing = 0

#create a for loop to count the number of students who passed reading 
for scores in rodriguez_df["reading_score"]:
    if scores >= 70:
        rodriguez_r_passing = rodriguez_r_passing + 1
32/49:
#Shelton High School
#Create a df with avg math and reading score, % passing in math and reading, overall passing

#first create a df with just the one school
shelton_df = school_data_complete.loc[school_data_complete["school_name"] == "Shelton High School", :]

#next find the averages of reading and math scores
sr_avg = shelton_df["reading_score"].mean()
sm_avg = shelton_df["math_score"].mean()

#find the % passing Math 
#create a for loop to count the students who have a passing math score
shelton_m_passing = 0

for scores in shelton_df["math_score"]:
    if scores >= 70:
        shelton_m_passing = shelton_m_passing + 1

#% passing reading (the percentage of students who passed reading)
#create a variable to hold the number of students passing reading

shelton_r_passing = 0

#create a for loop to count the number of students who passed reading 
for scores in shelton_df["reading_score"]:
    if scores >= 70:
        shelton_r_passing = shelton_r_passing + 1
32/50:
#Shelton High School
#Create a df with avg math and reading score, % passing in math and reading, overall passing

#first create a df with just the one school
shelton_df = school_data_complete.loc[school_data_complete["school_name"] == "Shelton High School", :]

#next find the averages of reading and math scores
sr_avg = shelton_df["reading_score"].mean()
sm_avg = shelton_df["math_score"].mean()

#find the % passing Math 
#create a for loop to count the students who have a passing math score
shelton_m_passing = 0

for scores in shelton_df["math_score"]:
    if scores >= 70:
        shelton_m_passing = shelton_m_passing + 1

#% passing reading (the percentage of students who passed reading)
#create a variable to hold the number of students passing reading

shelton_r_passing = 0

#create a for loop to count the number of students who passed reading 
for scores in shelton_df["reading_score"]:
    if scores >= 70:
        shelton_r_passing = shelton_r_passing + 1
32/51:
#Thomas High School
#Create a df with avg math and reading score, % passing in math and reading, overall passing

#first create a df with just the one school
thomas_df = school_data_complete.loc[school_data_complete["school_name"] == "Thomas High School", :]

#next find the averages of reading and math scores
tr_avg = thomas_df["reading_score"].mean()
tm_avg = thomas_df["math_score"].mean()

#find the % passing Math 
#create a for loop to count the students who have a passing math score
thomas_m_passing = 0

for scores in thomas_df["math_score"]:
    if scores >= 70:
        thomas_m_passing = thomas_m_passing + 1

#% passing reading (the percentage of students who passed reading)
#create a variable to hold the number of students passing reading

thomas_r_passing = 0

#create a for loop to count the number of students who passed reading 
for scores in thomas_df["reading_score"]:
    if scores >= 70:
        thomas_r_passing = thomas_r_passing + 1
32/52:
#Wilson High School
#Create a df with avg math and reading score, % passing in math and reading, overall passing

#first create a df with just the one school
wilson_df = school_data_complete.loc[school_data_complete["school_name"] == "Wilson High School", :]

#next find the averages of reading and math scores
wr_avg = wilson_df["reading_score"].mean()
wm_avg = wilson_df["math_score"].mean()

#find the % passing Math 
#create a for loop to count the students who have a passing math score
wilson_m_passing = 0

for scores in wilson_df["math_score"]:
    if scores >= 70:
        wilson_m_passing = wilson_m_passing + 1

#% passing reading (the percentage of students who passed reading)
#create a variable to hold the number of students passing reading

wilson_r_passing = 0

#create a for loop to count the number of students who passed reading 
for scores in wilson_df["reading_score"]:
    if scores >= 70:
        wilson_r_passing = wilson_r_passing + 1
32/53:
#Wilson High School
#Create a df with avg math and reading score, % passing in math and reading, overall passing

#first create a df with just the one school
wilson_df = school_data_complete.loc[school_data_complete["school_name"] == "Wilson High School", :]

#next find the averages of reading and math scores
wilr_avg = wilson_df["reading_score"].mean()
wilm_avg = wilson_df["math_score"].mean()

#find the % passing Math 
#create a for loop to count the students who have a passing math score
wilson_m_passing = 0

for scores in wilson_df["math_score"]:
    if scores >= 70:
        wilson_m_passing = wilson_m_passing + 1

#% passing reading (the percentage of students who passed reading)
#create a variable to hold the number of students passing reading

wilson_r_passing = 0

#create a for loop to count the number of students who passed reading 
for scores in wilson_df["reading_score"]:
    if scores >= 70:
        wilson_r_passing = wilson_r_passing + 1
32/54:
#Wright High School
#Create a df with avg math and reading score, % passing in math and reading, overall passing

#first create a df with just the one school
wright_df = school_data_complete.loc[school_data_complete["school_name"] == "Wright High School", :]

#next find the averages of reading and math scores
wrir_avg = wright_df["reading_score"].mean()
wrim_avg = wright_df["math_score"].mean()

#find the % passing Math 
#create a for loop to count the students who have a passing math score
wright_m_passing = 0

for scores in wright_df["math_score"]:
    if scores >= 70:
        wright_m_passing = wright_m_passing + 1

#% passing reading (the percentage of students who passed reading)
#create a variable to hold the number of students passing reading

wright_r_passing = 0

#create a for loop to count the number of students who passed reading 
for scores in wright_df["reading_score"]:
    if scores >= 70:
        wright_r_passing = wright_r_passing + 1
32/55:
#Bailey High School
#Create a df with avg math and reading score, % passing in math and reading, overall passing

#first create a df with just the one school
bailey_df = school_data_complete.loc[school_data_complete["school_name"] == "Bailey High School", :]

#next find the averages of reading and math scores
br_avg = bailey_df["reading_score"].mean()
bm_avg = bailey_df["math_score"].mean()

#find the % passing Math 
#create a for loop to count the students who have a passing math score
bailey_m_passing = 0

for scores in bailey_df["math_score"]:
    if scores >= 70:
        bailey_m_passing = bailey_m_passing + 1
bailey_m_passing

#% passing reading (the percentage of students who passed reading)
#create a variable to hold the number of students passing reading

bailey_r_passing = 0

#create a for loop to count the number of students who passed reading 
for scores in bailey_df["reading_score"]:
    if scores >= 70:
        bailey_r_passing = bailey_r_passing + 1
        

# % overall passing (the percentage of students who passed math AND reading

#Filter out students who didn't pass math with a 70 or higher
b_students_table = bailey_df.loc[bailey_df["math_score"] >= 70, :]

#filter out students who didn't pass reading either with a 70 or higher

b_students_table = b_students_table.loc[b_students_table["reading_score"] >= 70, :]

#run a check to see the number of students who passed math AND reading
#create a variable for this number
b_passing_mr = b_students_table["Student ID"].count()
32/56:
#Bailey High School
#Create a df with avg math and reading score, % passing in math and reading, overall passing

#first create a df with just the one school
bailey_df = school_data_complete.loc[school_data_complete["school_name"] == "Bailey High School", :]

#next find the averages of reading and math scores
br_avg = bailey_df["reading_score"].mean()
bm_avg = bailey_df["math_score"].mean()

#find the % passing Math 
#create a for loop to count the students who have a passing math score
bailey_m_passing = 0

for scores in bailey_df["math_score"]:
    if scores >= 70:
        bailey_m_passing = bailey_m_passing + 1
bailey_m_passing

#% passing reading (the percentage of students who passed reading)
#create a variable to hold the number of students passing reading

bailey_r_passing = 0

#create a for loop to count the number of students who passed reading 
for scores in bailey_df["reading_score"]:
    if scores >= 70:
        bailey_r_passing = bailey_r_passing + 1
        

# % overall passing (the percentage of students who passed math AND reading

#Filter out students who didn't pass math with a 70 or higher
b_students_table = bailey_df.loc[bailey_df["math_score"] >= 70, :]

#filter out students who didn't pass reading either with a 70 or higher

b_students_table = b_students_table.loc[b_students_table["reading_score"] >= 70, :]

#run a check to see the number of students who passed math AND reading
#create a variable for this number
b_passing_mr = b_students_table["Student ID"].count()

b_passing_mr
32/57:
#Cabrera High School
#first create adf with just the cabrera school
cabrera_df = school_data_complete.loc[school_data_complete["school_name"] == "Cabrera High School", :]

#next find the averages of reading and math scores
cr_avg = cabrera_df["reading_score"].mean()
cm_avg = cabrera_df["math_score"].mean()

#find the % passing Math in cabrera high
#create a for loop to count the students who have a passing math score
cabrera_m_passing = 0

for scores in cabrera_df["math_score"]:
    if scores >= 70:
        cabrera_m_passing = cabrera_m_passing + 1
cabrera_m_passing

#% passing reading (the percentage of students who passed reading)
#create a variable to hold the number of students passing reading

cabrera_r_passing = 0

#create a for loop to count the number of students who passed reading 
for scores in cabrera_df["reading_score"]:
    if scores >= 70:
        cabrera_r_passing = cabrera_r_passing + 1
        
# % overall passing (the percentage of students who passed math AND reading

#Filter out students who didn't pass math with a 70 or higher
c_students_table = cabrera_df.loc[cabrera_df["math_score"] >= 70, :]

#filter out students who didn't pass reading either with a 70 or higher

c_students_table = c_students_table.loc[c_students_table["reading_score"] >= 70, :]

#run a check to see the number of students who passed math AND reading
#create a variable for this number
c_passing_mr = c_students_table["Student ID"].count()

c_passing_mr
32/58:
#Figueroa High School
#first create adf with just the Figueroa school
figueroa_df = school_data_complete.loc[school_data_complete["school_name"] == "Figueroa High School", :]

#next find the averages of reading and math scores
figr_avg = figueroa_df["reading_score"].mean()
figm_avg = figueroa_df["math_score"].mean()

#find the % passing Math in figueroa high
#create a for loop to count the students who have a passing math score
figueroa_m_passing = 0

for scores in figueroa_df["math_score"]:
    if scores >= 70:
        figueroa_m_passing = figueroa_m_passing + 1
figueroa_m_passing

#% passing reading (the percentage of students who passed reading)
#create a variable to hold the number of students passing reading

figueroa_r_passing = 0

#create a for loop to count the number of students who passed reading 
for scores in figueroa_df["reading_score"]:
    if scores >= 70:
        figueroa_r_passing = figueroa_r_passing + 1
        
# % overall passing (the percentage of students who passed math AND reading

#Filter out students who didn't pass math with a 70 or higher
fig_students_table = figueroa_df.loc[figueroa_df["math_score"] >= 70, :]

#filter out students who didn't pass reading either with a 70 or higher

fig_students_table = fig_students_table.loc[fig_students_table["reading_score"] >= 70, :]

#run a check to see the number of students who passed math AND reading
#create a variable for this number
fig_passing_mr = fig_students_table["Student ID"].count()

fig_passing_mr
33/1:
# % overall passing (the percentage of students who passed math AND reading

#Filter out students who didn't pass math with a 70 or higher
fig_students_table = figueroa_df.loc[figueroa_df["math_score"] >= 70, :]

#filter out students who didn't pass reading either with a 70 or higher

fig_students_table = fig_students_table.loc[fig_students_table["reading_score"] >= 70, :]

#run a check to see the number of students who passed math AND reading
#create a variable for this number
fig_passing_mr = fig_students_table["Student ID"].count()

fig_passing_mr
33/2:
# % overall passing (the percentage of students who passed math AND reading

#Filter out students who didn't pass math with a 70 or higher
students_table = school_data_complete.loc[school_data_complete["math_score"] >= 70, :]

#filter out students who didn't pass reading either with a 70 or higher

students_table = students_table.loc[students_table["reading_score"] >= 70, :]

#run a check to see the number of students who passed math AND reading
#create a variable for this number

#Bailey
bailey_df = students_table.loc[students_table["school_name"] == "Bailey High School", :]

b_passing_mr = students_table["Student ID"].count()

b_passing_mr
32/59:
# % overall passing (the percentage of students who passed math AND reading

#Filter out students who didn't pass math with a 70 or higher
students_table = school_data_complete.loc[school_data_complete["math_score"] >= 70, :]

#filter out students who didn't pass reading either with a 70 or higher

students_table = students_table.loc[students_table["reading_score"] >= 70, :]

#run a check to see the number of students who passed math AND reading
#create a variable for this number

#Bailey
bailey_df = students_table.loc[students_table["school_name"] == "Bailey High School", :]

b_passing_mr = students_table["Student ID"].count()

b_passing_mr
32/60:
#import dependencies
import pandas as pd
import numpy as np
32/61:
#import csv files
csv_students = "/Users/Jerry/Documents/Homework/students_complete.csv"
csv_schools = "/Users/Jerry/Documents/Homework/schools_complete.csv"
csv_purchases = "/Users/Jerry/Documents/Homework/purchase_data.csv"

students_df = pd.read_csv(csv_students)
schools_df = pd.read_csv(csv_schools)
purchases_df = pd.read_csv(csv_purchases)

#combine the data into a singe dataset
school_data_complete = pd.merge(students_df, schools_df, how = "left", on=["school_name", "school_name"])
32/62:
# % overall passing (the percentage of students who passed math AND reading

#Filter out students who didn't pass math with a 70 or higher
students_table = school_data_complete.loc[school_data_complete["math_score"] >= 70, :]

#filter out students who didn't pass reading either with a 70 or higher

students_table = students_table.loc[students_table["reading_score"] >= 70, :]

#run a check to see the number of students who passed math AND reading
#create a variable for this number

#Bailey
bailey_df = students_table.loc[students_table["school_name"] == "Bailey High School", :]

b_passing_mr = students_table["Student ID"].count()

b_passing_mr
32/63:
# % overall passing (the percentage of students who passed math AND reading

#Filter out students who didn't pass math with a 70 or higher
students_table = school_data_complete.loc[school_data_complete["math_score"] >= 70, :]

#filter out students who didn't pass reading either with a 70 or higher

students_table = students_table.loc[students_table["reading_score"] >= 70, :]

#run a check to see the number of students who passed math AND reading
#create a variable for this number

#Bailey
bailey_df = students_table.loc[students_table["school_name"] == "Bailey High School", :]

b_passing_mr = bailey_df["Student ID"].count()

b_passing_mr
32/64: schools_df.columns
32/65:
# % overall passing (the percentage of students who passed math AND reading

#Filter out students who didn't pass math with a 70 or higher
students_table = school_data_complete.loc[school_data_complete["math_score"] >= 70, :]

#filter out students who didn't pass reading either with a 70 or higher

students_table = students_table.loc[students_table["reading_score"] >= 70, :]

#run a check to see the number of students who passed math AND reading
#create a variable for this number

#Bailey
bailey_df = students_table.loc[students_table["school_name"] == "Bailey High School", :]

b_passing_mr = bailey_df["Student ID"].count()


#Cabrera
cabrera_df = students_table.loc[students_table["school_name"] == "Cabrera High School", :]

c_passing_mr = cabrera_df["Student ID"].count()

c_passing_mr
32/66: cebrera_df
32/67: cebrera_df.head()
28/260: students_df.head()
28/261:
# % passing math (the percentage of students who passed math)

#create a for loop to count the students who have a passing math score
math_passing = 0

for scores in students_df["math_score"]:
    if scores >= 70:
        math_passing = math_passing + 1
        
#now compare math_passing to total students 
percent_passing_math = round((math_passing / total_students), 2)
28/262:
# % passing math (the percentage of students who passed math)

#create a for loop to count the students who have a passing math score
math_passing = 0

for scores in students_df["math_score"]:
    if scores >= 70:
        math_passing = math_passing + 1
        
#now compare math_passing to total students 
percent_passing_math = round((math_passing / total_students), 2)

percent_passing_math
28/263:
# % passing math (the percentage of students who passed math)

#create a for loop to count the students who have a passing math score
math_passing = 0

for scores in students_df["math_score"]:
    if scores >= 70:
        math_passing = math_passing + 1
        
#now compare math_passing to total students 
percent_passing_math = round((math_passing / total_students), 4)

percent_passing_math
28/264: schools_df.head()
28/265: students_table.head()
32/68: school_data_complete.head()
32/69:
filtered_schools_df = schools_df[["school_name", "type", "size", "budget"]]

filtered_schools_df = pd.merge(filtered_schools_df, merge_total_stu_budget, how = "left", on=["school_name", "school_name"])

filtered_schools_df = filtered_schools_df.sort_values(by = 'school_name', ascending=True)

filtered_schools_df.set_index('school_name', inplace=True)

filtered_schools_df
32/70: mathrate = school_data_complete.groupby('school_name')['math_score'].mean()
32/71:
mathrate = school_data_complete.groupby('school_name')['math_score'].mean()
mathrate
32/72:
#Bailey High School
#Create a df with avg math and reading score, % passing in math and reading, overall passing

#first create a df with just the one school
select = school_data_complete.loc[(school_data_complete["school_name"] == "Bailey High School" & "Cabrera High School" ) 
                                  :]
32/73:
#Bailey High School
#Create a df with avg math and reading score, % passing in math and reading, overall passing

#first create a df with just the one school
select = school_data_complete.loc[(school_data_complete["school_name"] == "Bailey High School" & "Cabrera High School"), :]
32/74:
#Bailey High School
#Create a df with avg math and reading score, % passing in math and reading, overall passing

#first create a df with just the one school
select = school_data_complete.loc[(school_data_complete["school_name"] == "Bailey High School" &
                                   school_data_complete["school_name"] == "Cabrera High School"), :]
32/75:
#Bailey High School
#Create a df with avg math and reading score, % passing in math and reading, overall passing

#first create a df with just the one school
select = school_data_complete.loc[(school_data_complete["school_name"] == "Bailey High School") &
                                   (school_data_complete["school_name"] == "Cabrera High School"), :]
32/76:
#Bailey High School
#Create a df with avg math and reading score, % passing in math and reading, overall passing

#first create a df with just the one school
select = school_data_complete.loc[(school_data_complete["school_name"] == "Bailey High School") &
                                   (school_data_complete["school_name"] == "Cabrera High School"), :]
select.head()
32/77:
#Bailey High School
#Create a df with avg math and reading score, % passing in math and reading, overall passing

#first create a df with just the one school
select = school_data_complete.loc[(school_data_complete["school_name"] == "Bailey High School") |
                                   (school_data_complete["school_name"] == "Cabrera High School"), :]
select.head()
32/78: bailey_df.head()
32/79: br_avg
32/80: bm_avg
32/81: bailey_m_passing
32/82: bailey_m_passing/4976
32/83:
# % overall passing (the percentage of students who passed math AND reading

#Filter out students who didn't pass math with a 70 or higher
students_table = school_data_complete.loc[school_data_complete["math_score"] >= 70, :]

#filter out students who didn't pass reading either with a 70 or higher

students_table = students_table.loc[students_table["reading_score"] >= 70, :]

#run a check to see the number of students who passed math AND reading
#create a variable for this number

#Bailey
bailey_df = students_table.loc[students_table["school_name"] == "Bailey High School", :]

b_passing_mr = students_table["Student ID"].count()

b_passing_mr
32/84:
mathrate = school_data_complete.groupby('school_name')['math_score'].mean()
mathrate

readrate = school_data_complete.groupby('school_name')['math_score'].mean()
readrate
32/85: type(readrate)
32/86:
filtered_schools_df = pd.merge (filtered_schools_df, mathrate, right_index = True,
                                left_index = True)


# using pandas series merge()
#df = pd.merge(courses, fees, right_index = True,
              # left_index = True)
32/87:
filtered_schools_df = pd.merge (filtered_schools_df, mathrate, right_index = True,
                                left_index = True)

filtered_schools_df
# using pandas series merge()
#df = pd.merge(courses, fees, right_index = True,
              # left_index = True)
32/88:
filtered_schools_df = pd.merge (filtered_schools_df, mathrate, right_index = True)

filtered_schools_df
# using pandas series merge()
#df = pd.merge(courses, fees, right_index = True,
              # left_index = True)
32/89:
filtered_schools_df = pd.merge (filtered_schools_df, mathrate, right_index = True,
                                left_index = True)

filtered_schools
# using pandas series merge()
#df = pd.merge(courses, fees, right_index = True,
              # left_index = True)
32/90:
filtered_schools_df = pd.merge (filtered_schools_df, mathrate, right_index = True,
                                left_index = True)

filtered_schools_df
# using pandas series merge()
#df = pd.merge(courses, fees, right_index = True,
              # left_index = True)
32/91:
filtered_schools_df = schools_df[["school_name", "type", "size", "budget"]]

filtered_schools_df = pd.merge(filtered_schools_df, merge_total_stu_budget, how = "left", on=["school_name", "school_name"])

filtered_schools_df = filtered_schools_df.sort_values(by = 'school_name', ascending=True)

filtered_schools_df.set_index('school_name', inplace=True)

filtered_schools_df
32/92:
filtered_schools_df = schools_df[["school_name", "type", "size", "budget"]]

filtered_schools_df = pd.merge(filtered_schools_df, merge_total_stu_budget, how = "left", on=["school_name", "school_name"])

filtered_schools_df = filtered_schools_df.sort_values(by = 'school_name', ascending=True)

filtered_schools_df.set_index('school_name', inplace=True)

filtered_schools_df = pd.merge (filtered_schools_df, mathrate, right_index = True,
                                left_index = True)

filtered_schools_df
32/93:
filtered_schools_df = schools_df[["school_name", "type", "size", "budget"]]

filtered_schools_df = pd.merge(filtered_schools_df, merge_total_stu_budget, how = "left", on=["school_name", "school_name"])

filtered_schools_df = filtered_schools_df.sort_values(by = 'school_name', ascending=True)

filtered_schools_df.set_index('school_name', inplace=True)

filtered_schools_df = pd.merge (filtered_schools_df, mathrate, right_index = True,
                                left_index = True)
filtered_schools_df = pd.merge (filtered_schools_df, readrate, right_index = True,
                                left_index = True)

filtered_schools_df
32/94:
filtered_schools_df = schools_df[["school_name", "type", "size", "budget"]]

filtered_schools_df = pd.merge(filtered_schools_df, merge_total_stu_budget, how = "left", on=["school_name", "school_name"])

filtered_schools_df = filtered_schools_df.sort_values(by = 'school_name', ascending=True)

filtered_schools_df.set_index('school_name', inplace=True)

filtered_schools_df
32/95:
filtered_schools_df = pd.merge (filtered_schools_df, mathrate, right_index = True,
                                left_index = True)
filtered_schools_df = pd.merge (filtered_schools_df, readrate, right_index = True,
                                left_index = True)
32/96: filtered_schools_df
32/97:
filtered_schools_df = schools_df[["school_name", "type", "size", "budget"]]

filtered_schools_df = pd.merge(filtered_schools_df, merge_total_stu_budget, how = "left", on=["school_name", "school_name"])

filtered_schools_df = filtered_schools_df.sort_values(by = 'school_name', ascending=True)

filtered_schools_df.set_index('school_name', inplace=True)

filtered_schools_df
32/98: filtered_schools_df
32/99:
filtered_schools_df = pd.merge (filtered_schools_df, mathrate, right_index = True,
                                left_index = True)
32/100: filtered_schools_df
32/101:
filtered_schools_df = pd.merge (filtered_schools_df, readrate, right_index = True,
                                left_index = True)
32/102: filtered_schools_df
32/103:
mathrate = school_data_complete.groupby('school_name')['math_score'].mean()
mathrate

readrate = school_data_complete.groupby('school_name')['read_score'].mean()
readrate
32/104:
mathrate = school_data_complete.groupby('school_name')['math_score'].mean()
mathrate
32/105:
readrate = school_data_complete.groupby('school_name')['read_score'].mean()
readrate
32/106:
readrate = school_data_complete.groupby('school_name')['reading_score'].mean()
readrate
32/107:
filtered_schools_df = schools_df[["school_name", "type", "size", "budget"]]

filtered_schools_df = pd.merge(filtered_schools_df, merge_total_stu_budget, how = "left", on=["school_name", "school_name"])

filtered_schools_df = filtered_schools_df.sort_values(by = 'school_name', ascending=True)

filtered_schools_df.set_index('school_name', inplace=True)

filtered_schools_df
32/108:
filtered_schools_df = pd.merge (filtered_schools_df, mathrate, right_index = True,
                                left_index = True)
32/109:
filtered_schools_df = pd.merge (filtered_schools_df, readrate, right_index = True,
                                left_index = True)
32/110: filtered_schools_df
32/111:
# % overall passing (the percentage of students who passed math AND reading

#Filter out students who didn't pass math with a 70 or higher
students_table = school_data_complete.loc[(school_data_complete["math_score"] >= 70) &
                                          (school_data_complete["reading_score"] >= 70), :]

school_data_complete.groupby('school_name')['Student ID'].count()
32/112:
# % overall passing (the percentage of students who passed math AND reading

#Filter out students who didn't pass math with a 70 or higher
students_table = school_data_complete.loc[(school_data_complete["math_score"] >= 70) &
                                          (school_data_complete["reading_score"] >= 70), :]

school_data_complete.groupby('school_name')['Student ID'].count()
32/113:
# % overall passing (the percentage of students who passed math AND reading

#Filter out students who didn't pass math with a 70 or higher
students_table = school_data_complete.loc[(school_data_complete["math_score"] >= 70) &
                                          (school_data_complete["reading_score"] >= 70), :]

total_both_passing = school_data_complete.groupby('school_name')['Student ID'].count()

total_both_passing
32/114:
# % overall passing (the percentage of students who passed math AND reading

#Filter out students who didn't pass math with a 70 or higher
students_table = school_data_complete.loc[(school_data_complete["math_score"] >= 70) &
                                          (school_data_complete["reading_score"] >= 70), :]

total_both_passing = school_data_complete.groupby('school_name').count()

total_both_passing
32/115:
# % overall passing (the percentage of students who passed math AND reading

#Filter out students who didn't pass math with a 70 or higher
students_table = school_data_complete.loc[(school_data_complete["math_score"] >= 70) &
                                          (school_data_complete["reading_score"] >= 70), :]

total_both_passing = school_data_complete.groupby('school_name')['Student ID'].sum()

total_both_passing
32/116:
filtered_schools_df = schools_df[["school_name", "type", "size", "budget"]]

filtered_schools_df = pd.merge(filtered_schools_df, merge_total_stu_budget, how = "left", on=["school_name", "school_name"])

filtered_schools_df = filtered_schools_df.sort_values(by = 'school_name', ascending=True)

filtered_schools_df.set_index('school_name', inplace=True)

filtered_schools_df
32/117:
filtered_schools_df = pd.merge (filtered_schools_df, mathrate, right_index = True,
                                left_index = True)
32/118:
filtered_schools_df = pd.merge (filtered_schools_df, readrate, right_index = True,
                                left_index = True)
32/119: filtered_schools_df
32/120:
#import dependencies
import pandas as pd
import numpy as np
32/121:
#import csv files
csv_students = "/Users/Jerry/Documents/Homework/students_complete.csv"
csv_schools = "/Users/Jerry/Documents/Homework/schools_complete.csv"
csv_purchases = "/Users/Jerry/Documents/Homework/purchase_data.csv"

students_df = pd.read_csv(csv_students)
schools_df = pd.read_csv(csv_schools)
purchases_df = pd.read_csv(csv_purchases)

#combine the data into a singe dataset
school_data_complete = pd.merge(students_df, schools_df, how = "left", on=["school_name", "school_name"])
32/122:
#Create an overview table that summarizes key metrics about each school, including:

#create a two column df with school name, size and total budget 
#create a column for per student budget
budget = schools_df[["school_name", "budget", "size"]]
budget["per student budget"] = (schools_df["budget"])/(schools_df["size"])
#budget
#merge this df with the final df later on
merge_total_stu_budget = budget[["school_name", "per student budget"]]
merge_total_stu_budget
32/123:
# % overall passing (the percentage of students who passed math AND reading

#Filter out students who didn't pass math with a 70 or higher
students_table = school_data_complete.loc[(school_data_complete["math_score"] >= 70) &
                                          (school_data_complete["reading_score"] >= 70), :]

school_data_complete.groupby('school_name')['Student ID'].count()
32/124:
#The average score in Math for each school
mathrate = school_data_complete.groupby('school_name')['math_score'].mean()
mathrate
32/125:
#The average score in Reading for each school
readrate = school_data_complete.groupby('school_name')['reading_score'].mean()
readrate
32/126:
# % overall passing (the percentage of students who passed math AND reading

#Filter out students who didn't pass math with a 70 or higher
students_table = school_data_complete.loc[(school_data_complete["math_score"] >= 70) &
                                          (school_data_complete["reading_score"] >= 70), :]

school_data_complete.groupby('school_name')['Student ID'].count()
32/127:
# % overall passing (the percentage of students who passed math AND reading

#Filter out students who didn't pass math with a 70 or higher
students_table = school_data_complete.loc[(school_data_complete["math_score"] >= 70) &
                                          (school_data_complete["reading_score"] >= 70), :]

#school_data_complete.groupby('school_name')['Student ID'].count()
32/128:
# % overall passing (the percentage of students who passed math AND reading

#Filter out students who didn't pass math with a 70 or higher
students_table = school_data_complete.loc[(school_data_complete["math_score"] >= 70) &
                                          (school_data_complete["reading_score"] >= 70), :]

#school_data_complete.groupby('school_name')['Student ID'].count()
students_table.head()
32/129:
# % overall passing (the percentage of students who passed math AND reading

#Filter out students who didn't pass math with a 70 or higher
students_table = school_data_complete.loc[(school_data_complete["math_score"] >= 70) &
                                          (school_data_complete["reading_score"] >= 70), :]

#school_data_complete.groupby('school_name')['Student ID'].count()
students_table.tail()
32/130:
# % overall passing (the percentage of students who passed math AND reading

#Filter out students who didn't pass math with a 70 or higher
students_table = school_data_complete.loc[(school_data_complete["math_score"] >= 70) &
                                          (school_data_complete["reading_score"] >= 70), :]

students_table.groupby('school_name')['Student ID'].count()
32/131:
# % overall passing (the percentage of students who passed math AND reading

#Filter out students who didn't pass math with a 70 or higher
students_table = school_data_complete.loc[(school_data_complete["math_score"] >= 70) &
                                          (school_data_complete["reading_score"] >= 70), :]

overall_passing = students_table.groupby('school_name')['Student ID'].count()
overall_passing
32/132:
filtered_schools_df = pd.merge (filtered_schools_df, overall_passing, right_index = True,
                                left_index = True)
32/133: filtered_schools_df
32/134:
filtered_schools_df = pd.merge (filtered_schools_df, overall_passing, right_index = True,
                                left_index = True)
#reaname new column from Student ID to total overall passing 
filtered_schools_df = filtered_schools_df.rename(columns={"Student ID":"total overall passing"})
32/135:
filtered_schools_df
#student Id is total number of students who passed math AND reading
32/136:
filtered_schools_df = schools_df[["school_name", "type", "size", "budget"]]

filtered_schools_df = pd.merge(filtered_schools_df, merge_total_stu_budget, how = "left", on=["school_name", "school_name"])

filtered_schools_df = filtered_schools_df.sort_values(by = 'school_name', ascending=True)

filtered_schools_df.set_index('school_name', inplace=True)

filtered_schools_df
32/137:
filtered_schools_df = pd.merge (filtered_schools_df, mathrate, right_index = True,
                                left_index = True)
32/138:
filtered_schools_df = pd.merge (filtered_schools_df, readrate, right_index = True,
                                left_index = True)
32/139:
filtered_schools_df = pd.merge (filtered_schools_df, overall_passing, right_index = True,
                                left_index = True)
#reaname new column from Student ID to total overall passing 
filtered_schools_df = filtered_schools_df.rename(columns={"Student ID":"total overall passing"})
32/140:
filtered_schools_df
#student Id is total number of students who passed math AND reading
32/141:
filtered_schools_df = schools_df[["school_name", "type", "size", "budget"]]

filtered_schools_df = pd.merge(filtered_schools_df, merge_total_stu_budget, how = "left", on=["school_name", "school_name"])

filtered_schools_df = filtered_schools_df.sort_values(by = 'school_name', ascending=True)

filtered_schools_df.set_index('school_name', inplace=True)

filtered_schools_df
32/142:
filtered_schools_df = pd.merge (filtered_schools_df, mathrate, right_index = True,
                                left_index = True)
32/143:
filtered_schools_df = pd.merge (filtered_schools_df, readrate, right_index = True,
                                left_index = True)
32/144:
filtered_schools_df = pd.merge (filtered_schools_df, overall_passing, right_index = True,
                                left_index = True)
#reaname new column from Student ID to total overall passing 
#rename all other columns to appropiate names
filtered_schools_df = filtered_schools_df.rename(columns={"Student ID":"total overall passing",
                                                         "type":"School Type",
                                                         "size":"Total Students",
                                                          "budget":"Total School Budget",
                                                          "math_score":"Average Math Score",
                                                          "reading_score":"Average Reading Score"  
                                                         })
32/145:
filtered_schools_df
#student Id is total number of students who passed math AND reading
32/146:
# % overall passing (the percentage of students who passed math AND reading

#Filter out students who didn't pass math with a 70 or higher
math_table = school_data_complete.loc[(school_data_complete["math_score"] >= 70), :]

total_passing_m = school_data_complete.groupby('school_name')['Student ID'].count()
32/147:
# % overall passing (the percentage of students who passed math AND reading

#Filter out students who didn't pass math with a 70 or higher
math_table = school_data_complete.loc[(school_data_complete["math_score"] >= 70), :]

total_passing_m = school_data_complete.groupby('school_name')['Student ID'].count()

total_passing_m
32/148:
# % overall passing (the percentage of students who passed math AND reading

#Filter out students who didn't pass math with a 70 or higher
math_table = school_data_complete.loc[(school_data_complete["math_score"] >= 70), :]

math_table

#total_passing_m = school_data_complete.groupby('school_name')['Student ID'].count()

#total_passing_m
32/149:
# % overall passing (the percentage of students who passed math AND reading

#Filter out students who didn't pass math with a 70 or higher
math_table = school_data_complete.loc[(school_data_complete["math_score"] >= 70), :]

total_passing_m = math_table.groupby('school_name')['Student ID'].count()

total_passing_m
32/150:
#Filter out students who didn't pass reading with a 70 or higher
reading_table = school_data_complete.loc[(school_data_complete["reading_score"] >= 70), :]

total_passing_r = reading_table.groupby('school_name')['Student ID'].count()
total_passing_r
32/151:
#Filter out students who didn't pass math with a 70 or higher
math_table = school_data_complete.loc[(school_data_complete["math_score"] >= 70), :]

total_passing_m = math_table.groupby('school_name')['Student ID'].count()

total_passing_m
32/152:
#Filter out students who didn't pass reading with a 70 or higher
reading_table = school_data_complete.loc[(school_data_complete["reading_score"] >= 70), :]

total_passing_r = reading_table.groupby('school_name')['Student ID'].count()

total_passing_r
32/153:
filtered_schools_df
#student Id is total number of students who passed math AND reading
32/154:
filtered_schools_df = pd.merge (filtered_schools_df, total_passing_m, right_index = True,
                                left_index = True)

filtered_schools_df = filtered_schools_df.rename(columns={"Student ID":"total math passing"})
32/155:
filtered_schools_df = pd.merge (filtered_schools_df, total_passing_r, right_index = True,
                                left_index = True)

filtered_schools_df = filtered_schools_df.rename(columns={"Student ID":"total math passing"})
32/156:
filtered_schools_df
#student Id is total number of students who passed math AND reading
32/157:
filtered_schools_df = schools_df[["school_name", "type", "size", "budget"]]

filtered_schools_df = pd.merge(filtered_schools_df, merge_total_stu_budget, how = "left", on=["school_name", "school_name"])

filtered_schools_df = filtered_schools_df.sort_values(by = 'school_name', ascending=True)

filtered_schools_df.set_index('school_name', inplace=True)

filtered_schools_df
32/158:
filtered_schools_df = pd.merge (filtered_schools_df, mathrate, right_index = True,
                                left_index = True)
32/159:
filtered_schools_df = pd.merge (filtered_schools_df, readrate, right_index = True,
                                left_index = True)
32/160:
filtered_schools_df = pd.merge (filtered_schools_df, total_passing_m, right_index = True,
                                left_index = True)

filtered_schools_df = filtered_schools_df.rename(columns={"Student ID":"total math passing"})
32/161:
filtered_schools_df = pd.merge (filtered_schools_df, total_passing_r, right_index = True,
                                left_index = True)

filtered_schools_df = filtered_schools_df.rename(columns={"Student ID":"total math passing"})
32/162:
filtered_schools_df = pd.merge (filtered_schools_df, overall_passing, right_index = True,
                                left_index = True)
#reaname new column from Student ID to total overall passing 
#rename all other columns to appropiate names
filtered_schools_df = filtered_schools_df.rename(columns={"Student ID":"total overall passing",
                                                         "type":"School Type",
                                                         "size":"Total Students",
                                                          "budget":"Total School Budget",
                                                          "math_score":"Average Math Score",
                                                          "reading_score":"Average Reading Score"  
                                                         })
32/163:
filtered_schools_df
#student Id is total number of students who passed math AND reading
32/164:
filtered_schools_df = schools_df[["school_name", "type", "size", "budget"]]

filtered_schools_df = pd.merge(filtered_schools_df, merge_total_stu_budget, how = "left", on=["school_name", "school_name"])

filtered_schools_df = filtered_schools_df.sort_values(by = 'school_name', ascending=True)

filtered_schools_df.set_index('school_name', inplace=True)

filtered_schools_df
32/165:
filtered_schools_df = pd.merge (filtered_schools_df, mathrate, right_index = True,
                                left_index = True)
32/166:
filtered_schools_df = pd.merge (filtered_schools_df, readrate, right_index = True,
                                left_index = True)
32/167:
filtered_schools_df = pd.merge (filtered_schools_df, total_passing_m, right_index = True,
                                left_index = True)

#
#student Id is total number of students who passed math AND reading
filtered_schools_df = filtered_schools_df.rename(columns={"Student ID":"total math passing"})
32/168:
filtered_schools_df = pd.merge (filtered_schools_df, total_passing_r, right_index = True,
                                left_index = True)

filtered_schools_df = filtered_schools_df.rename(columns={"Student ID":"total reading passing"})
32/169:
filtered_schools_df = pd.merge (filtered_schools_df, overall_passing, right_index = True,
                                left_index = True)
#reaname new column from Student ID to total overall passing 
#rename all other columns to appropiate names
filtered_schools_df = filtered_schools_df.rename(columns={"Student ID":"total overall passing",
                                                         "type":"School Type",
                                                         "size":"Total Students",
                                                          "budget":"Total School Budget",
                                                          "math_score":"Average Math Score",
                                                          "reading_score":"Average Reading Score"  
                                                         })
32/170: filtered_schools_df
32/171:
#create column % Passing Math
filtered_schools_df["% Passing Math"] = ((filtered_schools_df["total math passing"]/filtered_schools_df["Total Students"])*100)
32/172: filtered_schools_df["% Passing Reading"] = ((filtered_schools_df["total reading passing"]/filtered_schools_df["Total Students"])*100)
32/173: filtered_schools_df["% Overall Passing"] = ((filtered_schools_df["total overall passing"]/filtered_schools_df["Total Students"])*100)
32/174:
#final version 
filtered_schools_df
32/175: filtered_schools_df.columns
32/176:
#Now remove the three total columns 
main_df = filtered_schools_df[['School Type', 'Total Students', 'Total School Budget',
       'per student budget', 'Average Math Score', 'Average Reading Score',
       '% Passing Math', '% Passing Reading', '% Overall Passing']]
32/177:
#final version
main_df
32/178:
#create main df by filtering 4 columns from schools_df into main df
filtered_schools_df = schools_df[["school_name", "type", "size", "budget"]]

#Sort df alphabetically by school_name
filtered_schools_df = filtered_schools_df.sort_values(by = 'school_name', ascending=True)

#set school_name as index
filtered_schools_df.set_index('school_name', inplace=True)

#check progress
filtered_schools_df
32/179: filtered_schools_df["Per Student Budget"] = (filtered_schools_df["budget"]/filtered_schools_df["size"])
32/180:
#create main df by filtering 4 columns from schools_df into main df
filtered_schools_df = schools_df[["school_name", "type", "size", "budget"]]

#Sort df alphabetically by school_name
filtered_schools_df = filtered_schools_df.sort_values(by = 'school_name', ascending=True)

#set school_name as index
filtered_schools_df.set_index('school_name', inplace=True)

#check progress
filtered_schools_df
32/181:
#Create column for per student budget
filtered_schools_df["Per Student Budget"] = (filtered_schools_df["budget"]/filtered_schools_df["size"])
32/182:
#merge into main df the column mathrate
filtered_schools_df = pd.merge (filtered_schools_df, mathrate, right_index = True,
                                left_index = True)
32/183:
##merge into main df the column readrate
filtered_schools_df = pd.merge (filtered_schools_df, readrate, right_index = True,
                                left_index = True)
32/184:
##merge into main df the column total_passing_m
filtered_schools_df = pd.merge (filtered_schools_df, total_passing_m, right_index = True,
                                left_index = True)

#student Id is total number of students who passed math AND reading
filtered_schools_df = filtered_schools_df.rename(columns={"Student ID":"total math passing"})
32/185:
#merge into main df the column total_passing_r
filtered_schools_df = pd.merge (filtered_schools_df, total_passing_r, right_index = True,
                                left_index = True)
#rename merged column from Student ID to total reading passing
filtered_schools_df = filtered_schools_df.rename(columns={"Student ID":"total reading passing"})
32/186:
#merge into main df the column overall_passing 
filtered_schools_df = pd.merge (filtered_schools_df, overall_passing, right_index = True,
                                left_index = True)
#reaname new column from Student ID to total overall passing 
#rename all other columns to appropiate names
filtered_schools_df = filtered_schools_df.rename(columns={"Student ID":"total overall passing",
                                                         "type":"School Type",
                                                         "size":"Total Students",
                                                          "budget":"Total School Budget",
                                                          "math_score":"Average Math Score",
                                                          "reading_score":"Average Reading Score"  
                                                         })
32/187:
#check progress of merging and renaming columns
filtered_schools_df
32/188:
#A column for % Passing Math
#divide total math passing by total students
filtered_schools_df["% Passing Math"] = ((filtered_schools_df["total math passing"]/filtered_schools_df["Total Students"])*100)

#A column for % Passing Reading
#divide total reading passing by total students
filtered_schools_df["% Passing Reading"] = ((filtered_schools_df["total reading passing"]/filtered_schools_df["Total Students"])*100)

#A column for % Overall Passing
#divide total overall passing by total students
filtered_schools_df["% Overall Passing"] = ((filtered_schools_df["total overall passing"]/filtered_schools_df["Total Students"])*100)
32/189:
#Now remove the three total columns 
main_df = filtered_schools_df[['School Type', 'Total Students', 'Total School Budget',
       'per student budget', 'Average Math Score', 'Average Reading Score',
       '% Passing Math', '% Passing Reading', '% Overall Passing']]
32/190:
#Now remove the three total columns 
main_df = filtered_schools_df[['School Type', 'Total Students', 'Total School Budget',
       'Per student budget', 'Average Math Score', 'Average Reading Score',
       '% Passing Math', '% Passing Reading', '% Overall Passing']]
32/191:
#Now remove the three total columns 
main_df = filtered_schools_df[['School Type', 'Total Students', 'Total School Budget',
       'Per Student Budget', 'Average Math Score', 'Average Reading Score',
       '% Passing Math', '% Passing Reading', '% Overall Passing']]
32/192:
#final version
main_df
32/193:
#import dependencies
import pandas as pd
import numpy as np
32/194:
#import csv files
csv_students = "/Users/Jerry/Documents/Homework/students_complete.csv"
csv_schools = "/Users/Jerry/Documents/Homework/schools_complete.csv"
csv_purchases = "/Users/Jerry/Documents/Homework/purchase_data.csv"

students_df = pd.read_csv(csv_students)
schools_df = pd.read_csv(csv_schools)
purchases_df = pd.read_csv(csv_purchases)

#combine the data into a singe dataset
school_data_complete = pd.merge(students_df, schools_df, how = "left", on=["school_name", "school_name"])
32/195:
#The average score in Math for each school
mathrate = school_data_complete.groupby('school_name')['math_score'].mean()
32/196:
#The average score in Reading for each school
readrate = school_data_complete.groupby('school_name')['reading_score'].mean()
32/197:
#Filter out students who didn't pass math with a 70 or higher
math_table = school_data_complete.loc[(school_data_complete["math_score"] >= 70), :]

#count the number of students left in df and group them by school_name
total_passing_m = math_table.groupby('school_name')['Student ID'].count()
32/198:
#Filter out students who didn't pass reading with a 70 or higher
reading_table = school_data_complete.loc[(school_data_complete["reading_score"] >= 70), :]

#count the number of students left in df and group them by school_name
total_passing_r = reading_table.groupby('school_name')['Student ID'].count()
32/199:
# % overall passing (the percentage of students who passed math AND reading

#Filter out students who didn't pass math with a 70 or higher
students_table = school_data_complete.loc[(school_data_complete["math_score"] >= 70) &
                                          (school_data_complete["reading_score"] >= 70), :]

#count the number of students left in df and group them by school_name
overall_passing = students_table.groupby('school_name')['Student ID'].count()
32/200:
#create main df by filtering 4 columns from schools_df into main df
filtered_schools_df = schools_df[["school_name", "type", "size", "budget"]]

#Sort df alphabetically by school_name
filtered_schools_df = filtered_schools_df.sort_values(by = 'school_name', ascending=True)

#set school_name as index
filtered_schools_df.set_index('school_name', inplace=True)

#check progress
filtered_schools_df
32/201:
#Create column for per student budget
filtered_schools_df["Per Student Budget"] = (filtered_schools_df["budget"]/filtered_schools_df["size"])
32/202:
#Create column for per student budget
filtered_schools_df["Per Student Budget"] = (filtered_schools_df["budget"]/filtered_schools_df["size"])
32/203:
#merge into main df the column mathrate
filtered_schools_df = pd.merge (filtered_schools_df, mathrate, right_index = True,
                                left_index = True)
32/204:
##merge into main df the column readrate
filtered_schools_df = pd.merge (filtered_schools_df, readrate, right_index = True,
                                left_index = True)
32/205:
##merge into main df the column total_passing_m
filtered_schools_df = pd.merge (filtered_schools_df, total_passing_m, right_index = True,
                                left_index = True)

#student Id is total number of students who passed math AND reading
filtered_schools_df = filtered_schools_df.rename(columns={"Student ID":"total math passing"})
32/206:
#merge into main df the column total_passing_r
filtered_schools_df = pd.merge (filtered_schools_df, total_passing_r, right_index = True,
                                left_index = True)
#rename merged column from Student ID to total reading passing
filtered_schools_df = filtered_schools_df.rename(columns={"Student ID":"total reading passing"})
32/207:
#merge into main df the column overall_passing 
filtered_schools_df = pd.merge (filtered_schools_df, overall_passing, right_index = True,
                                left_index = True)
#reaname new column from Student ID to total overall passing 
#rename all other columns to appropiate names
filtered_schools_df = filtered_schools_df.rename(columns={"Student ID":"total overall passing",
                                                         "type":"School Type",
                                                         "size":"Total Students",
                                                          "budget":"Total School Budget",
                                                          "math_score":"Average Math Score",
                                                          "reading_score":"Average Reading Score"  
                                                         })
32/208:
#check progress of merging and renaming columns
filtered_schools_df
32/209:
#A column for % Passing Math
#divide total math passing by total students
filtered_schools_df["% Passing Math"] = ((filtered_schools_df["total math passing"]/filtered_schools_df["Total Students"])*100)

#A column for % Passing Reading
#divide total reading passing by total students
filtered_schools_df["% Passing Reading"] = ((filtered_schools_df["total reading passing"]/filtered_schools_df["Total Students"])*100)

#A column for % Overall Passing
#divide total overall passing by total students
filtered_schools_df["% Overall Passing"] = ((filtered_schools_df["total overall passing"]/filtered_schools_df["Total Students"])*100)
32/210:
#Now remove the three total columns 
main_df = filtered_schools_df[['School Type', 'Total Students', 'Total School Budget',
       'Per Student Budget', 'Average Math Score', 'Average Reading Score',
       '% Passing Math', '% Passing Reading', '% Overall Passing']]
32/211:
#final version
main_df
32/212:
#Top Performing Schools (By % Overall Passing)
Top_schools = main_df.sort_values(by = '% Overall Passing', ascending=True)
Top_Schools
32/213:
#Top Performing Schools (By % Overall Passing)
Top_schools = main_df.sort_values(by = '% Overall Passing', ascending=True)
32/214:
#Top Performing Schools (By % Overall Passing)
top_schools = main_df.sort_values(by = '% Overall Passing', ascending=True)
32/215:
#Top Performing Schools (By % Overall Passing)
top_schools = main_df.sort_values(by = '% Overall Passing', ascending=True)
top_schools
32/216:
#Top Performing Schools (By % Overall Passing)
top_schools = main_df.sort_values(by = '% Overall Passing', ascending=False)
top_schools
32/217:
#Bottom Performing Schools (By % Overall Passing)
bottom_schools = main_df.sort_values(by = '% Overall Passing', ascending=True)
32/218:
#Top Performing Schools (By % Overall Passing)
top_schools = main_df.sort_values(by = '% Overall Passing', ascending=False)
top_schools.head()
32/219:
#Bottom Performing Schools (By % Overall Passing)
bottom_schools = main_df.sort_values(by = '% Overall Passing', ascending=True)
bottom_schools.head()
32/220:
#Top Performing Schools (By % Overall Passing)
top_schools = main_df.sort_values(by = '% Overall Passing', ascending=False)
top_schools = top_schools.head()
32/221:
#Top Performing Schools (By % Overall Passing)
top_schools = main_df.sort_values(by = '% Overall Passing', ascending=False)
top_schools = top_schools.head()
top_schools
32/222:
#Bottom Performing Schools (By % Overall Passing)
bottom_schools = main_df.sort_values(by = '% Overall Passing', ascending=True)
bottom_schools = bottom_schools.head()
32/223:
#Bottom Performing Schools (By % Overall Passing)
bottom_schools = main_df.sort_values(by = '% Overall Passing', ascending=True)
bottom_schools = bottom_schools.head()
bottom_schools
32/224: school_data_complete.head()
32/225: type(school_data_complete["grade"])
32/226:
# Math Scores by Grade
#Create a table that lists the average Reading Score for students of each grade level 
#(9th, 10th, 11th, 12th) at each school.

nineth_series = school_data_complete.loc[(school_data_complete["grade"] == "9th"), :]

nineth_math = nineth_series.groupby('school_name')[math_score].mean()

nineth_math
32/227:
# Math Scores by Grade
#Create a table that lists the average Reading Score for students of each grade level 
#(9th, 10th, 11th, 12th) at each school.

nineth_series = school_data_complete.loc[(school_data_complete["grade"] == "9th"), :]

nineth_math = nineth_series.groupby('school_name')[math_score].mean()
32/228:
# Math Scores by Grade
#Create a table that lists the average Reading Score for students of each grade level 
#(9th, 10th, 11th, 12th) at each school.

nineth_series = school_data_complete.loc[(school_data_complete["grade"] == "9th"), :]
nineth_series
#nineth_math = nineth_series.groupby('school_name')[math_score].mean()
32/229:
# Math Scores by Grade
#Create a table that lists the average Reading Score for students of each grade level 
#(9th, 10th, 11th, 12th) at each school.

nineth_series = school_data_complete.loc[(school_data_complete["grade"] == "9th"), :]

nineth_math = nineth_series.groupby('school_name')['math_score'].mean()

nineth_math
32/230:
# Math Scores by Grade
#Create a table that lists the average Reading Score for students of each grade level 
#(9th, 10th, 11th, 12th) at each school.

#9th
nineth_series = school_data_complete.loc[(school_data_complete["grade"] == "9th"), :]

nineth_math = nineth_series.groupby('school_name')['math_score'].mean()

#10th
tenth_series = school_data_complete.loc[(school_data_complete["grade"] == "10th"), :]

tenth_math = tenth_series.groupby("schools_name")["math_score"].mean()
32/231:
# Math Scores by Grade
#Create a table that lists the average Reading Score for students of each grade level 
#(9th, 10th, 11th, 12th) at each school.

#9th
nineth_series = school_data_complete.loc[(school_data_complete["grade"] == "9th"), :]

nineth_math = nineth_series.groupby('school_name')['math_score'].mean()

#10th
tenth_series = school_data_complete.loc[(school_data_complete["grade"] == "10th"), :]

tenth_math = tenth_series.groupby("school_name")["math_score"].mean()
32/232:
# Math Scores by Grade
#Create a table that lists the average Reading Score for students of each grade level 
#(9th, 10th, 11th, 12th) at each school.

#9th
nineth_series = school_data_complete.loc[(school_data_complete["grade"] == "9th"), :]

nineth_math = nineth_series.groupby('school_name')['math_score'].mean()

#10th
tenth_series = school_data_complete.loc[(school_data_complete["grade"] == "10th"), :]

tenth_math = tenth_series.groupby("school_name")["math_score"].mean()

#11th
eleventh_series = school_data_complete.loc[(school_data_complete["grade"] == "11th"), :]

eleventh_math = eleventh_series.groupby("school_name")["math_score"].mean()
32/233:
# Math Scores by Grade
#Create a table that lists the average Reading Score for students of each grade level 
#(9th, 10th, 11th, 12th) at each school.

#9th
nineth_series = school_data_complete.loc[(school_data_complete["grade"] == "9th"), :]

nineth_math = nineth_series.groupby('school_name')['math_score'].mean()

#10th
tenth_series = school_data_complete.loc[(school_data_complete["grade"] == "10th"), :]

tenth_math = tenth_series.groupby("school_name")["math_score"].mean()

#11th
eleventh_series = school_data_complete.loc[(school_data_complete["grade"] == "11th"), :]

eleventh_math = eleventh_series.groupby("school_name")["math_score"].mean()

#12th
= school_data_complete.loc[(school_data_complete["grade"] == "11th"), :]
32/234:
# Math Scores by Grade
#Create a table that lists the average Reading Score for students of each grade level 
#(9th, 10th, 11th, 12th) at each school.

#9th
nineth_series = school_data_complete.loc[(school_data_complete["grade"] == "9th"), :]

nineth_math = nineth_series.groupby('school_name')['math_score'].mean()

#10th
tenth_series = school_data_complete.loc[(school_data_complete["grade"] == "10th"), :]

tenth_math = tenth_series.groupby("school_name")["math_score"].mean()

#11th
eleventh_series = school_data_complete.loc[(school_data_complete["grade"] == "11th"), :]

eleventh_math = eleventh_series.groupby("school_name")["math_score"].mean()

#12th
twelfth_series = school_data_complete.loc[(school_data_complete["grade"] == "12th"), :]

twelfth_math = twelfth_series.groupby("school_name")["math_score"].mean()
32/235:
# Math Scores by Grade
#Create a table that lists the average Reading Score for students of each grade level 
#(9th, 10th, 11th, 12th) at each school.

#9th
nineth_series = school_data_complete.loc[(school_data_complete["grade"] == "9th"), :]

nineth_math = nineth_series.groupby('school_name')['math_score'].mean()

nineth_reading = nineth_series.groupby('school_name')['reading_score'].mean()

#10th
tenth_series = school_data_complete.loc[(school_data_complete["grade"] == "10th"), :]

tenth_math = tenth_series.groupby("school_name")["math_score"].mean()

tenth_reading = tenth_series.groupby('school_name')['reading_score'].mean()

#11th
eleventh_series = school_data_complete.loc[(school_data_complete["grade"] == "11th"), :]

eleventh_math = eleventh_series.groupby("school_name")["math_score"].mean()

eleventh_reading = eleventh_series.groupby('school_name')['reading_score'].mean()

#12th
twelfth_series = school_data_complete.loc[(school_data_complete["grade"] == "12th"), :]

twelfth_math = twelfth_series.groupby("school_name")["math_score"].mean()

twelfth_reading = twelfth_series.groupby('school_name')['reading_score'].mean()
32/236: # Math Scores by Grade DataFrame
32/237: # Reading Scores by Grade DataFrame
32/238:
# Math Scores by Grade DataFrame
#merge series into new data frame
math_df = pd.merge(nineth_math, tenth_math , how = "left", on=["school_name", "school_name"])
32/239:
# Math Scores by Grade DataFrame
#merge series into new data frame
math_df = pd.merge(nineth_math, tenth_math , how = "left", on=["school_name", "school_name"])
math_df
32/240:
# Math Scores by Grade DataFrame
#merge series into new data frame
math_df = pd.merge(nineth_math, tenth_math , how = "left", on=["school_name"])
math_df
32/241: math_df = pd.merge(math_df, eleventh_math, right_index = True, left_index = True))
32/242: math_df = pd.merge(math_df, eleventh_math, right_index = True, left_index = True)
32/243:
math_df = pd.merge(math_df, eleventh_math, right_index = True, left_index = True)
math_df
32/244:
# Math Scores by Grade DataFrame
#merge series into new data frame
math_df = pd.merge(nineth_math, tenth_math , how = "left", on=["school_name"])
32/245:
math_df = pd.merge(math_df, eleventh_math, right_index = True, left_index = True)
math_df
32/246: math_df = pd.merge(math_df, twelfth_math, right_index = True, left_index = True)
32/247: math_df
32/248:
# Math Scores by Grade DataFrame
#merge series into new data frame
math_df = pd.merge(nineth_math, tenth_math , how = "left", on=["school_name"])
math_df = math_df.rename(columns={"math_score_x":"9th",
                       "math_score_y":"10th"})
32/249: math_df = pd.merge(math_df, eleventh_math, right_index = True, left_index = True)
32/250: math_df = pd.merge(math_df, twelfth_math, right_index = True, left_index = True)
32/251: math_df
32/252:
math_df = pd.merge(math_df, twelfth_math, right_index = True, left_index = True)
math_df = math_df.rename(columns={"math_score_x":"11th",
                       "math_score_y":"12th"})
32/253: math_df
32/254:
# Math Scores by Grade DataFrame
#merge series into new data frame
math_df = pd.merge(nineth_math, tenth_math , how = "left", on=["school_name"])
math_df = math_df.rename(columns={"math_score_x":"9th",
                       "math_score_y":"10th"})
32/255: math_df = pd.merge(math_df, eleventh_math, right_index = True, left_index = True)
32/256:
math_df = pd.merge(math_df, twelfth_math, right_index = True, left_index = True)
math_df = math_df.rename(columns={"math_score_x":"11th",
                       "math_score_y":"12th"})
32/257: math_df
32/258:
# Reading Scores by Grade DataFrame
reading_df = pd.merge(nineth_reading, tenth_reading , how = "left", on=["school_name"])
reading_df = reading_df.rename(columns={"reading_score_x":"9th",
                       "reading_score_y":"10th"})
32/259: reading_df = pd.merge(reading_df, eleventh_reading, right_index = True, left_index = True)
32/260:
reading_df = pd.merge(reading_df, twelfth_reading, right_index = True, left_index = True)
reading_df = reading_df.rename(columns={"reading_score_x":"11th",
                       "reading_score_y":"12th"})
32/261: reading_df
32/262: #Scores by School Spending
32/263:
#import dependencies
import pandas as pd
import numpy as np
32/264:
#import csv files
csv_students = "/Users/Jerry/Documents/Homework/students_complete.csv"
csv_schools = "/Users/Jerry/Documents/Homework/schools_complete.csv"
csv_purchases = "/Users/Jerry/Documents/Homework/purchase_data.csv"

students_df = pd.read_csv(csv_students)
schools_df = pd.read_csv(csv_schools)
purchases_df = pd.read_csv(csv_purchases)

#combine the data into a singe dataset
school_data_complete = pd.merge(students_df, schools_df, how = "left", on=["school_name", "school_name"])
32/265:
#The average score in Math for each school
mathrate = school_data_complete.groupby('school_name')['math_score'].mean()
32/266:
#The average score in Reading for each school
readrate = school_data_complete.groupby('school_name')['reading_score'].mean()
32/267:
#Filter out students who didn't pass math with a 70 or higher
math_table = school_data_complete.loc[(school_data_complete["math_score"] >= 70), :]

#count the number of students left in df and group them by school_name
total_passing_m = math_table.groupby('school_name')['Student ID'].count()
32/268:
#Filter out students who didn't pass reading with a 70 or higher
reading_table = school_data_complete.loc[(school_data_complete["reading_score"] >= 70), :]

#count the number of students left in df and group them by school_name
total_passing_r = reading_table.groupby('school_name')['Student ID'].count()
32/269:
# % overall passing (the percentage of students who passed math AND reading

#Filter out students who didn't pass math with a 70 or higher
students_table = school_data_complete.loc[(school_data_complete["math_score"] >= 70) &
                                          (school_data_complete["reading_score"] >= 70), :]

#count the number of students left in df and group them by school_name
overall_passing = students_table.groupby('school_name')['Student ID'].count()
32/270:
#create main df by filtering 4 columns from schools_df into main df
filtered_schools_df = schools_df[["school_name", "type", "size", "budget"]]

#Sort df alphabetically by school_name
filtered_schools_df = filtered_schools_df.sort_values(by = 'school_name', ascending=True)

#set school_name as index
filtered_schools_df.set_index('school_name', inplace=True)

#check progress
#filtered_schools_df
32/271:
#Create column for per student budget
filtered_schools_df["Per Student Budget"] = (filtered_schools_df["budget"]/filtered_schools_df["size"])
32/272:
#merge into main df the column mathrate
filtered_schools_df = pd.merge (filtered_schools_df, mathrate, right_index = True,
                                left_index = True)
32/273:
##merge into main df the column readrate
filtered_schools_df = pd.merge (filtered_schools_df, readrate, right_index = True,
                                left_index = True)
32/274:
##merge into main df the column total_passing_m
filtered_schools_df = pd.merge (filtered_schools_df, total_passing_m, right_index = True,
                                left_index = True)

#student Id is total number of students who passed math AND reading
filtered_schools_df = filtered_schools_df.rename(columns={"Student ID":"total math passing"})
32/275:
#merge into main df the column total_passing_r
filtered_schools_df = pd.merge (filtered_schools_df, total_passing_r, right_index = True,
                                left_index = True)
#rename merged column from Student ID to total reading passing
filtered_schools_df = filtered_schools_df.rename(columns={"Student ID":"total reading passing"})
32/276:
#merge into main df the column overall_passing 
filtered_schools_df = pd.merge (filtered_schools_df, overall_passing, right_index = True,
                                left_index = True)
#reaname new column from Student ID to total overall passing 
#rename all other columns to appropiate names
filtered_schools_df = filtered_schools_df.rename(columns={"Student ID":"total overall passing",
                                                         "type":"School Type",
                                                         "size":"Total Students",
                                                          "budget":"Total School Budget",
                                                          "math_score":"Average Math Score",
                                                          "reading_score":"Average Reading Score"  
                                                         })
32/277:
#check progress of merging and renaming columns
filtered_schools_df
32/278:
#A column for % Passing Math
#divide total math passing by total students
filtered_schools_df["% Passing Math"] = ((filtered_schools_df["total math passing"]/filtered_schools_df["Total Students"])*100)

#A column for % Passing Reading
#divide total reading passing by total students
filtered_schools_df["% Passing Reading"] = ((filtered_schools_df["total reading passing"]/filtered_schools_df["Total Students"])*100)

#A column for % Overall Passing
#divide total overall passing by total students
filtered_schools_df["% Overall Passing"] = ((filtered_schools_df["total overall passing"]/filtered_schools_df["Total Students"])*100)
32/279:
#Now remove the three total columns 
main_df = filtered_schools_df[['School Type', 'Total Students', 'Total School Budget',
       'Per Student Budget', 'Average Math Score', 'Average Reading Score',
       '% Passing Math', '% Passing Reading', '% Overall Passing']]
32/280:
#final version
main_df
32/281: main_df
32/282: main_df.sort_values(by = "Per Student Budget", ascending = False)
32/283:
#Scores by School Spending
#Create a table that breaks down school performances based on average Spending 
#Ranges(Per Student)


#create a bin
bin = [575, 585, 630, 645, 680]

#create labels for the bin
group_labels= ("<585", "$585-630", "$630-645", "$645-680")

# Slice the data and place it into bins
pd.cut(main_df["Per Student Budget"], bins, labels = group_labels).head()
32/284:
#Scores by School Spending
#Create a table that breaks down school performances based on average Spending 
#Ranges(Per Student)


#create a bin
bins = [575, 585, 630, 645, 680]

#create labels for the bin
group_labels= ("<585", "$585-630", "$630-645", "$645-680")

# Slice the data and place it into bins
pd.cut(main_df["Per Student Budget"], bins, labels = group_labels).head()
32/285:
#Scores by School Spending
#Create a table that breaks down school performances based on average Spending 
#Ranges(Per Student)


#create a bin
bins = [575, 585, 630, 645, 680]

#create labels for the bin
group_labels= ("<585", "$585-630", "$630-645", "$645-680")

# Slice the data and place it into bins
main_df["Spending Ranges(Per Student)" = pd.cut(main_df["Per Student Budget"], bins, labels = group_labels).head()
32/286:
#Scores by School Spending
#Create a table that breaks down school performances based on average Spending 
#Ranges(Per Student)


#create a bin
bins = [575, 585, 630, 645, 680]

#create labels for the bin
group_labels= ("<585", "$585-630", "$630-645", "$645-680")

# Slice the data and place it into bins
main_df["Spending Ranges(Per Student)"] = pd.cut(main_df["Per Student Budget"], bins, labels = group_labels).head()
32/287: main_df
32/288: main_df.sort_values(by = "Per Student Budget", ascending = False)
32/289:
#final version
main_df
32/290:
#Now remove the three total columns 
main_df = filtered_schools_df[['School Type', 'Total Students', 'Total School Budget',
       'Per Student Budget', 'Average Math Score', 'Average Reading Score',
       '% Passing Math', '% Passing Reading', '% Overall Passing']]
32/291:
#final version
main_df
32/292: main_df.sort_values(by = "Per Student Budget", ascending = False)
32/293:
#Scores by School Spending
#Create a table that breaks down school performances based on average Spending 
#Ranges(Per Student)


#create a bin
bins = [575, 585, 630, 645, 680]

#create labels for the bin
group_labels= ("<585", "$585-630", "$630-645", "$645-680")

# Slice the data and place it into bins
main_df["Spending Ranges(Per Student)"] = pd.cut(main_df["Per Student Budget"], bins, labels = group_labels)
32/294: main_df
32/295:
#Scores by School Spending
#Create a table that breaks down school performances based on average Spending 
#Ranges(Per Student)


#create a bin
bins = [575, 585, 630, 645, 680]

#create labels for the bin
group_labels= ("<585", "$585-630", "$630-645", "$645-680")

# Slice the data and place it into bins
spending_df["Spending Ranges(Per Student)"] = pd.cut(main_df["Per Student Budget"], bins, labels = group_labels)
32/296:
#Scores by School Spending
#Create a table that breaks down school performances based on average Spending 
#Ranges(Per Student)


#create a bin
bins = [575, 585, 630, 645, 680]

#create labels for the bin
group_labels= ("<585", "$585-630", "$630-645", "$645-680")

spending_df = main_df
# Slice the data and place it into bins
spending_df["Spending Ranges(Per Student)"] = pd.cut(main_df["Per Student Budget"], bins, labels = group_labels)
32/297: spending_df
32/298:

#
a = spending_df.groupby('Spending Ranges(Per Student)')['Average Math Score'].mean()
#
b = spending_df.groupby('Spending Ranges(Per Student)')['Average Reading Score'].mean()
#
c = spending_df.groupby('Spending Ranges(Per Student)')['% Passing Math'].mean()
#
d = spending_df.groupby('Spending Ranges(Per Student)')['% Passing Reading'].mean()
#
e = spending_df.groupby('Spending Ranges(Per Student)')['% Passing Reading'].mean()
32/299: type(a)
32/300: scores_df = pd.concat([a, b, c, d, e], axis = 1)
32/301: scores_df
32/302:
scores_df = pd.concat([a, b, c, d, e], axis = 1)
scores_df
32/303:
#create a bin
size_bin = [0, 1000, 2000, 5000]

#create labels for the bin
size_labels = ["Small (<1000)", "Medium (1000-2000)", "Large (2000-5000)"]
32/304:
#create a bin
size_bin = [0, 1000, 2000, 5000]

#create labels for the bin
size_labels = ["Small (<1000)", "Medium (1000-2000)", "Large (2000-5000)"]

#
size_df = main_df

# Slice the data and place it into bins
size_df["School Size"] = pd.cut(main_df["Total Students"], size_bin, labels = size_labels)
32/305:
#
f = spending_df.groupby('Total Students')['Average Math Score'].mean()
#
g = spending_df.groupby('Total Students')['Average Reading Score'].mean()
#
h = spending_df.groupby('Total Students')['% Passing Math'].mean()
#
i = spending_df.groupby('Total Students')['% Passing Reading'].mean()
#
j = spending_df.groupby('Total Students')['% Passing Reading'].mean()
32/306:
by_size_df = pd.concat([f, g, h, i, j], axis = 1)
by_size_df
32/307:
#
f = spending_df.groupby('School Size')['Average Math Score'].mean()
#
g = spending_df.groupby('School Size')['Average Reading Score'].mean()
#
h = spending_df.groupby('School Size')['% Passing Math'].mean()
#
i = spending_df.groupby('School Size')['% Passing Reading'].mean()
#
j = spending_df.groupby('School Size')['% Passing Reading'].mean()
32/308:
by_size_df = pd.concat([f, g, h, i, j], axis = 1)
by_size_df
32/309:
#
k = spending_df.groupby('School Type')['Average Math Score'].mean()
#
l = spending_df.groupby('School Type')['Average Reading Score'].mean()
#
m = spending_df.groupby('School Type')['% Passing Math'].mean()
#
n = spending_df.groupby('School Type')['% Passing Reading'].mean()
#
o = spending_df.groupby('School Type')['% Passing Reading'].mean()
32/310:
by_school_type = pd.concat([k, l, m, n, o], axis = 1)
by_school_type
32/311: reading_df
39/1: #import dependencies
39/2:
#import dependencies
import pandas as pd
import numpy as np
39/3:
#import dependencies
import pandas as pd
import numpy as np

#import csv file path
csv_path = "/Users/Jerry/Downloads/California_Housing.csv"

housing_df = pd.csv_read(csv_path)
39/4:
#import dependencies
import pandas as pd
import numpy as np

#import csv file path
csv_path = "/Users/Jerry/Downloads/California_Housing.csv"

housing_df = pd.read_csv(csv_path)
39/5: housing_df.head()
39/6: housing_df.tail()
39/7: housing_df.head()
39/8:
#import dependencies
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import scipy.stats as st

#import csv file path
csv_path = "/Users/Jerry/Downloads/California_Housing.csv"

housing_df = pd.read_csv(csv_path)
39/9: housing_df.tail()
39/10: housing_df.describe()
39/11: housing_df.head()
39/12:
#Determine the most appropriate measure of central tendency to describe the population, 
#and then calculate this value
np.mean(Population)
39/13:
#Determine the most appropriate measure of central tendency to describe the population, 
#and then calculate this value
population = housing_df["Population"]
np.mean(Population)
39/14:
#Determine the most appropriate measure of central tendency to describe the population, 
#and then calculate this value
population = housing_df["Population"]
np.mean(population)
39/15: np.median(population)
39/16: st.mode(population)
39/17: housing_df.tail()
39/18: housing_df.max()
39/19: housing_df.min()
39/20: housing_df.head()
39/21:
# Determine if the house age in California is considered normally distributed
age = housing_df["HouseAge"]
39/22:
# Determine if the house age in California is considered normally distributed
age = housing_df["HouseAge"]
plt.hist(age)
39/23:
# Determine if the house age in California is considered normally distributed
age = housing_df["HouseAge"]
plt.hist(age)
plt.xlabel("Age")
plt.ylabel("Count")
39/24:
# Determine if the house age in California is considered normally distributed
age = housing_df["HouseAge"]
plt.hist(age)
plt.xlabel("Age")
plt.ylabel("Count")
print(st.normaltest(age.samples(50)))
39/25:
# Determine if the house age in California is considered normally distributed
age = housing_df["HouseAge"]
plt.hist(age)
plt.xlabel("Age")
plt.ylabel("Count")
39/26: var_numpy = np.var(age, ddof = 0)
39/27:
var_numpy = np.var(age, ddof = 0)
var_numpy
39/28: sd_numpy = np.std(temperatures, ddof = 0)
39/29: sd_numpy = np.std(age, ddof = 0)
39/30:
sd_numpy = np.std(age, ddof = 0)
sd_numpy
39/31:
avg_occ = housing_df["AveOccup"]
avg_occ
39/32:
avg_occ = housing_df["AveOccup"]
np.mean(avg_occ)
39/33: plt.hist(avg_occ)
39/34: housing_df["AveOccup"].max()
39/35: housing_df["AveOccup"].min()
40/1: %matplotlib notebook
40/2:
# Import dependencies
from matplotlib import pyplot as plt
import numpy as np
import pandas as pd
from sklearn.datasets import fetch_california_housing
from scipy.stats import sem
40/3:
 # Import the California housing data set and get description
california_dataset = fetch_california_housing()

print(california_dataset.DESCR)
40/4:
 # Read California housing data into a Pandas dataframe
housing_data = pd.DataFrame(data=california_dataset.data,columns=california_dataset.feature_names)
housing_data['MEDV'] = california_dataset.target
40/5:
# Create a bunch of samples, each with sample size of 20
random.seed(20)
40/6:
# Import dependencies
from matplotlib import pyplot as plt
import numpy as np
import pandas as pd
from sklearn.datasets import fetch_california_housing
from scipy.stats import sem
import random
40/7:
 # Read California housing data into a Pandas dataframe
housing_data = pd.DataFrame(data=california_dataset.data,columns=california_dataset.feature_names)
housing_data['MEDV'] = california_dataset.target
housing_data.head()
40/8:
# Create a bunch of samples, each with sample size of 20
subset = housing_data.sample(20)
print(f"Mean: {round(subset['MedInc'].mean(), 2)}")
40/9: print(f"The SEM value for the sample fuel economy data is {sem(subset['MedInc'])}")
40/10:
#Create a sample set of median housing prices using Pandas. Set the sample size to 20.
housing_sample_set = [housing_data.sample(20) for x in range(0,10)]
40/11: housing_sample_set
40/12:
#Calculate the means and standard errors for each sample.

mean = [subset["MedInc"].mean() for sample in housing_sample_set]
standard_erros = [sem(subset["MedInc"]) for sample in housing_sample_set]
x_acis = np.arange(0, len(housing_sample_set), 1) +1
40/13:
#Calculate the means and standard errors for each sample.

mean = [subset["MedInc"].mean() for sample in housing_sample_set]
standard_erros = [sem(subset["MedInc"]) for sample in housing_sample_set]
x_axis = np.arange(0, len(housing_sample_set), 1) +1
41/1:
 # Dependencies
import pandas as pd
import sklearn.datasets as dta
import scipy.stats as st
import matplotlib.pyplot as plt
41/2:
# Read in the wine recognition data set from sklearn and load into Pandas
data = dta.load_wine()
wine_data = pd.DataFrame(data.data,columns=data.feature_names)
41/3: wine_data.head()
41/4: # Plot flavanoids versus malic_acid on a scatterplot
41/5:
# Plot flavanoids versus malic_acid on a scatterplot
plt.scatter(wine_data.iloc[:,1], wine_data.iloc[:, 8])
41/6: wine_data.iloc[:,1]
41/7:
# Plot flavanoids versus malic_acid on a scatterplot
plt.scatter(wine_data.iloc[:,1], wine_data.iloc[:, 6])
41/8:
# Calculate the correlation coefficient between malic_acid and flavanoids

malic_acid = wine_data.iloc[:,1]

flavanoids = wine_data.iloc[:, 6]

correlation = st.pearsonr(malic_acid, flavanoids)
41/9:
# Calculate the correlation coefficient between malic_acid and flavanoids

malic_acid = wine_data.iloc[:,1]

flavanoids = wine_data.iloc[:, 6]

correlation = st.pearsonr(malic_acid, flavanoids)

correlation
41/10:
# Calculate the correlation coefficient between malic_acid and flavanoids

malic_acid = wine_data.iloc[:,1]

flavanoids = wine_data.iloc[:, 6]

correlation = st.pearsonr(malic_acid, flavanoids)

round(correlation[0],2)
41/11:
# Calculate the correlation coefficient between malic_acid and flavanoids

malic_acid = wine_data.iloc[:,1]

flavanoids = wine_data.iloc[:, 6]

correlation = st.pearsonr(malic_acid, flavanoids)

round(correlation[0],2)

correlation
41/12:
# Calculate the correlation coefficient between alcohol and color_intensity

alcohol = wine_data.iloc[:, 0]

color_intensity = wine_data.iloc[:, 9]

correlation2 = st.pearsonr(alcohol, color_intensity)
41/13:
# Calculate the correlation coefficient between alcohol and color_intensity

alcohol = wine_data.iloc[:, 0]

color_intensity = wine_data.iloc[:, 9]

correlation2 = st.pearsonr(alcohol, color_intensity)

round(correlation2[0],2)
41/14:
# Calculate the correlation coefficient between malic_acid and flavanoids

malic_acid = wine_data.iloc[:,1]

flavanoids = wine_data.iloc[:, 6]

correlation = st.pearsonr(malic_acid, flavanoids)

round(correlation[0],2)
41/15:
# Plot colour_intensity versus alcohol on a scatterplot

plt.scatter(wine_data.iloc[:,0], wine_data.iloc[:, 9])
41/16:
# BONUS: Generate the correlation matrix and find the strongest positive and negative correlations
wine_data.correlation()
41/17:
# BONUS: Generate the correlation matrix and find the strongest positive and negative correlations
wine_data.corr()
41/18:
# BONUS: Generate the correlation matrix and find the strongest positive and negative correlations
wine = wine_data.corr()
41/19: wine.max()
41/20:
# BONUS: Generate the correlation matrix and find the strongest positive and negative correlations
wine = wine_data.corr()
wine
41/21:
alc_less1 = wine.loc[(wine["alcohol"] < 1), :]
alc_less1["alcohol"].max()
37/1:
#final data frame for the district 
district_summary_df
37/2:
#Create a dataframe to hold the above results
#check data type of total_students
##type(total_schools)

d = {'Total Schools':[total_schools], 'Total Students':[total_students], 
     'Total Budget':[total_budget], 'Average Math Score':[avg_math_score], 
     'Average Reading Score':[avg_reading_score], '% Passing Math':[percent_passing_math], 
     '% Passing Reading':[percent_passing_reading], '% Overall Passing':[percentage_passing_mr]}
district_summary_df = pd.DataFrame(data = d)
37/3:
#import dependencies
import pandas as pd
import numpy as np
37/4:
#import csv files
csv_students = "/Users/Jerry/Documents/Homework/students_complete.csv"
csv_schools = "/Users/Jerry/Documents/Homework/schools_complete.csv"
csv_purchases = "/Users/Jerry/Documents/Homework/purchase_data.csv"

students_df = pd.read_csv(csv_students)
schools_df = pd.read_csv(csv_schools)
purchases_df = pd.read_csv(csv_purchases)

#combine the data into a singe dataset
school_data_complete = pd.merge(students_df, schools_df, how = "left", on=["school_name", "school_name"])
37/5:
#Total schools
total_schools = schools_df["school_name"].count()
37/6:
#Total students
total_students = students_df["Student ID"].count()
37/7:
#Total budget
total_budget = schools_df["budget"].sum()
37/8:
#Average math score
#round to the hundrednth decimal place
avg_math_score = round((students_df["math_score"].mean()), 2)
37/9:
#Average reading score
avg_reading_score = round((students_df["reading_score"].mean()), 2)
37/10:
# % passing math (the percentage of students who passed math)

#create a for loop to count the students who have a passing math score
math_passing = 0

for scores in students_df["math_score"]:
    if scores >= 70:
        math_passing = math_passing + 1
        
#now compare math_passing to total students 
percent_passing_math = round((math_passing / total_students), 4)
37/11:
#% passing reading (the percentage of students who passed reading)

#create a variable to hold the number of students passing reading
reading_passing = 0

#create a for loop to count the number of students who passed reading 
for scores in students_df["reading_score"]:
    if scores >= 70:
        reading_passing = reading_passing + 1
        
# check if reading_passing populates correctly
#reading_passing

#The percent of student who passed reading district wide
percent_passing_reading = round((reading_passing / total_students), 2)

#check if percent_passing_reading populates correctly
#percent_passing_reading
37/12:
# % overall passing (the percentage of students who passed math AND reading

#Filter main df "students_df" to essential columns
filtered_students_df = students_df[["Student ID", "reading_score", "math_score"]]

#Filter out students who didn't pass math with a 70 or higher
students_table = filtered_students_df.loc[filtered_students_df["math_score"] >= 70, :]

#filter out students who didn't pass reading either with a 70 or higher

students_table = students_table.loc[students_table["reading_score"] >= 70, :]

#run a check to see the number of students who passed math AND reading
#create a variable for this number
passing_mr = students_table["Student ID"].count()

#compare this number with total number of students. 
#note m = math and r = reading
percentage_passing_mr = round((passing_mr / total_students), 2)
37/13:
#Create a dataframe to hold the above results
#check data type of total_students
##type(total_schools)

d = {'Total Schools':[total_schools], 'Total Students':[total_students], 
     'Total Budget':[total_budget], 'Average Math Score':[avg_math_score], 
     'Average Reading Score':[avg_reading_score], '% Passing Math':[percent_passing_math], 
     '% Passing Reading':[percent_passing_reading], '% Overall Passing':[percentage_passing_mr]}
district_summary_df = pd.DataFrame(data = d)
37/14:
#final data frame for the district 
district_summary_df
42/1: New Jersey Weather
42/2: #New Jersey Weather
42/3:
#New Jersey Weather
#import dependencies
import numpy as np
import matplotlib.pyplot as plt
42/4:
#set x axis to numerical value for month
x_axis_data = np.arange(1,13,1)
x_axis_data
42/5:
#set x axis to numerical value for month
x_axis_data = np.arange(1,13,2)
x_axis_data
42/6:
#set x axis to numerical value for month
x_axis_data = np.arange(1,20,1)
x_axis_data
42/7:
#set x axis to numerical value for month
x_axis_data = np.arange(5,20,1)
x_axis_data
42/8:
#set x axis to numerical value for month
x_axis_data = np.arange(1,13,1)
x_axis_data
42/9:
#Average weather temp
points = [39, 42, 51, 62, 72, 82, 86, 84, 77, 65, 55, 44]

#create a lis comprehension to convert the temp from f to c and plot that line
42/10:
#Average weather temp
points = [39, 42, 51, 62, 72, 82, 86, 84, 77, 65, 55, 44]

#plot these two variables
plt.plot(x_axis_data, points)
plt.show()
42/11:
#Average weather temp
points = [39, 42, 51, 62, 72, 82, 86, 84, 77, 65, 55, 44]

#plot these two variables
plt.plot(points, x_axis_data)
plt.show()
42/12:
#Average weather temp
points = [39, 42, 51, 62, 72, 82, 86, 84, 77, 65, 55, 44]

#plot these two variables
plt.plot(x_axis_data, points)
plt.show()
42/13:
#Use a list comprehension to convert the temperature to degrees Celsius.

points_c = [(x - 32)* .56 for x in points] 
points_c
42/14: plt.plot(x_axis, points_C)
42/15: plt.plot(x_axis_data, points_C)
42/16: plt.plot(x_axis_data, points_c)
42/17:
plt.plot(x_axis_data, points_c)
plt.plot(x_axis_data, points)
42/18: plt.title("Two graphs")
42/19:
plt.plot(x_axis_data, points_c)
plt.plot(x_axis_data, points)
plt.title("Two graphs")
42/20:
plt.plot(x_axis_data, points_c)
plt.plot(x_axis_data, points)
plt.title("Two graphs")
plt.hlines(0,0,10, alpha =.25
42/21:
plt.plot(x_axis_data, points_c)
plt.plot(x_axis_data, points)
plt.title("Two graphs")
plt.hlines(0,0,10, alpha =.25)
42/22:
plt.plot(x_axis_data, points_c)
plt.plot(x_axis_data, points)
plt.title("Two graphs")
plt.hlines(0,0,35, alpha =.25)
42/23:
plt.plot(x_axis_data, points_c)
plt.plot(x_axis_data, points)
plt.title("Two graphs")
plt.hlines(0,0,15, alpha =.25)
42/24:
plt.plot(x_axis_data, points_c)
plt.plot(x_axis_data, points)
plt.title("Two graphs")
plt.hlines(0,0,13, alpha =.25)
42/25:
plt.plot(x_axis_data, points_c)
plt.plot(x_axis_data, points)
plt.title("Two graphs")
plt.hlines(0,35,13, alpha =.25)
42/26:
plt.plot(x_axis_data, points_c)
plt.plot(x_axis_data, points)
plt.title("Two graphs")
plt.hlines(35,0,13, alpha =.25)
42/27:
plt.plot(x_axis_data, points_c)
plt.plot(x_axis_data, points)
plt.title("Two graphs")
plt.hlines(35,0,13, alpha =.25, marker = 'o')
42/28:
plt.plot(x_axis_data, points_c)
plt.plot(x_axis_data, points)
plt.title("Two graphs")
plt.hlines(35,0,13, alpha =.25, color = 'blue')
42/29:
plt.plot(x_axis_data, points_c)
plt.plot(x_axis_data, points)
plt.title("Two graphs")
plt.hlines(35,0,13, alpha =.25, color = 'red')
42/30:
plt.plot(x_axis_data, points_c)
plt.plot(x_axis_data, points)
plt.title("Two graphs")
plt.hlines(35,0,13, alpha =.25, color = 'blue', label = 'blue label')
42/31:
#plt.plot(x_axis_data, points_c)
plt.plot(x_axis_data, points)
plt.title("Two graphs")
plt.hlines(35,0,13, alpha =.25, color = 'blue', label = 'blue label')
42/32:
#plt.plot(x_axis_data, points_c)
plt.plot(x_axis_data, points)
plt.title("Two graphs")
plt.hlines(35,0,13, alpha =.25, color = 'blue', label = 'blue label')
plt.legend(loc='lower right')
42/33:
#plt.plot(x_axis_data, points_c)
plt.plot(x_axis_data, points)
plt.title("Two graphs")
plt.hlines(35,0,13, alpha =.25, color = 'blue', label = 'blue label')
plt.legend(loc='top right')
42/34:
#plt.plot(x_axis_data, points_c)
plt.plot(x_axis_data, points)
plt.title("Two graphs")
plt.hlines(35,0,13, alpha =.25, color = 'blue', label = 'blue label')
plt.legend(loc='upper right')
43/1:
celcius = plt.plot(x_axis_data, points_c, marker = '+', color = 'blue', label = "Fahrenheit", linewidth = 1)
plt.plot(x_axis_data, points)
43/2:
#New Jersey Weather
#import dependencies
import numpy as np
import matplotlib.pyplot as plt
43/3:
#set x axis to numerical value for month
x_axis_data = np.arange(1,13,1)
x_axis_data
43/4:
#Average weather temp
points = [39, 42, 51, 62, 72, 82, 86, 84, 77, 65, 55, 44]

#plot these two variables
plt.plot(x_axis_data, points)
plt.show()
43/5:
#Use a list comprehension to convert the temperature to degrees Celsius.

points_c = [(x - 32)* .56 for x in points] 
points_c
43/6:
celcius = plt.plot(x_axis_data, points_c, marker = '+', color = 'blue', label = "Fahrenheit", linewidth = 1)
plt.plot(x_axis_data, points)
43/7:
celcius = plt.plot(x_axis_data, points_c, marker = '+', color = 'blue', label = "Celceius", linewidth = 1)
plt.plot(x_axis_data, points, marker ='^', color = 'red', label = "Celceius", linewidth = 2)
43/8:
celcius = plt.plot(x_axis_data, points_c, marker = '+', color = 'blue', label = "Celceius", linewidth = 1)
plt.plot(x_axis_data, points, marker ='^', color = 'red', label = "Celceius", linewidth = 3)
43/9:
celcius = plt.plot(x_axis_data, points_c, marker = '+', color = 'blue', label = "Celceius", linewidth = 1)
plt.plot(x_axis_data, points, marker ='^', color = 'red', label = "Celceius", linewidth = 2)
43/10:
celcius = plt.plot(x_axis_data, points_c, marker = '+', color = 'blue', label = "Celceius", linewidth = 2)
plt.plot(x_axis_data, points, marker ='^', color = 'red', label = "Celceius", linewidth = 2)
43/11:
celcius = plt.plot(x_axis_data, points_c, marker = '+', color = 'blue', label = "Celceius", linewidth = 2)
fahrenheit = plt.plot(x_axis_data, points, marker ='^', color = 'red', label = "Celceius", linewidth = 2)
43/12:
celcius = plt.plot(x_axis_data, points_c, marker = '+', color = 'blue', label = "Celceius", linewidth = 2)
farhenheit = plt.plot(x_axis_data, points, marker ='^', color = 'red', label = "Celceius", linewidth = 2)
43/13:
celcius = plt.plot(x_axis_data, points_c, marker = '+', color = 'blue', label = "Celceius", linewidth = 2)
farhenheit = plt.plot(x_axis_data, points, marker ='^', color = 'red', label = "Celceius", linewidth = 2)
plt.legend(handles = [farhenheit, celcius], loc = "best")
43/14:
celcius = plt.plot(x_axis_data, points_c, marker = '+', color = 'blue', label = "Celceius", linewidth = 2)
farhenheit = plt.plot(x_axis_data, points, marker ='^', color = 'red', label = "Celceius", linewidth = 2)
43/15: plt.legend(handles = [farhenheit, celcius], loc = "best")
43/16:
#New Jersey Weather
#import dependencies
import numpy as np
import matplotlib.pyplot as plt
43/17:
#set x axis to numerical value for month
x_axis_data = np.arange(1,13,1)
x_axis_data
43/18:
#Average weather temp
points = [39, 42, 51, 62, 72, 82, 86, 84, 77, 65, 55, 44]

#plot these two variables
plt.plot(x_axis_data, points)
plt.show()
43/19:
#Use a list comprehension to convert the temperature to degrees Celsius.

points_c = [(x - 32)* .56 for x in points] 
points_c
43/20: plt.legend(handles = [farhenheit, celcius], loc="best")
44/1:
#import dependencies
import requests
import json
44/2:
# URL for get requests to retrieve vehicle data
url = 'https://api.spacexdata.com/v3/dragons/dragon1'
44/3: print(requests.get(url))
44/4:
#pretty print the output of the JSON
response = requests.get(url).json()
print(json.dumps(response, indent = 4, sort_keys=True))
44/5:
#pretty print the output of the JSON
response = requests.get(url).json()
print(json.dumps(response, indent = 3, sort_keys=True))
44/6:
#pretty print the output of the JSON
response = requests.get(url).json()
print(json.dumps(response, indent = 4, sort_keys=True))
45/1:
import requests
import json
45/2:
#create a url with a specific character id 
character_id = '4'
url = base_url + character_id
print(url)
45/3:
import requests
import json
45/4:
#URL for GET requests to retrieve star wars character data
base_url = "https://swapi.dev/api/people/"
45/5:
#create a url with a specific character id 
character_id = '4'
url = base_url + character_id
print(url)
45/6:
response = requests.get(url)
print(response.url)
45/7:
 # Storing the JSON response within a variable
data = response.json()
# Use json.dumps to print the json stored in variable
# YOUR CODE HERE
45/8: data
45/9: data[0]
45/10:
 # Storing the JSON response within a variable
data = response.json()
# Use json.dumps to print the json stored in variable
print(json.dumps(data, indent = 4, sort_keys=True))
45/11: data
45/12:
 # Storing the JSON response within a variable
data = response.json()
# Use json.dumps to print the json stored in variable
print(json.dumps(data, indent = 4, sort_keys=False))
45/13:
# Print the name of the character retrieved
data("name")
45/14:
# Print the name of the character retrieved
data["name"]
45/15:
# Print the name of the character retrieved
type(data["name"])
45/16:
# Print the name of the character retrieved
data["name"]
45/17:
# Print the number of films that they were in (hint: use len())
data[0]
45/18:
# Print the number of films that they were in (hint: use len())
data(0)
45/19:
# Print the number of films that they were in (hint: use len())
data["films"]
45/20:
# Print the number of films that they were in (hint: use len())
len(data["films"])
45/21:
# Print the number of films that they were in (hint: use len())
Number_of_flims = len(data["films"])
45/22:
# Print the number of films that they were in (hint: use len())
Number_of_flims = len(data["films"])
45/23:
# Print the name of the character retrieved
character_name = data["name"]
45/24:
 # Request the starships URI found in the starships property of the
# previously retreived json, then use the response to figure out what this 
# character's first starship was


type(data)
45/25:
 # Request the starships URI found in the starships property of the
# previously retreived json, then use the response to figure out what this 
# character's first starship was

type(clean)
45/26:
 # Storing the JSON response within a variable
data = response.json()
# Use json.dumps to print the json stored in variable
clean = print(json.dumps(data, indent = 4, sort_keys=False))
45/27:
 # Request the starships URI found in the starships property of the
# previously retreived json, then use the response to figure out what this 
# character's first starship was

type(clean)
45/28:
 # Storing the JSON response within a variable
data = response.json()
# Use json.dumps to print the json stored in variable
print(json.dumps(data, indent = 4, sort_keys=False))
45/29:
# Print the number of films that they were in (hint: use len())
number_of_flims = len(data["films"])
print(number_of_flims)
45/30:
 # Request the starships URI found in the starships property of the
# previously retreived json, then use the response to figure out what this 
# character's first starship was

url2 = "https://swapi.dev/api/starships/13/"
#or
#ship_url = data['Starships'][0]
new_response = requests.get(url2).json()
(new_response)
45/31:
 # Print the name of the character's first starship
# YOUR CODE HERE
new_response["name"]
46/1:
#import dependencies
import json
import requests
46/2:
# Base URL for GET requests to retrieve number/date facts
base_url = "http://numbersapi.com/#5/math"
46/3: print(requests.get(base_url))
46/4: response = requests.get(base_url).json()
46/5: response = requests.get(base_url).json()
44/7:
#pretty print the output of the JSON
response = requests.get(url).json()
#print(json.dumps(response, indent = 4, sort_keys=True))
46/6: response = requests.get(base_url).json()
46/7:
#import dependencies
import json
import requests
46/8:
# Base URL for GET requests to retrieve number/date facts
base_url = "http://numbersapi.com/#5/math"
46/9: print(requests.get(base_url))
46/10: response = requests.get(base_url).json()
46/11: response = requests.get(base_url).json()
46/12: response = requests.get(base_url).json()
46/13:
# Base URL for GET requests to retrieve number/date facts
base_url = "http://numbersapi.com/#"

x = input("What number do you want to look up?")
46/14: url = base_url + x/math
46/15: url = base_url + x + "/math"
46/16:
url = base_url + x + "/math"
print(url)
46/17: print(requests.get(url))
46/18: response = requests.get(base_url).json()
46/19:
#import dependencies
import json
import requests
46/20: response = requests.get(url).json()
46/21:
response = requests.get(url).json()
print(json.dumps(response, indent = 4, sort_keys=True))
46/22:

print(json.dumps(url, indent = 4, sort_keys=True))
46/23: response = requests.get(url).json()
46/24: response = requests.get(url).?json()
46/25: response = requests.get(url).?json
46/26: url = base_url + x + "/math/?json"
46/27: print(requests.get(url))
46/28: response = requests.get(url).
46/29: response = requests.get(url).json()
46/30: response = requests.get(base_url).json()
46/31:
# Base URL for GET requests to retrieve number/date facts
base_url = "http://numbersapi.com/#5/math"
response = requests.get(base_url).json()
#x = input("What number do you want to look up?")
46/32:
# Base URL for GET requests to retrieve number/date facts
base_url = "http://numbersapi.com/#42"
response = requests.get(base_url).json()
#x = input("What number do you want to look up?")
46/33:
# Base URL for GET requests to retrieve number/date facts
base_url = "http://numbersapi.com/#42/?json"
response = requests.get(base_url).json()
#x = input("What number do you want to look up?")
46/34:
# Base URL for GET requests to retrieve number/date facts
url = "http://numbersapi.com/#42/?json"
response = requests.get(url)
46/35:
# Base URL for GET requests to retrieve number/date facts
url = "http://numbersapi.com/#42/?json"
response = requests.get(url)
print(response)
46/36: data = response.json()
47/1:
import requests
import json

# Note that the ?t= is a query param for the t-itle of the
# movie we want to search for.
url = "http://www.omdbapi.com/?t=avengers&apikey=trilogy"

# Performing a GET request similar to the one we executed
# earlier
response = requests.get(url)

# Converting the response to JSON, and printing the result.
data = response.json()
pprint(data)
47/2:
import requests
import json
import ppprint

# Note that the ?t= is a query param for the t-itle of the
# movie we want to search for.
url = "http://www.omdbapi.com/?t=avengers&apikey=trilogy"

# Performing a GET request similar to the one we executed
# earlier
response = requests.get(url)

# Converting the response to JSON, and printing the result.
data = response.json()
pprint(data)
47/3:
import requests
import json
import pprint

# Note that the ?t= is a query param for the t-itle of the
# movie we want to search for.
url = "http://www.omdbapi.com/?t=avengers&apikey=trilogy"

# Performing a GET request similar to the one we executed
# earlier
response = requests.get(url)

# Converting the response to JSON, and printing the result.
data = response.json()
pprint(data)
47/4:
import requests
import json

# Note that the ?t= is a query param for the t-itle of the
# movie we want to search for.
url = "http://www.omdbapi.com/?t=avengers&apikey=trilogy"

# Performing a GET request similar to the one we executed
# earlier
response = requests.get(url)

# Converting the response to JSON, and printing the result.
data = response.json()
print(data)
47/5:
import requests
import json
import pprint

# Note that the ?t= is a query param for the t-itle of the
# movie we want to search for.
url = "http://www.omdbapi.com/?t=avengers&apikey=trilogy"

# Performing a GET request similar to the one we executed
# earlier
response = requests.get(url)

# Converting the response to JSON, and printing the result.
data = response.json()
pprint(data)
47/6:
import requests
import json
import pprint from lib

# Note that the ?t= is a query param for the t-itle of the
# movie we want to search for.
url = "http://www.omdbapi.com/?t=avengers&apikey=trilogy"

# Performing a GET request similar to the one we executed
# earlier
response = requests.get(url)

# Converting the response to JSON, and printing the result.
data = response.json()
pprint(data)
47/7:
import requests
import json
import pprint 

# Note that the ?t= is a query param for the t-itle of the
# movie we want to search for.
url = "http://www.omdbapi.com/?t=avengers&apikey=trilogy"

# Performing a GET request similar to the one we executed
# earlier
response = requests.get(url)

# Converting the response to JSON, and printing the result.
data = response.json()
pprint(data)
47/8:
import requests
import json
import pprint 

# Note that the ?t= is a query param for the t-itle of the
# movie we want to search for.
url = "http://www.omdbapi.com/?t=avengers&apikey=trilogy"

# Performing a GET request similar to the one we executed
# earlier
response = requests.get(url)

# Converting the response to JSON, and printing the result.
data = response.json()
print(data)
47/9:
import requests
import json
import pprintpp

# Note that the ?t= is a query param for the t-itle of the
# movie we want to search for.
url = "http://www.omdbapi.com/?t=avengers&apikey=trilogy"

# Performing a GET request similar to the one we executed
# earlier
response = requests.get(url)

# Converting the response to JSON, and printing the result.
data = response.json()
print(data)
47/10:
import requests
import json
import pprint

# Note that the ?t= is a query param for the t-itle of the
# movie we want to search for.
url = "http://www.omdbapi.com/?t=avengers&apikey=trilogy"

# Performing a GET request similar to the one we executed
# earlier
response = requests.get(url)

# Converting the response to JSON, and printing the result.
data = response.json()
print(data)
47/11:
import requests
import json
import pprint

# Note that the ?t= is a query param for the t-itle of the
# movie we want to search for.
url = "http://www.omdbapi.com/?t=avengers&apikey=trilogy"

# Performing a GET request similar to the one we executed
# earlier
response = requests.get(url)

# Converting the response to JSON, and printing the result.
data = response.json()
print(data["Title"])
47/12:
import requests
import json
import pprint

# Note that the ?t= is a query param for the t-itle of the
# movie we want to search for.
url = "http://www.omdbapi.com/?t=avengers&apikey=trilogy"

# Performing a GET request similar to the one we executed
# earlier
response = requests.get(url)

# Converting the response to JSON, and printing the result.
data = response.json()
print(data)
47/13:
import requests
import json
import pprint

# Note that the ?t= is a query param for the t-itle of the
# movie we want to search for.
url = "http://www.omdbapi.com/?t=avengers&apikey=trilogy"

# Performing a GET request similar to the one we executed
# earlier
response = requests.get(url)

# Converting the response to JSON, and printing the result.
data = response.json()
pprint(data)
47/14:
import requests
import json
#import pprint

# Note that the ?t= is a query param for the t-itle of the
# movie we want to search for.
#url = "http://www.omdbapi.com/?t=avengers&apikey=trilogy"
url = "http://www.omdbapi.com/?t=avengers&apikey=trilogy"

movie = "?t=" + input("What movie do you want to search?")
# Performing a GET request similar to the one we executed
# earlier
response = requests.get(url)

# Converting the response to JSON, and printing the result.
data = response.json()
print(data)
47/15: movie = "?t=" + input("What movie do you want to search?")
47/16: movie = "?t=" + input("What movie do you want to search?")
47/17: print(movie)
47/18:
movie = "?t=" + input("What movie do you want to search?")
api_key = "&apikey=trilogy"
47/19: print(api_key)
47/20:
movie = "?t=" + input("What movie do you want to search?")
api_key = "&apikey=trilogy"
full_url = (f"{url} + {movie} + {api_key})
47/21:
movie = "?t=" + input("What movie do you want to search?")
api_key = "&apikey=trilogy"
full_url = (f"{url} + {movie} + {api_key}")
47/22: print(movie)
47/23: print(api_key)
47/24: print(full_url)
47/25:
movie = "?t=" + input("What movie do you want to search?")
api_key = "&apikey=trilogy"
full_url = (f"{url}{movie}{api_key}")
47/26: print(movie)
47/27: print(api_key)
47/28: print(full_url)
47/29:
import requests
import json
#import pprint

# Note that the ?t= is a query param for the t-itle of the
# movie we want to search for.
#url = "http://www.omdbapi.com/?t=avengers&apikey=trilogy"
url = "http://www.omdbapi.com/"

movie = "?t=" + input("What movie do you want to search?")
# Performing a GET request similar to the one we executed
# earlier
response = requests.get(url)

# Converting the response to JSON, and printing the result.
data = response.json()
print(data)
47/30:
import requests
import json
#import pprint

# Note that the ?t= is a query param for the t-itle of the
# movie we want to search for.
#url = "http://www.omdbapi.com/?t=avengers&apikey=trilogy"
url = "http://www.omdbapi.com/"

# Performing a GET request similar to the one we executed
# earlier
response = requests.get(url)

# Converting the response to JSON, and printing the result.
data = response.json()
print(data)
47/31:
import requests
import json
#import pprint

# Note that the ?t= is a query param for the t-itle of the
# movie we want to search for.
#url = "http://www.omdbapi.com/?t=avengers&apikey=trilogy"
url = "http://www.omdbapi.com/"

# Performing a GET request similar to the one we executed
# earlier
#response = requests.get(url)

# Converting the response to JSON, and printing the result.
#data = response.json()
#print(data)
47/32:
movie = "?t=" + input("What movie do you want to search?")
api_key = "&apikey=trilogy"
full_url = (f"{url}{movie}{api_key}")
47/33: print(movie)
47/34: print(api_key)
47/35: print(full_url)
47/36:
response = requests.get(url)
data = response.json()
print(data)
47/37:
response = requests.get(full_url)
data = response.json()
print(data)
47/38:
import requests
import json
import pprint

# Note that the ?t= is a query param for the t-itle of the
# movie we want to search for.
#url = "http://www.omdbapi.com/?t=avengers&apikey=trilogy"
url = "http://www.omdbapi.com/"

# Performing a GET request similar to the one we executed
# earlier
#response = requests.get(url)

# Converting the response to JSON, and printing the result.
#data = response.json()
#print(data)
47/39:
response = requests.get(full_url)
data = response.json()
pprint(data)
47/40:
import requests
import json
#import pprint

# Note that the ?t= is a query param for the t-itle of the
# movie we want to search for.
#url = "http://www.omdbapi.com/?t=avengers&apikey=trilogy"
url = "http://www.omdbapi.com/"

# Performing a GET request similar to the one we executed
# earlier
#response = requests.get(url)

# Converting the response to JSON, and printing the result.
#data = response.json()
#print(data)
47/41:
response = requests.get(full_url)
data = response.json()
print(data)
47/42:
movie = "?t=" + input("What movie do you want to search?")
api_key = "&apikey=trilogy"
full_url = (f"{url}{movie}{api_key}")
47/43:
response = requests.get(full_url)
data = response.json()
print(data)
47/44:
movie = "?t=" + input("What movie do you want to search?")
api_key = "&apikey=trilogy"
full_url = (f"{url}{movie}{api_key}")
47/45:
response = requests.get(full_url)
data = response.json()
print(data)
47/46:
import requests
import json
#import pprint

# Note that the ?t= is a query param for the t-itle of the
# movie we want to search for.
#url = "http://www.omdbapi.com/?t=avengers&apikey=trilogy"

# Performing a GET request similar to the one we executed
# earlier
#response = requests.get(url)

# Converting the response to JSON, and printing the result.
#data = response.json()
#print(data)
47/47:
url = "http://www.omdbapi.com/"
movie = "?t=" + input("What movie do you want to search?")
api_key = "&apikey=trilogy"
full_url = (f"{url}{movie}{api_key}")
47/48:
response = requests.get(full_url)
data = response.json()
print(data)
44/8:
#pretty print the output of the JSON
response = requests.get(url).json()
print(json.dumps(response, indent = 4, sort_keys=True))
47/49:
response = requests.get(full_url)
data = response.json()
pp = pprint.PrettyPrinter(indent = 4)
pp.pprint(data)
48/1:
# Dependencies and Setup
import matplotlib.pyplot as plt
import pandas as pd
import scipy.stats as st

# Study data files
mouse_metadata_path = "/Users/Jerry/Documents/Homework/Mouse_metadata.csv"
study_results_path = "/Users/Jerry/Documents/Homework/Study_results.csv"

# Read the mouse data and the study results
mouse_metadata = pd.read_csv(mouse_metadata_path)
study_results = pd.read_csv(study_results_path)

# Combine the data into a single dataset

# Display the data table for preview
48/2: mouse_metadata.head()
48/3: study_results.head()
48/4:
# Dependencies and Setup
import matplotlib.pyplot as plt
import pandas as pd
import scipy.stats as st

# Study data files
mouse_metadata_path = "Mouse_metadata.csv"
study_results_path = "/Users/Jerry/Documents/Homework/Study_results.csv"

# Read the mouse data and the study results
mouse_metadata = pd.read_csv(mouse_metadata_path)
study_results = pd.read_csv(study_results_path)

# Combine the data into a single dataset

# Display the data table for preview
48/5: mouse_metadata.head()
48/6:
# Dependencies and Setup
import matplotlib.pyplot as plt
import pandas as pd
import scipy.stats as st

# Study data files
mouse_metadata_path = "Mouse_metadata.csv"
study_results_path = "Study_results.csv"

# Read the mouse data and the study results
mouse_metadata = pd.read_csv(mouse_metadata_path)
study_results = pd.read_csv(study_results_path)

# Combine the data into a single dataset

# Display the data table for preview
48/7: mouse_metadata.head()
48/8: study_results.head()
48/9: mouse_metadata.tail()
48/10: study_results.tail()
48/11: mouse_metadata.head()
48/12: study_results.head()
48/13: mouse_metadata.describe()
48/14: study_results.describe()
48/15: mouse_metadata["Drug Regimen"].unique()
48/16: mouse_metadata.tail()
48/17:
# Dependencies and Setup
import matplotlib.pyplot as plt
import pandas as pd
import scipy.stats as st

# Study data files
mouse_metadata_path = "Mouse_metadata.csv"
study_results_path = "Study_results.csv"

# Read the mouse data and the study results
mouse_metadata = pd.read_csv(mouse_metadata_path)
study_results = pd.read_csv(study_results_path)

# Combine the data into a single dataset
combined_df = mouse_metadata.merge(study_results_path, how="inner", on = "Mouse ID")
# Display the data table for preview
48/18:
# Dependencies and Setup
import matplotlib.pyplot as plt
import pandas as pd
import scipy.stats as st

# Study data files
mouse_metadata_path = "Mouse_metadata.csv"
study_results_path = "Study_results.csv"

# Read the mouse data and the study results
mouse_metadata = pd.read_csv(mouse_metadata_path)
study_results = pd.read_csv(study_results_path)

# Combine the data into a single dataset
combined_df = mouse_metadata.merge(study_results_path, how='inner', on = 'Mouse ID')
# Display the data table for preview
48/19:
# Dependencies and Setup
import matplotlib.pyplot as plt
import pandas as pd
import scipy.stats as st

# Study data files
mouse_metadata_path = "Mouse_metadata.csv"
study_results_path = "Study_results.csv"

# Read the mouse data and the study results
mouse_metadata = pd.read_csv(mouse_metadata_path)
study_results = pd.read_csv(study_results_path)

# Combine the data into a single dataset
combined_df = mouse_metadata.merge(study_results_path, how='inner', on='Mouse ID')
# Display the data table for preview
48/20:
# Dependencies and Setup
import matplotlib.pyplot as plt
import pandas as pd
import scipy.stats as st

# Study data files
mouse_metadata_path = "Mouse_metadata.csv"
study_results_path = "Study_results.csv"

# Read the mouse data and the study results
mouse_metadata = pd.read_csv(mouse_metadata_path)
study_results = pd.read_csv(study_results_path)

# Combine the data into a single dataset
combined_df = mouse_metadata.merge(study_results, how='inner', on='Mouse ID')
# Display the data table for preview
48/21:
# Dependencies and Setup
import matplotlib.pyplot as plt
import pandas as pd
import scipy.stats as st

# Study data files
mouse_metadata_path = "Mouse_metadata.csv"
study_results_path = "Study_results.csv"

# Read the mouse data and the study results
mouse_metadata = pd.read_csv(mouse_metadata_path)
study_results = pd.read_csv(study_results_path)

# Combine the data into a single dataset
combined_df = mouse_metadata.merge(study_results, how='inner', on='Mouse ID')
# Display the data table for preview
combine_df.head()
48/22:
# Dependencies and Setup
import matplotlib.pyplot as plt
import pandas as pd
import scipy.stats as st

# Study data files
mouse_metadata_path = "Mouse_metadata.csv"
study_results_path = "Study_results.csv"

# Read the mouse data and the study results
mouse_metadata = pd.read_csv(mouse_metadata_path)
study_results = pd.read_csv(study_results_path)

# Combine the data into a single dataset
combined_df = mouse_metadata.merge(study_results, how='inner', on='Mouse ID')
# Display the data table for preview
combined_df.head()
48/23:
# Dependencies and Setup
import matplotlib.pyplot as plt
import pandas as pd
import scipy.stats as st

# Study data files
mouse_metadata_path = "Mouse_metadata.csv"
study_results_path = "Study_results.csv"

# Read the mouse data and the study results
mouse_metadata = pd.read_csv(mouse_metadata_path)
study_results = pd.read_csv(study_results_path)

# Combine the data into a single dataset
combined_df = mouse_metadata.merge(study_results, how='inner', on='Mouse ID')
# Display the data table for preview
combined_df.count()
48/24:
# Dependencies and Setup
import matplotlib.pyplot as plt
import pandas as pd
import scipy.stats as st

# Study data files
mouse_metadata_path = "Mouse_metadata.csv"
study_results_path = "Study_results.csv"

# Read the mouse data and the study results
mouse_metadata = pd.read_csv(mouse_metadata_path)
study_results = pd.read_csv(study_results_path)

# Combine the data into a single dataset
combined_df = mouse_metadata.merge(study_results, how='inner', on='Mouse ID')
# Display the data table for preview
combined_df.head()
48/25: combined_df["Mouse ID"].value_counts()
48/26:
# Checking the number of mice.
#unique mice IDs
combined_df["Mouse ID"].unique()

#checking the amount of times a mice ID shows up.
#combined_df["Mouse ID"].value_counts()
48/27:
# Checking the number of mice.
#unique mice IDs
combined_df["Mouse ID"].count()

#checking the amount of times a mice ID shows up.
#combined_df["Mouse ID"].value_counts()
48/28:
# Checking the number of mice.
#combined_df["Mouse ID"].count()
#unique mice IDs
(combined_df["Mouse ID"].unique()).count()

#checking the amount of times a mice ID shows up.
#combined_df["Mouse ID"].value_counts()
48/29:
# Checking the number of mice.
#combined_df["Mouse ID"].count()
#unique mice IDs
combined_df(combined_df["Mouse ID"].unique()).count()

#checking the amount of times a mice ID shows up.
#combined_df["Mouse ID"].value_counts()
48/30:
# Checking the number of mice.
#combined_df["Mouse ID"].count()
#unique mice IDs
a = combined_df["Mouse ID"].unique()
a.count()
#checking the amount of times a mice ID shows up.
#combined_df["Mouse ID"].value_counts()
48/31:
# Checking the number of mice.
#combined_df["Mouse ID"].count()
#unique mice IDs
combined_df["Mouse ID"].unique()

#checking the amount of times a mice ID shows up.
#combined_df["Mouse ID"].value_counts()
48/32:
# Checking the number of mice.
#combined_df["Mouse ID"].count()
#unique mice IDs
a = len(combined_df["Mouse ID"].unique())

#checking the amount of times a mice ID shows up.
#combined_df["Mouse ID"].value_counts()
48/33:
# Checking the number of mice.
#combined_df["Mouse ID"].count()
#unique mice IDs
a = len(combined_df["Mouse ID"].unique())
a
#checking the amount of times a mice ID shows up.
#combined_df["Mouse ID"].value_counts()
48/34: combined_df[["Mouse ID", "Timepoint"]].value_counts()
48/35: combined_df["Mouse ID"].value_counts()
48/36: combined_df[["Mouse ID", "Timepoint"]].value_counts()
48/37: d = combined_df[["Mouse ID", "Timepoint"]].value_counts()
48/38: d.head()
48/39: d.tail()
48/40: d.head()
48/41: combined_df[["Mouse ID", "Timepoint"]].value_counts()
48/42: d = combined_df[["Mouse ID", "Timepoint"]].value_counts()
48/43:
d = combined_df[["Mouse ID", "Timepoint"]].value_counts()
d
48/44: combined_df.groupby[["Mouse ID", "Timepoint"]].count()
48/45: combined_df.groupby[["Mouse ID", "Timepoint"]].value_counts()
48/46: combined_df.groupby[["Mouse ID", "Timepoint"]].sum()
48/47: combined_df.groupby("Mouse ID")["Timepoint"].count()
50/1:
#The average score in Math for each school
mathrate = school_data_complete.groupby('school_name')['math_score'].mean()

#The average score in Reading for each school
readrate = school_data_complete.groupby('school_name')['reading_score'].mean()
50/2:
#import csv files
csv_students = "/Users/Jerry/Documents/Homework/students_complete.csv"
csv_schools = "/Users/Jerry/Documents/Homework/schools_complete.csv"
csv_purchases = "/Users/Jerry/Documents/Homework/purchase_data.csv"

students_df = pd.read_csv(csv_students)
schools_df = pd.read_csv(csv_schools)
purchases_df = pd.read_csv(csv_purchases)

#combine the data into a singe dataset
school_data_complete = pd.merge(students_df, schools_df, how = "left", on=["school_name", "school_name"])
50/3:
#import dependencies
import pandas as pd
import numpy as np
50/4:
#import csv files
csv_students = "/Users/Jerry/Documents/Homework/students_complete.csv"
csv_schools = "/Users/Jerry/Documents/Homework/schools_complete.csv"
csv_purchases = "/Users/Jerry/Documents/Homework/purchase_data.csv"

students_df = pd.read_csv(csv_students)
schools_df = pd.read_csv(csv_schools)
purchases_df = pd.read_csv(csv_purchases)

#combine the data into a singe dataset
school_data_complete = pd.merge(students_df, schools_df, how = "left", on=["school_name", "school_name"])
50/5:
#import csv files
csv_students = "students_complete.csv"
csv_schools = "schools_complete.csv"
csv_purchases = "purchase_data.csv"

students_df = pd.read_csv(csv_students)
schools_df = pd.read_csv(csv_schools)
purchases_df = pd.read_csv(csv_purchases)

#combine the data into a singe dataset
school_data_complete = pd.merge(students_df, schools_df, how = "left", on=["school_name", "school_name"])
50/6:
#import dependencies
import pandas as pd
import numpy as np
50/7:
#import csv files
csv_students = "students_complete.csv"
csv_schools = "schools_complete.csv"
csv_purchases = "purchase_data.csv"

students_df = pd.read_csv(csv_students)
schools_df = pd.read_csv(csv_schools)
purchases_df = pd.read_csv(csv_purchases)

#combine the data into a singe dataset
school_data_complete = pd.merge(students_df, schools_df, how = "left", on=["school_name", "school_name"])
50/8:
#The average score in Math for each school
mathrate = school_data_complete.groupby('school_name')['math_score'].mean()

#The average score in Reading for each school
readrate = school_data_complete.groupby('school_name')['reading_score'].mean()
50/9:
#The average score in Math for each school
mathrate = school_data_complete.groupby('school_name')['math_score'].mean()

#The average score in Reading for each school
readrate = school_data_complete.groupby('school_name')['reading_score'].mean()
readrate
50/10:
#Filter out students who didn't pass math with a 70 or higher
math_table = school_data_complete.loc[(school_data_complete["math_score"] >= 70), :]

#count the number of students left in df and group them by school_name
total_passing_m = math_table.groupby('school_name')['Student ID'].count()
50/11:
#Filter out students who didn't pass reading with a 70 or higher
reading_table = school_data_complete.loc[(school_data_complete["reading_score"] >= 70), :]

#count the number of students left in df and group them by school_name
total_passing_r = reading_table.groupby('school_name')['Student ID'].count()
50/12:
# % overall passing (the percentage of students who passed math AND reading

#Filter out students who didn't pass math with a 70 or higher
students_table = school_data_complete.loc[(school_data_complete["math_score"] >= 70) &
                                          (school_data_complete["reading_score"] >= 70), :]

#count the number of students left in df and group them by school_name
overall_passing = students_table.groupby('school_name')['Student ID'].count()
50/13:
#create main df by filtering 4 columns from schools_df into main df
filtered_schools_df = schools_df[["school_name", "type", "size", "budget"]]

#Sort df alphabetically by school_name
filtered_schools_df = filtered_schools_df.sort_values(by = 'school_name', ascending=True)

#set school_name as index
filtered_schools_df.set_index('school_name', inplace=True)

#check progress
filtered_schools_df
50/14:
#Create column for per student budget
filtered_schools_df["Per Student Budget"] = (filtered_schools_df["budget"]/filtered_schools_df["size"])
48/48: n_df = pd.DataFrame(d)
48/49:
n_df = pd.DataFrame(d)
n_df
48/50:
n_df = pd.DataFrame(d)
filtered_df = n_df.loc[(n_df["0"] < 2), :]
48/51:
d = combined_df[["Mouse ID", "Timepoint"]].value_counts()
type(d)
48/52:
d = combined_df[["Mouse ID", "Timepoint"]].value_counts()
e = {'count': d}
48/53:
d = combined_df[["Mouse ID", "Timepoint"]].value_counts()
e = {'count': d}
e
48/54:
d = combined_df[["Mouse ID", "Timepoint"]].value_counts()
d
48/55:
n_df = pd.DataFrame(d)
#filtered_df = n_df.loc[(n_df["0"] < 2), :]
48/56: n_df
48/57: n_df = n_df.rename[columns = {"0":"count"}]
48/58: n_df = n_df.rename[columns= {"0":"count"}]
48/59: n_df.columns
48/60: n_df.columns()
48/61: n_df.columns
48/62: mouse_metadata.columns
48/63:
d = combined_df[["Mouse ID", "Timepoint"]].value_counts()
d.columns
48/64: n_df.columns
48/65: n_df
48/66: d = combined_df[["Mouse ID", "Timepoint"]].value_counts()
48/67:
d = combined_df[["Mouse ID", "Timepoint"]].value_counts()
d
48/68:
# Dependencies and Setup
import matplotlib.pyplot as plt
import pandas as pd
import scipy.stats as st
import numpy as np

# Study data files
mouse_metadata_path = "Mouse_metadata.csv"
study_results_path = "Study_results.csv"

# Read the mouse data and the study results
mouse_metadata = pd.read_csv(mouse_metadata_path)
study_results = pd.read_csv(study_results_path)

# Combine the data into a single dataset
combined_df = mouse_metadata.merge(study_results, how='inner', on='Mouse ID')
# Display the data table for preview
combined_df.head()
48/69: combined_df["Mouse ID"].unique()
48/70:
# Checking the number of mice.
#unique mice IDs
a = len(combined_df["Mouse ID"].unique())
a
#checking the amount of times a mice ID shows up.
#combined_df["Mouse ID"].value_counts()
48/71: clean_df = combined_df.loc[(combined_df["Mouse ID"] == "g989"), :]
48/72:
clean_df = combined_df.loc[(combined_df["Mouse ID"] == "g989"), :]
clean_df
48/73:
clean_df = combined_df.loc[(combined_df["Mouse ID"] != "g989"), :]
clean_df
48/74: clean_df[["Mouse ID", "Timepoint"]].value_counts()
48/75:
# Generate a summary statistics table of mean, median, variance, standard deviation, and SEM of the tumor volume for each regimen

# Use groupby and summary statistical methods to calculate the following properties of each drug regimen: 
# mean, median, variance, standard deviation, and SEM of the tumor volume. 
# Assemble the resulting series into a single summary dataframe.


mean_summary = clean_df["Tumor Volume (mm3)"].mean()
48/76:
# Generate a summary statistics table of mean, median, variance, standard deviation, and SEM of the tumor volume for each regimen

# Use groupby and summary statistical methods to calculate the following properties of each drug regimen: 
# mean, median, variance, standard deviation, and SEM of the tumor volume. 
# Assemble the resulting series into a single summary dataframe.


mean_summary = clean_df["Tumor Volume (mm3)"].mean()
median_summary = clean_df["Tumor Volume (mm3)"].median()
48/77:
# Generate a summary statistics table of mean, median, variance, standard deviation, and SEM of the tumor volume for each regimen

# Use groupby and summary statistical methods to calculate the following properties of each drug regimen: 
# mean, median, variance, standard deviation, and SEM of the tumor volume. 
# Assemble the resulting series into a single summary dataframe.


mean_summary = clean_df["Tumor Volume (mm3)"].mean()
median_summary = clean_df["Tumor Volume (mm3)"].median()
variance_summary = clean_df["Tumor Volume (mm3)"].variance()
std_summary = clean_df["Tumor Volume (mm3)"].std()
sem_summary = clean_df["Tumor Volume (mm3)"].sem()
48/78:
# Generate a summary statistics table of mean, median, variance, standard deviation, and SEM of the tumor volume for each regimen

# Use groupby and summary statistical methods to calculate the following properties of each drug regimen: 
# mean, median, variance, standard deviation, and SEM of the tumor volume. 
# Assemble the resulting series into a single summary dataframe.


mean_summary = clean_df["Tumor Volume (mm3)"].mean()
median_summary = clean_df["Tumor Volume (mm3)"].median()
variance_summary = clean_df["Tumor Volume (mm3)"].var()
std_summary = clean_df["Tumor Volume (mm3)"].std()
sem_summary = clean_df["Tumor Volume (mm3)"].sem()
48/79:
# Generate a summary statistics table of mean, median, variance, standard deviation, and SEM of the tumor volume for each regimen

# Use groupby and summary statistical methods to calculate the following properties of each drug regimen: 
# mean, median, variance, standard deviation, and SEM of the tumor volume. 
# Assemble the resulting series into a single summary dataframe.


mean_summary = clean_df["Tumor Volume (mm3)"].mean()
median_summary = clean_df["Tumor Volume (mm3)"].median()
variance_summary = clean_df["Tumor Volume (mm3)"].var()
std_summary = clean_df["Tumor Volume (mm3)"].std()
sem_summary = clean_df["Tumor Volume (mm3)"].sem()


summary_df = pd.DataFrame({"":,
                           "":,
                           "":,
                          })
48/80:
# Generate a summary statistics table of mean, median, variance, standard deviation, and SEM of the tumor volume for each regimen

# Use groupby and summary statistical methods to calculate the following properties of each drug regimen: 
# mean, median, variance, standard deviation, and SEM of the tumor volume. 
# Assemble the resulting series into a single summary dataframe.


mean_summary = clean_df["Tumor Volume (mm3)"].mean()
median_summary = clean_df["Tumor Volume (mm3)"].median()
variance_summary = clean_df["Tumor Volume (mm3)"].var()
std_summary = clean_df["Tumor Volume (mm3)"].std()
sem_summary = clean_df["Tumor Volume (mm3)"].sem()


summary_df = pd.DataFrame({"mean tumor volume": mean_summary,
                           "median tumor volume": median_summary,
                           "varinace tumor volume": variance_summary,
                           "tumor volume std": std_summary,
                           "tumor volume sem": sem_summary})
48/81: summary_group = clean_df.groupby("Drug Regimen")
48/82:
# Generate a summary statistics table of mean, median, variance, standard deviation, and SEM of the tumor volume for each regimen

# Use groupby and summary statistical methods to calculate the following properties of each drug regimen: 
# mean, median, variance, standard deviation, and SEM of the tumor volume. 
# Assemble the resulting series into a single summary dataframe.
summary_group = clean_df.groupby("Drug Regimen")

mean_summary = summary_group["Tumor Volume (mm3)"].mean()
median_summary = summary_group["Tumor Volume (mm3)"].median()
variance_summary = summary_group["Tumor Volume (mm3)"].var()
std_summary = summary_group["Tumor Volume (mm3)"].std()
sem_summary = summary_group["Tumor Volume (mm3)"].sem()


summary_df = pd.DataFrame({"mean tumor volume": mean_summary,
                           "median tumor volume": median_summary,
                           "varinace tumor volume": variance_summary,
                           "tumor volume std": std_summary,
                           "tumor volume sem": sem_summary})
48/83:
# Using the aggregation method, produce the same summary statistics in a single line
summary_arg = clean_df.groupby["Drug Regimen"]("Tumor Volume (mm3)").agg(['mean', 'median', 'var', 'std', 'sem'])
48/84:
# Using the aggregation method, produce the same summary statistics in a single line
summary_arg = clean_df.groupby(["Drug Regimen"])[["Tumor Volume (mm3)"]].agg(['mean', 'median', 'var', 'std', 'sem'])
48/85:
# Using the aggregation method, produce the same summary statistics in a single line
summary_arg = clean_df.groupby(["Drug Regimen"])[["Tumor Volume (mm3)"]].agg(['mean', 'median', 'var', 'std', 'sem'])
summary_arg
48/86:
#Bar and Pie Charts
# Generate a bar plot showing the total number of timepoints for all mice tested for each drug
#regimen using Pandas.
48/87:
#Bar and Pie Charts
# Generate a bar plot showing the total number of timepoints for all mice tested for each drug
#regimen using Pandas.

drug_regimen = pd.DataFrame(clean_df.groupby(["Drug Regimen"]).count()).reset_index()
drug_regimen
48/88:
#Bar and Pie Charts
# Generate a bar plot showing the total number of timepoints for all mice tested for each drug
#regimen using Pandas.

drug_regimen = pd.DataFrame(clean_df.groupby(["Drug Regimen"]).count()).reset_index()

#filter the neccessary columns
drug_filtered = drug_regimen[["Drug Regimen", "Timepoint"]]
drug_filtered - drug_filtered.set_index("Drug Regimen")
48/89:
#Bar and Pie Charts
# Generate a bar plot showing the total number of timepoints for all mice tested for each drug
#regimen using Pandas.

drug_regimen = pd.DataFrame(clean_df.groupby(["Drug Regimen"]).count()).reset_index()
drug_regimen
#filter the neccessary columns
#drug_filtered = drug_regimen[["Drug Regimen", ]]
#drug_filtered - drug_filtered.set_index("Drug Regimen")
48/90:
#Bar and Pie Charts
# Generate a bar plot showing the total number of timepoints for all mice tested for each drug
#regimen using Pandas.

drug_regimen = pd.DataFrame(clean_df.groupby(["Drug Regimen"]).count()).reset_index()
drug_regimen
#filter the neccessary columns
drug_filtered = drug_regimen[["Drug Regimen", "Timepoint"]]
#drug_filtered - drug_filtered.set_index("Drug Regimen")
48/91:
#Bar and Pie Charts
# Generate a bar plot showing the total number of timepoints for all mice tested for each drug
#regimen using Pandas.

drug_regimen = pd.DataFrame(clean_df.groupby(["Drug Regimen"]).count()).reset_index()
drug_regimen
#filter the neccessary columns
drug_filtered = drug_regimen[["Drug Regimen", "Timepoint"]]
drug_filtered
#drug_filtered - drug_filtered.set_index("Drug Regimen")
48/92:
#Bar and Pie Charts
# Generate a bar plot showing the total number of timepoints for all mice tested for each drug
#regimen using Pandas.

drug_regimen = pd.DataFrame(clean_df.groupby(["Drug Regimen"]).count()).reset_index()
drug_regimen
#filter the neccessary columns
drug_filtered = drug_regimen[["Drug Regimen", "Timepoint"]]

drug_filtered = drug_filtered.set_index("Drug Regimen")
48/93:
#Bar and Pie Charts
# Generate a bar plot showing the total number of timepoints for all mice tested for each drug
#regimen using Pandas.

drug_regimen = pd.DataFrame(clean_df.groupby(["Drug Regimen"]).count()).reset_index()
drug_regimen
#filter the neccessary columns
drug_filtered = drug_regimen[["Drug Regimen", "Timepoint"]]

drug_filtered = drug_filtered.set_index("Drug Regimen")
drug_filtered
48/94:
#Bar and Pie Charts
# Generate a bar plot showing the total number of timepoints for all mice tested for each drug
#regimen using Pandas.

drug_regimen = pd.DataFrame(clean_df.groupby(["Drug Regimen"]).count()).reset_index()
drug_regimen
#filter the neccessary columns
drug_filtered = drug_regimen[["Drug Regimen", "Timepoint"]]

drug_filtered = drug_filtered.set_index("Drug Regimen")
drug_filtered.plot(kind = "bar", legend = False, rot =50)
48/95:
#Bar and Pie Charts
# Generate a bar plot showing the total number of timepoints for all mice tested for each drug
#regimen using Pandas.

drug_regimen = pd.DataFrame(clean_df.groupby(["Drug Regimen"]).count()).reset_index()
drug_regimen
#filter the neccessary columns
drug_filtered = drug_regimen[["Drug Regimen", "Timepoint"]]

drug_filtered = drug_filtered.set_index("Drug Regimen")
drug_filtered.plt(kind = "bar", legend = False, rot =50)
48/96:
#Bar and Pie Charts
# Generate a bar plot showing the total number of timepoints for all mice tested for each drug
#regimen using Pandas.

drug_regimen = pd.DataFrame(clean_df.groupby(["Drug Regimen"]).count()).reset_index()
drug_regimen
#filter the neccessary columns
drug_filtered = drug_regimen[["Drug Regimen", "Timepoint"]]

drug_filtered = drug_filtered.set_index("Drug Regimen")
drug_filtered.plot(kind = "bar", legend = False, rot =50)
48/97:
#Bar and Pie Charts
# Generate a bar plot showing the total number of timepoints for all mice tested for each drug
#regimen using Pandas.

drug_regimen = pd.DataFrame(clean_df.groupby(["Drug Regimen"]).count()).reset_index()
drug_regimen
#filter the neccessary columns
drug_filtered = drug_regimen[["Drug Regimen", "Timepoint"]]

drug_filtered = drug_filtered.set_index("Drug Regimen")
drug_filtered.plot(kind = "bar", legend = False, rot =50)
plt.title("Test")
48/98:
#Bar and Pie Charts
# Generate a bar plot showing the total number of timepoints for all mice tested for each drug
#regimen using Pandas.

drug_regimen = pd.DataFrame(clean_df.groupby(["Drug Regimen"]).count()).reset_index()
drug_regimen
#filter the neccessary columns
drug_filtered = drug_regimen[["Drug Regimen", "Timepoint"]]

drug_filtered = drug_filtered.set_index("Drug Regimen")
drug_filtered.plot(kind = "pie", legend = False, rot =50)
plt.title("Test")
48/99:
#Bar and Pie Charts
# Generate a bar plot showing the total number of timepoints for all mice tested for each drug
#regimen using Pandas.

drug_regimen = pd.DataFrame(clean_df.groupby(["Drug Regimen"]).count()).reset_index()
drug_regimen
#filter the neccessary columns
drug_filtered = drug_regimen[["Drug Regimen", "Timepoint"]]

drug_filtered = drug_filtered.set_index("Drug Regimen")
drug_filtered.plot(kind = "bar", legend = False, rot =50)
plt.title("Test")
48/100:
# Dependencies and Setup
import matplotlib.pyplot as plt
import pandas as pd
import scipy.stats as st
import numpy as np

# Study data files
mouse_metadata_path = "Mouse_metadata.csv"
study_results_path = "Study_results.csv"

# Read the mouse data and the study results
mouse_metadata = pd.read_csv(mouse_metadata_path)
study_results = pd.read_csv(study_results_path)

# Combine the data into a single dataset
combined_df = mouse_metadata.merge(study_results, how='inner', on='Mouse ID')
# Display the data table for preview
combined_df.head()
48/101:
# Checking the number of mice.
#unique mice IDs
a = len(combined_df["Mouse ID"].unique())
a
#checking the amount of times a mice ID shows up.
#combined_df["Mouse ID"].value_counts()
48/102:
d = combined_df[["Mouse ID", "Timepoint"]].value_counts()
d
48/103:
clean_df = combined_df.loc[(combined_df["Mouse ID"] != "g989"), :]
clean_df
48/104:
#Get all the data for the duplicate mouse ID. 
duplicated_df = combined_df.loc[(combined_df["Mouse ID"] = "g989"), :]
duplicated_df
48/105:
#Get all the data for the duplicate mouse ID. 
duplicated_df = combined_df.loc[(combined_df["Mouse ID"] == "g989"), :]
duplicated_df
48/106:
#Get all the data for the duplicate mouse ID. 
duplicated_df = combined_df.loc[(combined_df["Mouse ID"] == "g989"), :]
#duplicated_df
48/107:
# Create a clean DataFrame by dropping the duplicate mouse by its ID.
clean_df = combined_df.loc[(combined_df["Mouse ID"] != "g989"), :]
clean_df
48/108:
# Checking the number of mice in the clean DataFrame.
clean_df[["Mouse ID", "Timepoint"]].value_counts()
48/109:
# Checking the number of mice in the clean DataFrame.
clean_df["Mouse ID"].unique()
48/110:
# Checking the number of mice in the clean DataFrame.
len(clean_df["Mouse ID"].unique())
48/111:
#Bar and Pie Charts
# Generate a bar plot showing the total number of timepoints for all mice tested for each drug
#regimen using Pandas.

drug_regimen = pd.DataFrame(clean_df.groupby(["Drug Regimen"]).count()).reset_index()
drug_regimen
#filter the neccessary columns
drug_filtered = drug_regimen[["Drug Regimen", "Timepoint"]]

drug_filtered = drug_filtered.set_index("Drug Regimen")
drug_filtered.plot(kind = "bar", legend = False, rot =50)
plt.title("Test")
48/112:
#Bar and Pie Charts
# Generate a bar plot showing the total number of timepoints for all mice tested for each drug
#regimen using Pandas.

drug_regimen = pd.DataFrame(clean_df.groupby(["Drug Regimen"]).count()).reset_index()
drug_regimen
#filter the neccessary columns
#drug_filtered = drug_regimen[["Drug Regimen", "Timepoint"]]

#drug_filtered = drug_filtered.set_index("Drug Regimen")
#drug_filtered.plot(kind = "bar", legend = False, rot =50)
#plt.title("Test")
48/113:
#Bar and Pie Charts
# Generate a bar plot showing the total number of timepoints for all mice tested for each drug
#regimen using Pandas.

drug_regimen = pd.DataFrame(clean_df.groupby(["Drug Regimen"]).count())
#.reset_index()
drug_regimen
#filter the neccessary columns
#drug_filtered = drug_regimen[["Drug Regimen", "Timepoint"]]

#drug_filtered = drug_filtered.set_index("Drug Regimen")
#drug_filtered.plot(kind = "bar", legend = False, rot =50)
#plt.title("Test")
48/114:
#Bar and Pie Charts
# Generate a bar plot showing the total number of timepoints for all mice tested for each drug
#regimen using Pandas.

drug_regimen = pd.DataFrame(clean_df.groupby(["Drug Regimen"]).count()).reset_index()
drug_regimen
#filter the neccessary columns
#drug_filtered = drug_regimen[["Drug Regimen", "Timepoint"]]

#drug_filtered = drug_filtered.set_index("Drug Regimen")
#drug_filtered.plot(kind = "bar", legend = False, rot =50)
#plt.title("Test")
48/115:
#Bar and Pie Charts
# Generate a bar plot showing the total number of timepoints for all mice tested for each drug
#regimen using Pandas.

drug_regimen = pd.DataFrame(clean_df.groupby(["Drug Regimen"]).count())
#.reset_index()
#drug_regimen
#filter the neccessary columns
drug_filtered = drug_regimen[["Drug Regimen", "Timepoint"]]

#drug_filtered = drug_filtered.set_index("Drug Regimen")
drug_filtered
#drug_filtered.plot(kind = "bar", legend = False, rot =50)
#plt.title("Test")
48/116:
#Bar and Pie Charts
# Generate a bar plot showing the total number of timepoints for all mice tested for each drug
#regimen using Pandas.

drug_regimen = pd.DataFrame(clean_df.groupby(["Drug Regimen"]).count())
#.reset_index()
#drug_regimen
#filter the neccessary columns
#drug_filtered = drug_regimen[["Drug Regimen", "Timepoint"]]
drug_filtered = drug_regimen["Timepoint"]


#drug_filtered = drug_filtered.set_index("Drug Regimen")
drug_filtered
#drug_filtered.plot(kind = "bar", legend = False, rot =50)
#plt.title("Test")
48/117:
#Bar and Pie Charts
# Generate a bar plot showing the total number of timepoints for all mice tested for each drug
#regimen using Pandas.

drug_regimen = pd.DataFrame(clean_df.groupby(["Drug Regimen"]).count()).reset_index()

#filter the neccessary columns
drug_filtered = drug_regimen[["Drug Regimen", "Timepoint"]]

drug_filtered = drug_filtered.set_index("Drug Regimen")
drug_filtered.plot(kind = "bar", legend = False, rot =50)
#plt.title("Test")
48/118:
#Bar and Pie Charts
# Generate a bar plot showing the total number of timepoints for all mice tested for each drug
#regimen using Pandas.

drug_regimen = pd.DataFrame(clean_df.groupby(["Drug Regimen"]).count()).reset_index()

#filter the neccessary columns
drug_filtered = drug_regimen[["Drug Regimen", "Timepoint"]]

drug_filtered = drug_filtered.set_index("Drug Regimen")
drug_filtered
#drug_filtered.plot(kind = "bar", legend = False, rot =50)
#plt.title("Test")
48/119:
#Bar and Pie Charts
# Generate a bar plot showing the total number of timepoints for all mice tested for each drug
#regimen using Pandas.

drug_regimen = pd.DataFrame(clean_df.groupby(["Drug Regimen"]).count()).reset_index()

#filter the neccessary columns
drug_filtered = drug_regimen[["Drug Regimen", "Timepoint"]]

drug_filtered = drug_filtered.set_index("Drug Regimen")
drug_filtered.plot(kind = "bar", legend = False, rot =50)
48/120:
#Generate a bar plot showing the total number of timepoints for all mice tested for each drug
#regimen using pyplot.
drug_filtered
48/121:
#Generate a bar plot showing the total number of timepoints for all mice tested for each drug
#regimen using pyplot.
#drug_filtered
x_axis = np.arange(o,8,1)
#plt.bar()
48/122:
#Generate a bar plot showing the total number of timepoints for all mice tested for each drug
#regimen using pyplot.
#drug_filtered
x_axis = np.arange(0,8,1)
x_axis 
#plt.bar()
48/123:
#Generate a bar plot showing the total number of timepoints for all mice tested for each drug
#regimen using pyplot.
#drug_filtered
x_axis = np.arange(1,9,1)
x_axis 
#plt.bar()
48/124:
#Generate a bar plot showing the total number of timepoints for all mice tested for each drug
#regimen using pyplot.
drug_filtered
x_axis = np.arange(1,9,1) 
plt.bar(x_axis, drugs_filtered["Timepoint"])
48/125:
#Generate a bar plot showing the total number of timepoints for all mice tested for each drug
#regimen using pyplot.
x_axis = np.arange(1,9,1) 
plt.bar(x_axis, drug_filtered["Timepoint"])
48/126:
#Create the array of the number of mice that each drug have
drug_array = drug_filtered.tolist()
48/127:
#Bar and Pie Charts
# Generate a bar plot showing the total number of timepoints for all mice tested for each drug
#regimen using Pandas.

drug_regimen = pd.DataFrame(clean_df.groupby(["Drug Regimen"]).count()).reset_index()

#filter the neccessary columns
drug_filtered = drug_regimen[["Drug Regimen", "Timepoint"]]

drug_filtered = drug_filtered.set_index("Drug Regimen")
drug_filtered.plot(kind = "bar", legend = False, rot =50)
48/128:
#Create the array of the number of mice that each drug have
num_mice = (clean_df.groupby(["Drug Regimen"])["Timepoint"].count()).tolist()
48/129:
#Generate a bar plot showing the total number of timepoints for all mice tested for each drug
#regimen using pyplot.
x_axis = np.arange(len(drug_filtered))
plt.bar(x_axis, num_mice, color="r", alpha = 0.6 )
48/130:
#Generate a bar plot showing the total number of timepoints for all mice tested for each drug
#regimen using pyplot.
x_axis = np.arange(len(drug_filtered))
plt.bar(x_axis, num_mice, color="r", alpha = 0.6, align = "center")
48/131:
#Generate a bar plot showing the total number of timepoints for all mice tested for each drug
#regimen using pyplot.
x_axis = np.arange(len(drug_filtered))
plt.bar(x_axis, num_mice, color="r", alpha = 0.6, align = "center")




plt.title(Total Number of timepoints by each drug regimen)
48/132:
#Generate a bar plot showing the total number of timepoints for all mice tested for each drug
#regimen using pyplot.
x_axis = np.arange(len(drug_filtered))
plt.bar(x_axis, num_mice, color="r", alpha = 0.6, align = "center")




plt.title("Total Number of timepoints by each drug regimen")
plt.ytitle("Count of timepoints")
48/133:
#Generate a bar plot showing the total number of timepoints for all mice tested for each drug
#regimen using pyplot.
x_axis = np.arange(len(drug_filtered))
plt.bar(x_axis, num_mice, color="r", alpha = 0.6, align = "center")




plt.title("Total Number of timepoints by each drug regimen")
plt.ylabel("Count of timepoints")
48/134:
#Generate a bar plot showing the total number of timepoints for all mice tested for each drug
#regimen using pyplot.
x_axis = np.arange(len(drug_filtered))
plt.bar(x_axis, num_mice, color="r", alpha = 0.6, align = "center")




plt.title("Total Number of timepoints by each drug regimen")
plt.ylabel("Count of timepoints")
plt.xlabel("Drugs")
48/135: drug_filtered.columns
48/136: clean_df["Drug regimen"].unique()
48/137: clean_df["Drug Regimen"].unique()
48/138:
#Generate a bar plot showing the total number of timepoints for all mice tested for each drug
#regimen using pyplot.
x_axis = np.arange(len(drug_filtered))
plt.bar(x_axis, num_mice, color="r", alpha = 0.6, align = "center")

#Create tick locations assigned to the name for x_axis
tick_locations = [value for value in x_axis]
plt.xticks(tick_locations, ["Capomulin", "Ceftamin", "Infubinol", "Ketapril", "Naftisol", "Placebo", "Propriva", "Ramicane", "Stelasyn", "Zoniferol"])
plt.xticks(rotation = 45)

plt.title("Total Number of timepoints by each drug regimen")
plt.ylabel("Count of timepoints")
plt.xlabel("Drugs")
48/139:
#Generate two pie plots. Both plots should be identical and show the distribution of 
#female or male mice in the study.

#Create the first pie plot by using both Pandas's DataFrame.plot().
gender_pie = clean_df["Sex"].value_counts()
48/140:
#Generate two pie plots. Both plots should be identical and show the distribution of 
#female or male mice in the study.

#Create the first pie plot by using both Pandas's DataFrame.plot().
gender_pie = clean_df["Sex"].value_counts()
gender_pie
48/141:
#Generate two pie plots. Both plots should be identical and show the distribution of 
#female or male mice in the study.

#Create the first pie plot by using both Pandas's DataFrame.plot().
gender_pie = clean_df["Sex"].value_counts()
gender_pie.plot.pie(autopct = "%1.1f%%")
plt.show()
48/142:
#Create the second pie plot by using Matplotlib's pyplot methods.

#create variables for attributes in plt.pie function
colors = ["red", "blue"]
explode = 0.01, 0
labels = ["male", "female"]
plt.pie(gender_pie, explode = explode, label = labels, colors = colors)
48/143:
#Create the second pie plot by using Matplotlib's pyplot methods.

#create variables for attributes in plt.pie function
colors = ["red", "blue"]
explode = 0.01, 0
labels = ["male", "female"]
plt.pie(gender_pie, explode = explode, labels = labels, colors = colors)
48/144:
#Create the second pie plot by using Matplotlib's pyplot methods.

#create variables for attributes in plt.pie function
colors = ["blue", "pink"]
explode = 0.01, 0
labels = ["male", "female"]
plt.pie(gender_pie, explode = explode, labels = labels, colors = colors)
48/145:
#Create the second pie plot by using Matplotlib's pyplot methods.

#create variables for attributes in plt.pie function
colors = ["blue", "pink"]
explode = 0.01, 0
labels = ["male", "female"]
plt.pie(gender_pie, explode = explode, labels = labels, colors = colors, autopct = "%1.1f%%")
48/146:
#Create the second pie plot by using Matplotlib's pyplot methods.

#create variables for attributes in plt.pie function
colors = ["blue", "pink"]
explode = 0.01, 0
labels = ["male", "female"]
plt.pie(gender_pie, explode = explode, labels = labels, colors = colors, autopct = "%1.1f%%", alpha = .5)
48/147:
#Create the second pie plot by using Matplotlib's pyplot methods.

#create variables for attributes in plt.pie function
colors = ["blue", "pink"]
explode = 0.01, 0
labels = ["male", "female"]
plt.pie(gender_pie, explode = explode, labels = labels, colors = colors, autopct = "%1.1f%%")
48/148:
#Create the second pie plot by using Matplotlib's pyplot methods.

#create variables for attributes in plt.pie function
colors = ["blue", "pink"]
explode = 0.01, 0
labels = ["male", "female"]
plt.pie(gender_pie, explode = explode, labels = labels, colors = colors, autopct = "%1.1f%%")
plt.title(Pyplot "The distribution of male and female mice")
48/149:
#Create the second pie plot by using Matplotlib's pyplot methods.

#create variables for attributes in plt.pie function
colors = ["blue", "pink"]
explode = 0.01, 0
labels = ["male", "female"]
plt.pie(gender_pie, explode = explode, labels = labels, colors = colors, autopct = "%1.1f%%")
plt.title("Pyplot: The distribution of male and female mice")
48/150:
#Create the second pie plot by using Matplotlib's pyplot methods.

#create variables for attributes in plt.pie function
colors = ["blue", "pink"]
explode = 0.01, 0
labels = ["male", "female"]
plt.pie(gender_pie, explode = explode, labels = labels, colors = colors, autopct = "%1.1f%%")
plt.title("Pyplot: The distribution of male and female mice")
plt.ylabel("Gender")
48/151:
#Create the second pie plot by using Matplotlib's pyplot methods.

#create variables for attributes in plt.pie function
colors = ["blue", "pink"]
explode = 0.01, 0
labels = ["male", "female"]
plt.pie(gender_pie, explode = explode, labels = labels, colors = colors, autopct = "%1.1f%%")
plt.title("Pyplot: The distribution of male and female mice")
plt.ylabel("Sex")
51/1:
 # Dependencies
import json
import os

# Load JSON
filepath = os.path.join("..", "Resources", "video_api_response.json")
with open(filepath) as jsonfile:
    json_data = json.load(jsonfile)
51/2:
 # Dependencies
import json
import os

# Load JSON
filepath = os.path.join("..", "Resources", "video_api_response.json")
with open(filepath) as jsonfile:
    json_data = json.load(jsonfile)
51/3:
 # Dependencies
import json
import os

# Load JSON
filepath = os.path.join("..", "Resources", "video_api_response.json")
with open(filepath) as jsonfile:
    json_data = json.load(jsonfile)
51/4:
 # Dependencies
import json
import os

# Load JSON
filepath = os.path.join("..", "Documnets", "video_api_response.json")
with open(filepath) as jsonfile:
    json_data = json.load(jsonfile)
51/5:
 # Dependencies
import json
import os

# Load JSON
filepath = os.path.join("..", "Resources", "video_api_response.json")
with open(filepath) as jsonfile:
    json_data = json.load(jsonfile)
51/6:
 # Dependencies
import json
import os

# Load JSON
filepath = os.path.join(/Users/Jerry/Documents/video_api_response.json)
with open(filepath) as jsonfile:
    json_data = json.load(jsonfile)
51/7:
 # Dependencies
import json
import os

# Load JSON
filepath = os.path.join("..", "Resources", "video_api_response.json")
with open(filepath) as jsonfile:
    json_data = json.load(jsonfile)
51/8:
 # Dependencies
import json
import os

# Load JSON
filepath = os.path.join("..", "Resources", "video_api_response.json")
with open(filepath) as jsonfile:
    json_data = json.load(jsonfile)
51/9:
 # Dependencies
import json
import os
import pandas as pd

# Load JSON
csv = "video_api_response.json"
filepath = pd.read_csv(csv)
with open(filepath) as jsonfile:
    json_data = json.load(jsonfile)
51/10:
 # Dependencies
import json
import os
import pandas as pd

# Load JSON
csv = "/Users/Jerry/Documents/Resources/video_api_response.json"
filepath = pd.read_csv(csv)
with open(filepath) as jsonfile:
    json_data = json.load(jsonfile)
51/11:
 # Dependencies
import json
import os
import pandas as pd

# Load JSON
csv = "/Users/Jerry/Documents/Resources/video_api_response.json"
filepath = pd.read_csv(csv)
#with open(filepath) as jsonfile:
 #   json_data = json.load(jsonfile)
51/12:
 # Dependencies
import json
import os
import pandas as pd

# Load JSON
csv = "/Users/Jerry/Documents/Resources/video_api_response.json"
filepath = pd.read_csv(csv)
#with open(filepath) as jsonfile:
 #   json_data = json.load(jsonfile)
51/13:
 # Dependencies
import json
import os
import pandas as pd

# Load JSON
csv = "/Users/Jerry/Documents/Resources/video_api_response.json"
filepath = pd.csv_read(csv)
#with open(filepath) as jsonfile:
 #   json_data = json.load(jsonfile)
51/14:
 # Dependencies
import json
import os
import pandas as pd

# Load JSON
csv = "/Users/Jerry/Documents/Resources/video_api_response.json"
filepath = pd.read_csv(csv)
#with open(filepath) as jsonfile:
 #   json_data = json.load(jsonfile)
51/15:
 # Dependencies
import json
import os
import pandas as pd

# Load JSON
csv = "/Users/Jerry/Documents/Resources/video_api_response.json"
filepath = pd.read_json(csv)
#with open(filepath) as jsonfile:
 #   json_data = json.load(jsonfile)
51/16:
 # Dependencies
import json
import os
import pandas as pd

# Load JSON
csv = "/Users/Jerry/Documents/Resources/video_api_response.json"
filepath = pd.read_json(csv)
with open(filepath) as jsonfile:
    json_data = json.load(jsonfile)
51/17:
 # Dependencies
import json
import os
import pandas as pd

# Load JSON
csv = "/Users/Jerry/Documents/Resources/video_api_response.json"
loaded_json = pd.read_json(csv)
#with open(filepath) as jsonfile:
 #   json_data = json.load(jsonfile)
    fil
51/18:
 # Dependencies
import json
import os
import pandas as pd

# Load JSON
csv = "/Users/Jerry/Documents/Resources/video_api_response.json"
loaded_json = pd.read_json(csv)
#with open(filepath) as jsonfile:
 #   json_data = json.load(jsonfile)
loaded_json
51/19:
# Dependencies
import json
import os

# Load JSON
filepath = os.path.join("..", "Resources", "video_api_response.json")
with open(filepath) as jsonfile:
    json_data = json.load(jsonfile)
51/20:
# Dependencies
import json
import os

# Load JSON
filepath = os.path.join("..", "Resources", "video_api_response.json")
with open(filepath) as jsonfile:
    json_data = json.load(jsonfile)
51/21:
# Dependencies
import json
import os

# Load JSON
filepath = os.path.join("..", "Resources", "video_api_response.json")
with open(filepath) as jsonfile:
    json_data = json.load(jsonfile)
51/22:
 # Dependencies
import json
import requests 
from pprint import pprint
51/23:
 # Specify the URL
url = "https://2u-data-curriculum-team.s3.amazonaws.com/dataviz-classroom/v1.1/06-Python-APIs/request_review.json"
response = requests.get(url).json()
51/24:
 # Specify the URL
url = "https://2u-data-curriculum-team.s3.amazonaws.com/dataviz-classroom/v1.1/06-Python-APIs/request_review.json"
response = requests.get(url).json()
print(json.dumps(response, indent = 4, sort_keys=True))
51/25:
#Print the JSON representations of the first and last posts.
response
51/26:
#Print the JSON representations of the first and last posts.
type(response)
51/27:
#Print the JSON representations of the first and last posts.
len(response)
51/28:
#Print the JSON representations of the first and last posts.
response[0]
51/29: len(response)
51/30: response[999]
51/31:
 # Specify the URL
url = "https://2u-data-curriculum-team.s3.amazonaws.com/dataviz-classroom/v1.1/06-Python-APIs/request_review.json"
response = requests.get(url).json()
print(json.dumps(response, indent = 4, sort_keys=false))
51/32:
 # Specify the URL
url = "https://2u-data-curriculum-team.s3.amazonaws.com/dataviz-classroom/v1.1/06-Python-APIs/request_review.json"
response = requests.get(url).json()
print(json.dumps(response, indent = 4, sort_keys=False))
51/33:
 # Specify the URL
url = "https://2u-data-curriculum-team.s3.amazonaws.com/dataviz-classroom/v1.1/06-Python-APIs/request_review.json"
response = requests.get(url).json()
print(json.dumps(response, indent = 4, sort_keys=True))
51/34:
 # Specify the URL
url = "https://2u-data-curriculum-team.s3.amazonaws.com/dataviz-classroom/v1.1/06-Python-APIs/request_review.json"
response = requests.get(url).json()

# JSON-ify response
print(json.dumps(response, indent = 4, sort_keys=True))
51/35:
 # Specify the URL
url = "https://2u-data-curriculum-team.s3.amazonaws.com/dataviz-classroom/v1.1/06-Python-APIs/request_review.json"
response = requests.get(url).json()

# JSON-ify response
print(json.dumps(response, indent = 4, sort_keys=False))
51/36: url2 = "https://openweathermap.org/api"
51/37:
#Save all of your "config" information—i.e., your API key; the base URL; etc.—before moving on.
from config.py import api_key
51/38:
#Save all of your "config" information—i.e., your API key; the base URL; etc.—before moving on.
from config import api_key
51/39:
#Save all of your "config" information—i.e., your API key; the base URL; etc.—before moving on.
from config import api_key
api_key
51/40:
#Build your query URL.
base_url = "https://openweathermap.org/data/2.5/weather?"
city = "london"
query_url = base_url + "q=" + city + "&appid=" + api_key
51/41: query_url
51/42:
#Build your query URL.
base_url = "https://openweathermap.org/data/2.5/weather?"
city = "Bujumbura"
query_url = base_url + "q=" + city + "&appid=" + api_key
51/43: response = requests.get(query_url).json()
51/44:
response = requests.get(query_url)
weather_json = response.json()
51/45: print(weather_json)
51/46: query_url
51/47:
#Build your query URL.
base_url = "https://openweathermap.org/data/2.5/weather?"
city = "Bujumbura"
query_url = base_url + "appid=" + api_key + "&q=" + city
51/48: query_url
51/49:
#Make your request, and save the API response.
response = requests.get(query_url)
#Retrieve the current temperature in Bujumbura from the JSON response.
weather_json = response.json()
51/50: print(f"{weather_json}")
51/51: print(f"{weather_json}")
51/52: api_key
51/53: api_key2 = "3761b7072db9ad7469e5eedcb1b70b7a"
51/54:
#Build your query URL.
base_url = "https://openweathermap.org/data/2.5/weather?"
city = "Bujumbura"
query_url = base_url + "appid=" + api_key2 + "&q=" + city
51/55: query_url
51/56:
#Make your request, and save the API response.
response = requests.get(query_url)
#Retrieve the current temperature in Bujumbura from the JSON response.
weather_json = response.json()
51/57: print(f"{weather_json}")
51/58: query_url
51/59:
#Build your query URL.
base_url = "http://api.openweathermap.org/data/2.5/weather?"
city = "Bujumbura"
query_url = base_url + "appid=" + api_key2 + "&q=" + city
51/60: query_url
51/61:
#Save all of your "config" information—i.e., your API key; the base URL; etc.—before moving on.
from config import api_key
api_key
51/62:
#Build your query URL.
base_url = "http://api.openweathermap.org/data/2.5/weather?"
city = "Bujumbura"
query_url = base_url + "appid=" + api_key + "&q=" + city
51/63: query_url
51/64:
#Make your request, and save the API response.
response = requests.get(query_url)
#Retrieve the current temperature in Bujumbura from the JSON response.
weather_json = response.json()
51/65: print(f"{weather_json}")
51/66: print(json.dumps(weather_json, indent = 4, sort_keys=False)
51/67: print(json.dumps(weather_json, indent = 4, sort_keys=False))
51/68: type(weather_json)
51/69: len(weather_json)
51/70: weather["weather"]
51/71: weather_json["weather"]
51/72: weather_json["main"]
52/1: #json to dataframe
52/2:
#json to dataframe
#make json into a list then into a dataframe using pandas
52/3:
import matplotlib.pyplot as plt
import pandas as pd
import requests
from config import api_key
52/4:
#create list of movies
list = {"avengers", "thor", "iron man"}
#for list in list
52/5:
#create list of movies
list = {"avengers", "thor", "iron man"}
#for list in list
type(list)
52/6:
#create list of movies
list = ("avengers", "thor", "iron man")
#for list in list
type(list)
52/7:
#create list of movies
list = []"avengers", "thor", "iron man"]
#for list in list
type(list)
52/8:
#create list of movies
list = ["avengers", "thor", "iron man"]
#for list in list
type(list)
52/9: query_url = base + "Grey's Anatomy"
52/10:
base = "/search/shows?q="
query_url = base + "Grey's Anatomy"
52/11:
base = "/search/shows?q="
query_url = base + "Grey's Anatomy"
query_url
52/12:
base = "/search/shows?q="
movie= "Altered Carbon"
query_url = base + movie
query_url
52/13:
base = "/search/shows?q="
movie= "Altered Carbon"
query_url = base + movie
query_url
52/14:
base = "https://api.tvmaze.com/search/shows?q="
movie= "Altered Carbon"
query_url = base + movie
query_url
52/15:
#create list of movies
#list of tv show titles to query
tv_shows = ["Altered Carbon", "Grey's Anatomy", "This is Us", "The Flash", "Vikings", "Shameless", "Arrow", "Peaky Blinders", "Dirk Gently"]

#obtain the base url
base = "https://api.tvmaze.com/search/shows?q="

#set up lists to hold information later
name = []
rating = []

for shows in tv_shows:
    #for each movie create a query url
    query_url = base + shows
    
    #request information from endpoint
    response = request.get(query_url)
    
    #make response into json
    movie_json = response.json()
    
    #add name and rating from each movie into the lists above
    name.append(movie_json[0]["show"]["name"])
    rating.append(movie_json)[0]["show"]["rating"]["average"])
52/16:
#create list of movies
#list of tv show titles to query
tv_shows = ["Altered Carbon", "Grey's Anatomy", "This is Us", "The Flash", "Vikings", "Shameless", "Arrow", "Peaky Blinders", "Dirk Gently"]

#obtain the base url
base = "https://api.tvmaze.com/search/shows?q="

#set up lists to hold information later
name = []
rating = []

for shows in tv_shows:
    #for each movie create a query url
    query_url = base + shows
    
    #request information from endpoint
    response = request.get(query_url)
    
    #make response into json
    movie_json = response.json()
    
    #add name and rating from each movie into the lists above
    name.append(movie_json[0]["show"]["name"])
    rating.append(movie_json[0]["show"]["rating"]["average"])
52/17:
import matplotlib.pyplot as plt
import pandas as pd
import requests
from config import api_key
52/18:
#create list of movies
#list of tv show titles to query
tv_shows = ["Altered Carbon", "Grey's Anatomy", "This is Us", "The Flash", "Vikings", "Shameless", "Arrow", "Peaky Blinders", "Dirk Gently"]

#obtain the base url
base = "https://api.tvmaze.com/search/shows?q="

#set up lists to hold information later
name = []
rating = []

for shows in tv_shows:
    #for each movie create a query url
    query_url = base + shows
    
    #request information from endpoint
    response = request.get(query_url)
    
    #make response into json
    movie_json = response.json()
    
    #add name and rating from each movie into the lists above
    name.append(movie_json[0]["show"]["name"])
    rating.append(movie_json[0]["show"]["rating"]["average"])
52/19:
#create list of movies
#list of tv show titles to query
tv_shows = ["Altered Carbon", "Grey's Anatomy", "This is Us", "The Flash", "Vikings", "Shameless", "Arrow", "Peaky Blinders", "Dirk Gently"]

#obtain the base url
base = "https://api.tvmaze.com/search/shows?q="

#set up lists to hold information later
name = []
rating = []

for shows in tv_shows:
    #for each movie create a query url
    query_url = base + shows
    
    #request information from endpoint
    response = requests.get(query_url)
    
    #make response into json
    movie_json = response.json()
    
    #add name and rating from each movie into the lists above
    name.append(movie_json[0]["show"]["name"])
    rating.append(movie_json[0]["show"]["rating"]["average"])
52/20:
#create a dataframe using the a dictionary
#first create a dictionary with column names and lists corresponding to column name
d = {"show_name": name, "show_rating": rating}
52/21:
#create a dataframe using the a dictionary
#first create a dictionary with column names and lists corresponding to column name
d = {"show_name": name, "show_rating": rating}
tv_df = pd.DataFrame(d)
52/22:
#create a dataframe using the a dictionary
#first create a dictionary with column names and lists corresponding to column name
d = {"show_name": name, "show_rating": rating}
tv_df = pd.DataFrame(d)
tv_df
52/23: #Use Pandas to create a bar chart comparing the ratings of each show.
52/24:
#Use Pandas to create a bar chart comparing the ratings of each show.
plt.plot(show_name, show_rating)
52/25:
#Use Pandas to create a bar chart comparing the ratings of each show.
x_axis = arange(1,8, 1)
plt.plot()
52/26:
#Use Pandas to create a bar chart comparing the ratings of each show.
x_axis = arange(1,8, 1)
plt.plot(x_axis, tv_df)
52/27:
#Use Pandas to create a bar chart comparing the ratings of each show.
#x_axis = arange(1,8, 1)
#plt.plot(x_axis, tv_df)

tv_df.plot("Tv_shows", "Rating", kind = "bar", figsize = "10,5", rot = 45)
52/28:
#Use Pandas to create a bar chart comparing the ratings of each show.
#x_axis = arange(1,8, 1)
#plt.plot(x_axis, tv_df)

tv_df.plot("Title", "Rating", kind = "bar", figsize = "10,5", rot = 45)
52/29:
#create a dataframe using the a dictionary
#first create a dictionary with column names and lists corresponding to column name
d = {"show_name": name, "show_rating": rating}
tv_df = pd.DataFrame(d)
tv_df
52/30:
#Use Pandas to create a bar chart comparing the ratings of each show.
#x_axis = arange(1,8, 1)
#plt.plot(x_axis, tv_df)

tv_df.plot('Title', "Rating", kind = "bar", figsize = "10,5", rot = 45)
52/31:
import matplotlib.pyplot as plt
import pandas as pd
import requests
import json
import numpy as np
from config import api_key
52/32:
#create list of movies
#list of tv show titles to query
tv_shows = ["Altered Carbon", "Grey's Anatomy", "This is Us", "The Flash", "Vikings", "Shameless", "Arrow", "Peaky Blinders", "Dirk Gently"]

#obtain the base url
base = "https://api.tvmaze.com/search/shows?q="

#set up lists to hold information later
name = []
rating = []

for shows in tv_shows:
    #for each movie create a query url
    query_url = base + shows
    
    #request information from endpoint
    response = requests.get(query_url)
    
    #make response into json
    movie_json = response.json()
    
    #add name and rating from each movie into the lists above
    name.append(movie_json[0]["show"]["name"])
    rating.append(movie_json[0]["show"]["rating"]["average"])
52/33:
#create a dataframe using the a dictionary
#first create a dictionary with column names and lists corresponding to column name
d = {"show_name": name, "show_rating": rating}
tv_df = pd.DataFrame(d)
tv_df
52/34:
#Use Pandas to create a bar chart comparing the ratings of each show.
#x_axis = arange(1,8, 1)
#plt.plot(x_axis, tv_df)

tv_df.plot('Title', "Rating", kind = "bar", figsize = "10,5", rot = 45)
52/35:
#Use Pandas to create a bar chart comparing the ratings of each show.
#x_axis = arange(1,8, 1)
#plt.plot(x_axis, tv_df)

tv_df.plot('Title', "Rating", kind = "bar", figsize = "10,5", rot = 45)
52/36:
#Use Pandas to create a bar chart comparing the ratings of each show.
#x_axis = arange(1,8, 1)
#plt.plot(x_axis, tv_df)

tv_df.plot()
#'Title', "Rating", kind = "bar", figsize = "10,5", rot = 45
52/37:
#Use Pandas to create a bar chart comparing the ratings of each show.
#x_axis = arange(1,8, 1)
#plt.plot(x_axis, tv_df)

tv_df.plot(kind = "bar")
#'Title', "Rating", kind = "bar", figsize = "10,5", rot = 45
52/38:
#Use Pandas to create a bar chart comparing the ratings of each show.
#x_axis = arange(1,8, 1)
#plt.plot(x_axis, tv_df)

tv_df.plot(kind = "bar", figsize = "10,5")
#'Title', "Rating", kind = "bar", figsize = "10,5", rot = 45
52/39:
#Use Pandas to create a bar chart comparing the ratings of each show.
#x_axis = arange(1,8, 1)
#plt.plot(x_axis, tv_df)

tv_df.plot(kind = "bar", figsize = "10,5")
#'Title', "Rating", kind = "bar", figsize = (10,5), rot = 45
52/40:
#Use Pandas to create a bar chart comparing the ratings of each show.
#x_axis = arange(1,8, 1)
#plt.plot(x_axis, tv_df)

tv_df.plot(kind = "bar", figsize = (10,5)
#'Title', "Rating", kind = "bar", figsize = (10,5), rot = 45
52/41:
#Use Pandas to create a bar chart comparing the ratings of each show.
#x_axis = arange(1,8, 1)
#plt.plot(x_axis, tv_df)

tv_df.plot(kind = "bar", figsize = (10,5))
#'Title', "Rating", kind = "bar", figsize = (10,5), rot = 45
52/42:
#Use Pandas to create a bar chart comparing the ratings of each show.
#x_axis = arange(1,8, 1)
#plt.plot(x_axis, tv_df)

tv_df.plot(kind = "bar", figsize = (10,5), rot = 45)
#'Title', "Rating", kind = "bar", figsize = (10,5), rot = 45
52/43:
#Use Pandas to create a bar chart comparing the ratings of each show.
#x_axis = arange(1,8, 1)
#plt.plot(x_axis, tv_df)

tv_df.plot("show_name" , "show_rating", kind = "bar", figsize = (10,5), rot = 45)
#'Title', "Rating", kind = "bar", figsize = (10,5), rot = 45
48/152:
# Dependencies and Setup
import matplotlib.pyplot as plt
import pandas as pd
import scipy.stats as st
import numpy as np

# Study data files
mouse_metadata_path = "Mouse_metadata.csv"
study_results_path = "Study_results.csv"

# Read the mouse data and the study results
mouse_metadata = pd.read_csv(mouse_metadata_path)
study_results = pd.read_csv(study_results_path)

# Combine the data into a single dataset
combined_df = mouse_metadata.merge(study_results, how='inner', on='Mouse ID')
# Display the data table for preview
combined_df.head()
48/153: mouse_metadata.tail()
48/154:
# Dependencies and Setup
import matplotlib.pyplot as plt
import pandas as pd
import scipy.stats as st
import numpy as np

# Study data files
mouse_metadata_path = "Mouse_metadata.csv"
study_results_path = "Study_results.csv"

# Read the mouse data and the study results
mouse_metadata = pd.read_csv(mouse_metadata_path)
study_results = pd.read_csv(study_results_path)

# Combine the data into a single dataset
combined_df = mouse_metadata.merge(study_results, how='inner', on='Mouse ID')
# Display the data table for preview
combined_df.head()
48/155:
# Checking the number of mice.
#unique mice IDs
a = len(combined_df["Mouse ID"].unique())
a
#checking the amount of times a mice ID shows up.
#combined_df["Mouse ID"].value_counts()
48/156:
d = combined_df[["Mouse ID", "Timepoint"]].value_counts()
d
48/157:
# Create a clean DataFrame by dropping the duplicate mouse by its ID.
clean_df = combined_df.loc[(combined_df["Mouse ID"] != "g989"), :]
clean_df
48/158:
# Checking the number of mice in the clean DataFrame.
len(clean_df["Mouse ID"].unique())
48/159:
# Using the aggregation method, produce the same summary statistics in a single line
summary_arg = clean_df.groupby(["Drug Regimen"])[["Tumor Volume (mm3)"]].agg(['mean', 'median', 'var', 'std', 'sem'])
summary_arg
48/160:
#Generate Summary Statistics
practice = clean_df.groupby("Drug Regimen")("Tumor Volume (mm3)")
48/161:
#Generate Summary Statistics
practice = clean_df.groupby("Drug Regimen")("Tumor Volume (mm3)").mean()
48/162:
#Generate Summary Statistics
practice = (clean_df.groupby("Drug Regimen"))("Tumor Volume (mm3)").mean()
48/163:
# Using the aggregation method, produce the same summary statistics in a single line
summary_arg = clean_df.groupby("Drug Regimen")[["Tumor Volume (mm3)"]].agg(['mean', 'median', 'var', 'std', 'sem'])
summary_arg
48/164:
# Using the aggregation method, produce the same summary statistics in a single line
summary_arg = clean_df.groupby(["Drug Regimen"])[["Tumor Volume (mm3)"]].agg(['mean', 'median', 'var', 'std', 'sem'])
summary_arg
48/165:
# Using the aggregation method, produce the same summary statistics in a single line
summary_arg = clean_df.groupby("Drug Regimen")["Tumor Volume (mm3)"].agg(['mean', 'median', 'var', 'std', 'sem'])
summary_arg
48/166:
# Using the aggregation method, produce the same summary statistics in a single line
summary_arg = clean_df.groupby("Drug Regimen")["Tumor Volume (mm3)"].agg('mean', 'median', 'var', 'std', 'sem')
summary_arg
48/167:
# Using the aggregation method, produce the same summary statistics in a single line
summary_arg = clean_df.groupby("Drug Regimen")["Tumor Volume (mm3)"].agg(['mean', 'median', 'var', 'std', 'sem'])
summary_arg
48/168:
# Using the aggregation method, produce the same summary statistics in a single line
summary_arg = clean_df.groupby("Drug Regimen")("Tumor Volume (mm3)").agg(['mean', 'median', 'var', 'std', 'sem'])
summary_arg
48/169:
# Using the aggregation method, produce the same summary statistics in a single line
summary_arg = clean_df.groupby("Drug Regimen")["Tumor Volume (mm3)"].agg(['mean', 'median', 'var', 'std', 'sem'])
summary_arg
48/170: clean_df.groupby(["Drug Regimen"]).count()
48/171:
#Bar and Pie Charts
# Generate a bar plot showing the total number of timepoints for all mice tested for each drug
#regimen using Pandas.

drug_regimen = pd.DataFrame(clean_df.groupby(["Drug Regimen"]).count()).reset_index()

#filter the neccessary columns
drug_filtered = drug_regimen[["Drug Regimen", "Timepoint"]]

drug_filtered = drug_filtered.set_index("Drug Regimen")
drug_filtered.plot(kind = "bar", legend = False, rot =50)
48/172:
#Bar and Pie Charts
# Generate a bar plot showing the total number of timepoints for all mice tested for each drug
#regimen using Pandas.

drug_regimen = pd.DataFrame(clean_df.groupby(["Drug Regimen"]).count()).reset_index()

#filter the neccessary columns
drug_filtered = drug_regimen[["Drug Regimen", "Timepoint"]]

drug_filtered = drug_filtered.set_index("Drug Regimen")
drug_filtered.plot("Drug Regimen", "Timepoint", kind = "bar", legend = False, rot =50)
48/173:
#Bar and Pie Charts
# Generate a bar plot showing the total number of timepoints for all mice tested for each drug
#regimen using Pandas.

drug_regimen = pd.DataFrame(clean_df.groupby(["Drug Regimen"]).count()).reset_index()

#filter the neccessary columns
drug_filtered = drug_regimen[["Drug Regimen", "Timepoint"]]

drug_filtered = drug_filtered.set_index("Drug Regimen")
drug_filtered.plot(kind = "bar", legend = False, rot =50)
48/174:
#Bar and Pie Charts
# Generate a bar plot showing the total number of timepoints for all mice tested for each drug
#regimen using Pandas.

drug_regimen = pd.DataFrame(clean_df.groupby(["Drug Regimen"]).count()).reset_index()

#filter the neccessary columns
drug_filtered = drug_regimen[["Drug Regimen", "Timepoint"]]

drug_filtered = drug_filtered.set_index("Drug Regimen")
drug_filtered.plot(title = "Total Timepoints by Drug Regimen", kind = "bar", legend = False, rot =50)
48/175: clean_df["Drug Regimen"].unique()
48/176:
#Create the array of the number of mice that each drug have
num_mice = (clean_df.groupby(["Drug Regimen"])["Timepoint"].count()).tolist()
48/177:
#Create the array of the number of mice that each drug have
num_mice = (clean_df.groupby(["Drug Regimen"])["Timepoint"].count())
#.tolist()
48/178: num_mice
48/179:
#Create the array of the number of mice that each drug have
num_mice = (clean_df.groupby(["Drug Regimen"])["Timepoint"].count()).tolist()
48/180: num_mice
48/181:
#Generate a bar plot showing the total number of timepoints for all mice tested for each drug
#regimen using pyplot.
x_axis = np.arange(len(drug_filtered))
plt.bar(x_axis, num_mice, color="r", alpha = 0.6, align = "center")

#Create tick locations assigned to the name for x_axis
tick_locations = [value for value in x_axis]
plt.xticks(tick_locations, ["Capomulin", "Ceftamin", "Infubinol", "Ketapril", "Naftisol", "Placebo", "Propriva", "Ramicane", "Stelasyn", "Zoniferol"], rotation = 45)
#plt.xticks(rotation = 45)

#create descriptive labels
plt.title("Total Number of timepoints by each drug regimen")
plt.ylabel("Count of timepoints")
plt.xlabel("Drugs")
48/182:
#Generate two pie plots. Both plots should be identical and show the distribution of 
#female or male mice in the study.

#Create the first pie plot by using both Pandas's DataFrame.plot().
gender_pie = clean_df["Sex"].value_counts()
gender_pie.plot.pie(autopct = "%1.1f%%")
plt.show()
48/183:
#Generate two pie plots. Both plots should be identical and show the distribution of 
#female or male mice in the study.

#Create the first pie plot by using both Pandas's DataFrame.plot().
gender_pie = clean_df["Sex"].value_counts()
#gender_pie.plot.pie(autopct = "%1.1f%%")
#plt.show()
48/184: gender_pie
48/185:
#Generate two pie plots. Both plots should be identical and show the distribution of 
#female or male mice in the study.

#Create the first pie plot by using both Pandas's DataFrame.plot().
gender_pie = clean_df["Sex"].value_counts()
gender_pie.plot.pie(autopct = "%1.1f%%")
plt.show()
48/186:
#Generate two pie plots. Both plots should be identical and show the distribution of 
#female or male mice in the study.

#Create the first pie plot by using both Pandas's DataFrame.plot().
gender_pie = clean_df["Sex"].value_counts()
gender_pie.plot.pie(autopct = "%1.1f%%", figsize = (5,5))
plt.show()
48/187:
#Generate two pie plots. Both plots should be identical and show the distribution of 
#female or male mice in the study.

#Create the first pie plot by using both Pandas's DataFrame.plot().
gender_pie = clean_df["Sex"].value_counts()
gender_pie.plot.pie(autopct = "%1.1f%%", figsize = (5,5), color = "red")
plt.show()
48/188:
#Generate two pie plots. Both plots should be identical and show the distribution of 
#female or male mice in the study.
colors = ["Pink", "Blue"]
#Create the first pie plot by using both Pandas's DataFrame.plot().
gender_pie = clean_df["Sex"].value_counts()
gender_pie.plot.pie(autopct = "%1.1f%%", figsize = (5,5), colors = colors)
plt.show()
48/189:
#Generate two pie plots. Both plots should be identical and show the distribution of 
#female or male mice in the study.
colors = ["Blue", "Pink"]
#Create the first pie plot by using both Pandas's DataFrame.plot().
gender_pie = clean_df["Sex"].value_counts()
gender_pie.plot.pie(autopct = "%1.1f%%", figsize = (5,5), colors = colors)
plt.show()
48/190:
#Create the second pie plot by using Matplotlib's pyplot methods.

#create variables for attributes in plt.pie function
colors = ["blue", "pink"]
explode = 0.01, 0
labels = ["male", "female"]
plt.pie(gender_pie, explode = explode, labels = labels, colors = colors, autopct = "%1.1f%%", figsize = (5,5))
plt.title("Pyplot: The distribution of male and female mice")
plt.ylabel("Sex")
48/191:
#Create the second pie plot by using Matplotlib's pyplot methods.

#create variables for attributes in plt.pie function
colors = ["blue", "pink"]
explode = 0.01, 0
labels = ["male", "female"]
plt.pie(gender_pie, explode = explode, labels = labels, colors = colors, autopct = "%1.1f%%")
plt.title("Pyplot: The distribution of male and female mice")
plt.ylabel("Sex")
48/192:
#Generate two pie plots. Both plots should be identical and show the distribution of 
#female or male mice in the study.
colors = ["Blue", "Pink"]
#Create the first pie plot by using both Pandas's DataFrame.plot().
gender_pie = clean_df["Sex"].value_counts()
gender_pie.plot.pie(title = "Gender distribution of Mice", autopct = "%1.1f%%", figsize = (5,5), colors = colors)
plt.show()
48/193:
#Create the second pie plot by using Matplotlib's pyplot methods.

#create variables for attributes in plt.pie function
colors = ["blue", "pink"]
explode = 0.01, 0
labels = ["male", "female"]
plt.pie(gender_pie, explode = explode, labels = labels, colors = colors, autopct = "%1.1f%%")
plt.title("Pyplot: Gender distribution of mice")
plt.ylabel("Sex")
48/194:
#Create the second pie plot by using Matplotlib's pyplot methods.

#create variables for attributes in plt.pie function
colors = ["blue", "pink"]
explode = 0.01, 0
labels = ["male", "female"]
plt.pie(gender_pie, explode = explode, labels = labels, colors = colors, autopct = "%1.1f%%")
plt.title("Pyplot: Gender distribution of mice")
plt.ylabel("Sex")
plt.figure(figsize = (5,5))
48/195:
#Create the second pie plot by using Matplotlib's pyplot methods.

#create variables for attributes in plt.pie function
colors = ["blue", "pink"]
explode = 0.01, 0
labels = ["male", "female"]
plt.pie(gender_pie, explode = explode, labels = labels, colors = colors, autopct = "%1.1f%%")
plt.title("Pyplot: Gender distribution of mice")
plt.ylabel("Sex")
plt.figure(figsize = (6,6))
48/196:
#Create the second pie plot by using Matplotlib's pyplot methods.

#create variables for attributes in plt.pie function
colors = ["blue", "pink"]
explode = 0.01, 0
labels = ["male", "female"]
plt.pie(gender_pie, explode = explode, labels = labels, colors = colors, autopct = "%1.1f%%")
plt.title("Pyplot: Gender distribution of mice")
plt.ylabel("Sex")
plt.figure(figsize = (2,2))
48/197:
#Create the second pie plot by using Matplotlib's pyplot methods.

#create variables for attributes in plt.pie function
colors = ["blue", "pink"]
explode = 0.01, 0
labels = ["male", "female"]
plt.pie(gender_pie, explode = explode, labels = labels, colors = colors, autopct = "%1.1f%%")
plt.title("Pyplot: Gender distribution of mice")
plt.ylabel("Sex")
plt.figure(figsize = (10,10))
48/198:
#Generate two pie plots. Both plots should be identical and show the distribution of 
#female or male mice in the study.
colors = ["Blue", "Pink"]
#Create the first pie plot by using both Pandas's DataFrame.plot().
gender_pie = clean_df["Sex"].value_counts()
gender_pie.plot.pie(title = "Gender distribution of Mice", autopct = "%1.1f%%", figsize = (2.5,2.5), colors = colors)
plt.show()
48/199:
#Generate two pie plots. Both plots should be identical and show the distribution of 
#female or male mice in the study.
colors = ["Blue", "Pink"]
#Create the first pie plot by using both Pandas's DataFrame.plot().
gender_pie = clean_df["Sex"].value_counts()
gender_pie.plot.pie(title = "Gender distribution of Mice", autopct = "%1.1f%%", figsize = (3.5,3.5), colors = colors)
plt.show()
48/200:
#Generate two pie plots. Both plots should be identical and show the distribution of 
#female or male mice in the study.
colors = ["Blue", "Pink"]
#Create the first pie plot by using both Pandas's DataFrame.plot().
gender_pie = clean_df["Sex"].value_counts()
gender_pie.plot.pie(title = "Gender distribution of Mice", autopct = "%1.1f%%", figsize = (4.5,4.5), colors = colors)
plt.show()
48/201: #Quartiles, Outliers and Boxplots
48/202:
# Calculate the final tumor volume of each mouse across four of the treatment regimens:  
# Capomulin, Ramicane, Infubinol, and Ceftamin
48/203: clean_df
48/204:
# Calculate the final tumor volume of each mouse across four of the treatment regimens:  
# Capomulin, Ramicane, Infubinol, and Ceftamin
clean_df.loc[(clean_df["Drug Regimen"] == "Capomulin") |
             (clean_df["Drug Regimen"] == "Ramicane") |
             (clean_df["Drug Regimen"] == "Infubinol") |
             (clean_df["Drug Regimen"] == "Ceftamin"), :]
48/205:
# Calculate the final tumor volume of each mouse across four of the treatment regimens:  
# Capomulin, Ramicane, Infubinol, and Ceftamin
four_drugs = clean_df.loc[(clean_df["Drug Regimen"] == "Capomulin") |
             (clean_df["Drug Regimen"] == "Ramicane") |
             (clean_df["Drug Regimen"] == "Infubinol") |
             (clean_df["Drug Regimen"] == "Ceftamin"), :]
48/206: four_drugs
48/207: four_drugs["Mouse_ID"].max("Timepoint")
48/208: four_drugs.max("Timepoint")
48/209: four_drugs["Timepoint"].max()
48/210: four_drugs.groupby("Mouse ID")["Tumor Volume (mm3"].max()
48/211: four_drugs.groupby("Mouse ID")["Tumor Volume (mm3)"].max()
48/212: four_drugs.groupby("Mouse ID")["Timepoint"].max()
48/213:
four_drugs.groupby("Mouse ID")
#["Timepoint"].max()
48/214:
c = four_drugs.groupby("Mouse ID")
#["Timepoint"].max()
c
48/215: four_drugs.groupby("Mouse ID")["Timepoint"].max()
48/216:
# Start by getting the last (greatest) timepoint for each mouse
max_time = four_drugs.groupby("Mouse ID")["Timepoint"].max()

#new_df =
48/217: (max_time)
48/218:
# Start by getting the last (greatest) timepoint for each mouse
max_time = four_drugs.groupby("Mouse ID")["Timepoint"].max()

new_df = pd.merge(four_drugs, max_time, right_index = True, left_index = True)
48/219: new_df
48/220: max_time
48/221:
# Start by getting the last (greatest) timepoint for each mouse
max_time = four_drugs.groupby("Mouse ID")["Timepoint"].max()

new_df = pd.merge(max_time, four_drugs, right_index = True, left_index = True)
48/222: new_df
48/223:
# Start by getting the last (greatest) timepoint for each mouse
max_time = four_drugs.groupby(("Mouse ID")["Timepoint"].max()).reset_index

new_df = pd.merge(max_time, four_drugs, right_index = True, left_index = True)
48/224:
# Start by getting the last (greatest) timepoint for each mouse
max_time = four_drugs.groupby(("Mouse ID")["Timepoint"].max()).reset_index

#new_df = pd.merge(max_time, four_drugs, right_index = True, left_index = True)
48/225:
# Start by getting the last (greatest) timepoint for each mouse
max_time = four_drugs.groupby("Mouse ID")["Timepoint"].max()

#new_df = pd.merge(max_time, four_drugs, right_index = True, left_index = True)
48/226: max_time
48/227:
# Start by getting the last (greatest) timepoint for each mouse
max_time = four_drugs.groupby("Mouse ID")["Timepoint"].max()

four_drugs = pd.merge(four_drugs, max_time, right_index = True, left_index = True)
48/228: four_drugs
48/229:
# Calculate the final tumor volume of each mouse across four of the treatment regimens:  
# Capomulin, Ramicane, Infubinol, and Ceftamin
four_drugs = clean_df.loc[(clean_df["Drug Regimen"] == "Capomulin") |
             (clean_df["Drug Regimen"] == "Ramicane") |
             (clean_df["Drug Regimen"] == "Infubinol") |
             (clean_df["Drug Regimen"] == "Ceftamin"), :]
48/230: four_drugs
48/231:
# Start by getting the last (greatest) timepoint for each mouse
max_time = four_drugs.groupby("Mouse ID")["Timepoint"].max()

four_drugs = pd.merge(four_drugs, max_time, right_index = True, left_index = True)
48/232: four_drugs
48/233: type(max_time)
48/234:
# Start by getting the last (greatest) timepoint for each mouse
max_time = four_drugs.groupby("Mouse ID")["Timepoint"].max()

four_drugs = pd.merge(four_drugs, max_time, left_index = True)
48/235:
# Start by getting the last (greatest) timepoint for each mouse
max_time = four_drugs.groupby("Mouse ID")["Timepoint"].max()

four_drugs = pd.merge(four_drugs, max_time, right_index = True, left_index = True)
48/236:
# Start by getting the last (greatest) timepoint for each mouse
max_time = four_drugs.groupby("Mouse ID")["Timepoint"].max()

df2 = four_drugs.merge(max_time, left_index = True, right_index = True)
48/237: max_time(name = "Timepoint")
48/238: pd.concat([four_drugs, max_time], axis = 1)
48/239:
# Calculate the final tumor volume of each mouse across four of the treatment regimens:  
# Capomulin, Ramicane, Infubinol, and Ceftamin
four_drugs = clean_df.loc[(clean_df["Drug Regimen"] == "Capomulin") |
             (clean_df["Drug Regimen"] == "Ramicane") |
             (clean_df["Drug Regimen"] == "Infubinol") |
             (clean_df["Drug Regimen"] == "Ceftamin"), :]
48/240:
# Start by getting the last (greatest) timepoint for each mouse
max_time = four_drugs.groupby("Mouse ID")["Timepoint"].max()

#df2 = four_drugs.merge(max_time, left_index = True, right_index = True)
48/241: four_drugs
48/242: pd.concat([four_drugs, max_time], axis = 1)
48/243: max_time
48/244: max_time.reset_index()
48/245: df3 = max_time.reset_index()
48/246:
df3 = max_time.reset_index()
df3 = df3.rename(columns={"Timepoint": "Timepoint2"})
48/247:
df3 = max_time.reset_index()
df3 = df3.rename(columns={"Timepoint": "Timepoint2"})
df3
48/248: df3 = four_drugs.merge(df2, left_index = True, right_index = True)
48/249:
df2 = max_time.reset_index()
df2 = df2.rename(columns={"Timepoint": "Timepoint2"})
df2
48/250: df3 = four_drugs.merge(df2, left_index = True, right_index = True)
48/251:
df3 = four_drugs.merge(df2, left_index = True, right_index = True)
df3
48/252:
# Calculate the final tumor volume of each mouse across four of the treatment regimens:  
# Capomulin, Ramicane, Infubinol, and Ceftamin
four_drugs = clean_df.loc[(clean_df["Drug Regimen"] == "Capomulin") |
             (clean_df["Drug Regimen"] == "Ramicane") |
             (clean_df["Drug Regimen"] == "Infubinol") |
             (clean_df["Drug Regimen"] == "Ceftamin"), :]
48/253: four_drugs
48/254:
# Start by getting the last (greatest) timepoint for each mouse
max_time = four_drugs.groupby("Mouse ID")["Timepoint"].max()
48/255:
df2 = max_time.reset_index()
df2 = df2.rename(columns={"Timepoint": "Timepoint2"})
df2
48/256:
df3 = pd.merge(four_drugs, df2, left_index = True, right_index = True)
df3
48/257:
df3 = pd.merge(four_drugs, df2, how = "left", on={"Mouse ID"})
df3
48/258:
df3 = pd.merge(four_drugs, df2, how = "left", on=["Mouse ID"])
df3
48/259: df3["Timepoint2"].unique()
48/260:
# Start by getting the last (greatest) timepoint for each mouse
max_time = four_drugs.groupby("Mouse ID")["Timepoint"].max()

df2 = max_time.reset_index()
df2 = df2.rename(columns={"Timepoint": "Timepoint2"})
#df2

df3 = pd.merge(four_drugs, df2, how = "left", on=["Mouse ID"])
df3
48/261:
# Start by getting the last (greatest) timepoint for each mouse
max_time = four_drugs.groupby("Mouse ID")["Timepoint"].max()

#create a df for max_time in order to merge it with 
df2 = max_time.reset_index()
df2 = df2.rename(columns={"Timepoint": "Timepoint2"})
#df2

df3 = pd.merge(four_drugs, df2, how = "inner", on=["Mouse ID"])
df3
48/262:
df3["Drug Regimen"].unique()
treatments = []
48/263: df3["Drug Regimen"].unique()
48/264: final_df = df3.loc(df3["Timepoint"] == df3["Timepoint2"], :)
48/265: final_df = df3.loc(df3["Timepoint"] == df3["Timepoint2"], :]
48/266: final_df = df3.loc(df3["Timepoint"] == df3["Timepoint2"], :]
48/267: final_df = df3.loc(df3["Timepoint"] == df3["Timepoint2"]), :]
48/268: final_df = df3.loc[(df3["Timepoint"] == df3["Timepoint2"]), :]
48/269:
final_df = df3.loc[(df3["Timepoint"] == df3["Timepoint2"]), :]
final_df
48/270:
final_df = df3.loc[(df3["Timepoint"] == df3["Timepoint2"]), :]
final_df["Timepoint"]
48/271:
final_df = df3.loc[(df3["Timepoint"] == df3["Timepoint2"]), :]
final_df["Timepoint"].unique()
48/272:
final_df = df3.loc[(df3["Timepoint"] == df3["Timepoint2"]), :]
final_df["Timepoint"].value_counts()
48/273: final_df = df3.loc[(df3["Timepoint"] == df3["Timepoint2"]), :]
48/274:
final_df = df3.loc[(df3["Timepoint"] == df3["Timepoint2"]), :]
final_df
48/275:
a = final_df.loc[(final_df["Drug Regimen"] == 'Ramicane'), final_df["Tumor Volume (mm3)"]]
a
48/276:
a = final_df.loc[final_df["Drug Regimen"] == 'Ramicane', ["Tumor Volume (mm3)"]]
a
48/277:
a = final_df.loc[final_df["Drug Regimen"] == 'Ramicane']
a
48/278:
# Put treatments into a list for for loop (and later for plot labels)
treatments = ['Ramicane', 'Capomulin', 'Infubinol', 'Ceftamin']

# Create empty list to fill with tumor vol data (for plotting)
Ramicane_data = []
_data = []
_data = []

for x in treatments:
    tumor_data = final_df.loc[final_df["Drug Regimen"] == x, ["Tumor Volume (mm3)"]]
    
    tumor_df.append(tumor_data)
# Calculate the IQR and quantitatively determine if there are any potential outliers.
48/279:
a = final_df.loc[final_df["Drug Regimen"] == 'Ramicane', ["Tumor Volume (mm3)"]]
a
48/280:
a = final_df.loc[final_df["Drug Regimen"] == 'Ramicane', ["Tumor Volume (mm3)"]]
type(a)
48/281:
# Put treatments into a list for for loop (and later for plot labels)
treatments = ['Ramicane', 'Capomulin', 'Infubinol', 'Ceftamin']

# Create empty list to fill with tumor vol data (for plotting)
tumor_df = []


for x in treatments:
    tumor_data = final_df.loc[final_df["Drug Regimen"] == x, ["Tumor Volume (mm3)"]]
    
    tumor_df.append(tumor_data)
# Calculate the IQR and quantitatively determine if there are any potential outliers.
48/282: tumor_df
48/283:
# Put treatments into a list for for loop (and later for plot labels)
treatments = ['Ramicane', 'Capomulin', 'Infubinol', 'Ceftamin']

# Create empty list to fill with tumor vol data (for plotting)
Ramicane = []
Capomulin = []
Infubinol = []
Ceftamin = []
for x in treatments:
    tumor_data = final_df.loc[final_df["Drug Regimen"] == x, ["Tumor Volume (mm3)"]]
    
    x_df.append(tumor_data)
# Calculate the IQR and quantitatively determine if there are any potential outliers.
48/284:
# Put treatments into a list for for loop (and later for plot labels)
treatments = ['Ramicane', 'Capomulin', 'Infubinol', 'Ceftamin']

# Create empty list to fill with tumor vol data (for plotting)
tumor_df = []
for x in treatments:
    tumor_data = final_df.loc[final_df["Drug Regimen"] == x, ["Tumor Volume (mm3)"]]
    
    tumor_df.append(tumor_data)
# Calculate the IQR and quantitatively determine if there are any potential outliers.
48/285: tumor_df
48/286:
# Put treatments into a list for for loop (and later for plot labels)
treatments = ['Ramicane', 'Capomulin', 'Infubinol', 'Ceftamin']

# Create empty list to fill with tumor vol data (for plotting)
tumor_df = []
for x in treatments:
    tumor_data = final_df.loc[final_df["Drug Regimen"] == x, :]
    
    tumor_df.append(tumor_data)
# Calculate the IQR and quantitatively determine if there are any potential outliers.
48/287:
# Put treatments into a list for for loop (and later for plot labels)
treatments = ['Ramicane', 'Capomulin', 'Infubinol', 'Ceftamin']

# Create empty list to fill with tumor vol data (for plotting)
tumor_df = []
for x in treatments:
    tumor_data = final_df.loc[final_df["Drug Regimen"] == x, ["Tumor Volume (mm3)"]]
    tumor_df.append(tumor_data)
# Calculate the IQR and quantitatively determine if there are any potential outliers.
48/288: tumor_df
48/289: tumor_df.reset_index()
48/290: tumor_df
48/291: fig1, ax1 = plt.subplots()
48/292:
fig1, ax1 = plt.subplots()
ax1.boxplots()
48/293:
fig1, ax1 = plt.subplots()
ax1.set_title = "Tumor volume By Drug Regimen"
ax1.set_ylabel = "Tumor volume (mm3)"
ax1.boxplot()
48/294: type(tumor_df)
48/295:
# Put treatments into a list for for loop (and later for plot labels)
treatments = ['Ramicane', 'Capomulin', 'Infubinol', 'Ceftamin']

# Create empty list to fill with tumor vol data (for plotting)
tumor_list = []
for x in treatments:
    tumor_data = final_df.loc[final_df["Drug Regimen"] == x, ["Tumor Volume (mm3)"]]
    tumor_list.append(tumor_data)
# Calculate the IQR and quantitatively determine if there are any potential outliers.
48/296: type(tumor_list)
48/297:
fig1, ax1 = plt.subplots()
ax1.set_title = "Tumor volume By Drug Regimen"
ax1.set_ylabel = "Tumor volume (mm3)"
ax1.boxplot(tumor_list)
48/298: tumor_list
48/299: len(tumor_list)
48/300: a = tumor_list[0]
48/301:
a = tumor_list[0]
a
48/302:
a = tumor_list[0]
type(a)
48/303:
a = tumor_list[0]
a.tolist()
48/304:
a = tumor_list[0]
a
48/305:
fig1, ax1 = plt.subplots()
ax1.set_title = "Tumor volume By Drug Regimen"
ax1.set_ylabel = "Tumor volume (mm3)"
ax1.boxplot(a)
48/306:
a = tumor_list[0]
a.sort()
48/307:
a = tumor_list[0]
a.sort_values(by="Tumor Volume (mm3)", ascending=False)
48/308:
a = tumor_list[0]
a.sort_values(by="Tumor Volume (mm3)", ascending=True)
48/309:
fig1, ax1 = plt.subplots()
ax1.set_title = "Tumor volume By Drug Regimen"
ax1.set_ylabel = "Tumor volume (mm3)"
ax1.boxplot(a)
48/310:
fig1, ax1 = plt.subplots()
ax1.set_title = "Tumor volume By Drug Regimen"
ax1.set_ylabel = "Tumor volume (mm3)"
ax1.boxplot(a)
plt.show()
48/311:
fig1, ax1 = plt.subplots()
ax1.set_title = ("Tumor volume By Drug Regimen")
ax1.set_ylabel = ("Tumor volume (mm3)")
ax1.boxplot(a)
plt.show()
48/312:
# Dependencies and Setup
import matplotlib.pyplot as plt
import pandas as pd
import scipy.stats as st
import numpy as np

# Study data files
mouse_metadata_path = "Mouse_metadata.csv"
study_results_path = "Study_results.csv"

# Read the mouse data and the study results
mouse_metadata = pd.read_csv(mouse_metadata_path)
study_results = pd.read_csv(study_results_path)

# Combine the data into a single dataset
combined_df = mouse_metadata.merge(study_results, how='inner', on='Mouse ID')
# Display the data table for preview
combined_df.head()
48/313:
fig1, ax1 = plt.subplots()
ax1.set_title = ("Tumor volume By Drug Regimen")
ax1.set_ylabel = ("Tumor volume (mm3)")
ax1.boxplot(a)
plt.show()
48/314:
fig1, ax1 = plt.subplots()
ax1.set_title("Tumor volume By Drug Regimen")
ax1.set_ylabel("Tumor volume (mm3)")
ax1.boxplot(a)
plt.show()
48/315:
# Put treatments into a list for for loop (and later for plot labels)
treatments = ['Ramicane', 'Capomulin', 'Infubinol', 'Ceftamin']

# Create empty list to fill with tumor vol data (for plotting)
tumor_list = []
for x in treatments:
    tumor_data = final_df.loc[final_df["Drug Regimen"] == x], ["Tumor Volume (mm3)"]]
    tumor_list.append(tumor_data)
# Calculate the IQR and quantitatively determine if there are any potential outliers.
48/316:
# Put treatments into a list for for loop (and later for plot labels)
treatments = ['Ramicane', 'Capomulin', 'Infubinol', 'Ceftamin']

# Create empty list to fill with tumor vol data (for plotting)
tumor_list = []
for x in treatments:
    tumor_data = final_df.loc[final_df["Drug Regimen"] == x, ["Tumor Volume (mm3)"]]
    tumor_list.append(tumor_data)
# Calculate the IQR and quantitatively determine if there are any potential outliers.
48/317: tumor_list
48/318:
# Put treatments into a list for for loop (and later for plot labels)
treatments = ['Ramicane', 'Capomulin', 'Infubinol', 'Ceftamin']

# Create empty list to fill with tumor vol data (for plotting)
tumor_list = []
for x in treatments:
    #tumor_data = final_df.loc[final_df["Drug Regimen"] == x, ["Tumor Volume (mm3)"]]
    tumor_data = final_df.loc[final_df["Drug Regimen"] == x, :]
    tumor_list.append(tumor_data)
# Calculate the IQR and quantitatively determine if there are any potential outliers.
48/319: tumor_list
48/320: tumor_list = tumor_list[["Drug Regimen", "Tumor Volume (mm3)"]]
48/321:
# Put treatments into a list for for loop (and later for plot labels)
treatments = ['Ramicane', 'Capomulin', 'Infubinol', 'Ceftamin']

# Create empty list to fill with tumor vol data (for plotting)
tumor_list = []
for x in treatments:
    tumor_data = final_df.loc[final_df["Drug Regimen"] == x, ["Tumor Volume (mm3)"]]
    #tumor_data = final_df.loc[final_df["Drug Regimen"] == x, :]
    tumor_list.append(tumor_data)
# Calculate the IQR and quantitatively determine if there are any potential outliers.
48/322: type(tumor_list)
48/323: len(tumor_list)
48/324: tumor_list
48/325: tumor_list.head()
48/326: tumor_list
48/327:
mice_frequency = combined_df[["Mouse ID", "Timepoint"]].value_counts()
mice_frequency
48/328:
# Checking the number of mice.
#unique mice IDs
Num_mice = len(combined_df["Mouse ID"].unique())
Num_mice
#checking the amount of times a mice ID shows up.
#combined_df["Mouse ID"].value_counts()
48/329:
a = tumor_list[0]
b = tumor_list[1]
c = tumor_list[2]
d = tumor_list[3]
a.sort_values(by="Tumor Volume (mm3)", ascending=True)
48/330:
prac_dict = {'Ramicane': a}
prac_df = pd.DataFrame(data = prac_dict)
48/331:
prac_dict = {'Ramicane': a}
prac_df = pd.DataFrame(data = prac_dict, index=default)
48/332:
prac_dict = {'Ramicane': a}
prac_df = pd.DataFrame(data = prac_dict, index=Rangeindex)
48/333: type(c)
48/334: type(tumor_list)
48/335: tumor_list
48/336: tumor_list
48/337:
# Put treatments into a list for for loop (and later for plot labels)
treatments = ['Ramicane', 'Capomulin', 'Infubinol', 'Ceftamin']

# Create empty list to fill with tumor vol data (for plotting)
tumor_list = []

for x in treatments:
    #tumor_data = final_df.loc[final_df["Drug Regimen"] == x, ["Tumor Volume (mm3)"]]
    tumor_data = final_df.loc[final_df["Drug Regimen"] == x, :]
    tumor_list.append(tumor_data["Tumor Volume (mm3)"])
# Calculate the IQR and quantitatively determine if there are any potential outliers.
48/338: tumor_list
48/339:
# Put treatments into a list for for loop (and later for plot labels)
treatments = ['Ramicane', 'Capomulin', 'Infubinol', 'Ceftamin']

# Create empty list to fill with tumor vol data (for plotting)
tumor_list = []

for x in treatments:
    tumor_data = final_df.loc[final_df["Drug Regimen"] == x, ["Tumor Volume (mm3)"]]
    #tumor_data = final_df.loc[final_df["Drug Regimen"] == x, :]
    
    tumor_list.append(tumor_data)
    #tumor_list.append(tumor_data["Tumor Volume (mm3)"])
# Calculate the IQR and quantitatively determine if there are any potential outliers.
48/340: tumor_list
54/1:
# Dependencies and Setup
import matplotlib.pyplot as plt
import pandas as pd
import scipy.stats as st
import numpy as np

# Study data files
mouse_metadata_path = "Mouse_metadata.csv"
study_results_path = "Study_results.csv"

# Read the mouse data and the study results
mouse_metadata = pd.read_csv(mouse_metadata_path)
study_results = pd.read_csv(study_results_path)

# Combine the data into a single dataset
combined_df = mouse_metadata.merge(study_results, how='inner', on='Mouse ID')
# Display the data table for preview
combined_df.head()
54/2:
# Checking the number of mice.
#unique mice IDs
Num_mice = len(combined_df["Mouse ID"].unique())
Num_mice
#checking the amount of times a mice ID shows up.
#combined_df["Mouse ID"].value_counts()
54/3:
mice_frequency = combined_df[["Mouse ID", "Timepoint"]].value_counts()
mice_frequency
54/4:
#Get all the data for the duplicate mouse ID. 
duplicated_df = combined_df.loc[(combined_df["Mouse ID"] == "g989"), :]
#duplicated_df
54/5:
# Create a clean DataFrame by dropping the duplicate mouse by its ID.
clean_df = combined_df.loc[(combined_df["Mouse ID"] != "g989"), :]
clean_df
54/6:
# Checking the number of mice in the clean DataFrame.
len(clean_df["Mouse ID"].unique())
54/7:
# Generate a summary statistics table of mean, median, variance, standard deviation, 
#and SEM of the tumor volume for each regimen

# Use groupby and summary statistical methods to calculate the following properties of each drug regimen: 
# mean, median, variance, standard deviation, and SEM of the tumor volume. 
# Assemble the resulting series into a single summary dataframe.
summary_group = clean_df.groupby("Drug Regimen")

mean_summary = summary_group["Tumor Volume (mm3)"].mean()
median_summary = summary_group["Tumor Volume (mm3)"].median()
variance_summary = summary_group["Tumor Volume (mm3)"].var()
std_summary = summary_group["Tumor Volume (mm3)"].std()
sem_summary = summary_group["Tumor Volume (mm3)"].sem()


summary_df = pd.DataFrame({"mean tumor volume": mean_summary,
                           "median tumor volume": median_summary,
                           "varinace tumor volume": variance_summary,
                           "tumor volume std": std_summary,
                           "tumor volume sem": sem_summary})
54/8:
# Using the aggregation method, produce the same summary statistics in a single line
summary_arg = clean_df.groupby("Drug Regimen")["Tumor Volume (mm3)"].agg(['mean', 'median', 'var', 'std', 'sem'])
summary_arg
54/9:
#Bar and Pie Charts
# Generate a bar plot showing the total number of timepoints for all mice tested for each drug
#regimen using Pandas.

drug_regimen = pd.DataFrame(clean_df.groupby(["Drug Regimen"]).count()).reset_index()

#filter the neccessary columns
drug_filtered = drug_regimen[["Drug Regimen", "Timepoint"]]

drug_filtered = drug_filtered.set_index("Drug Regimen")
drug_filtered.plot(title = "Total Timepoints by Drug Regimen", kind = "bar", legend = False, rot =50)
54/10: clean_df["Drug Regimen"].unique()
54/11:
#Create the array of the number of mice that each drug have
num_mice = (clean_df.groupby(["Drug Regimen"])["Timepoint"].count()).tolist()
54/12:
#Generate a bar plot showing the total number of timepoints for all mice tested for each drug
#regimen using pyplot.
x_axis = np.arange(len(drug_filtered))
plt.bar(x_axis, num_mice, color="r", alpha = 0.6, align = "center")

#Create tick locations assigned to the name for x_axis
tick_locations = [value for value in x_axis]
plt.xticks(tick_locations, ["Capomulin", "Ceftamin", "Infubinol", "Ketapril", "Naftisol", "Placebo", "Propriva", "Ramicane", "Stelasyn", "Zoniferol"], rotation = 45)
#plt.xticks(rotation = 45)

#create descriptive labels
plt.title("Total Number of timepoints by each drug regimen")
plt.ylabel("Count of timepoints")
plt.xlabel("Drugs")
54/13:
#Generate two pie plots. Both plots should be identical and show the distribution of 
#female or male mice in the study.
colors = ["Blue", "Pink"]
#Create the first pie plot by using both Pandas's DataFrame.plot().
gender_pie = clean_df["Sex"].value_counts()
gender_pie.plot.pie(title = "Gender distribution of Mice", autopct = "%1.1f%%", figsize = (4.5,4.5), colors = colors)
plt.show()
54/14:
#Create the second pie plot by using Matplotlib's pyplot methods.

#create variables for attributes in plt.pie function
colors = ["blue", "pink"]
explode = 0.01, 0
labels = ["male", "female"]
plt.pie(gender_pie, explode = explode, labels = labels, colors = colors, autopct = "%1.1f%%")
plt.title("Pyplot: Gender distribution of mice")
plt.ylabel("Sex")
plt.figure(figsize = (10,10))
54/15:
# Calculate the final tumor volume of each mouse across four of the treatment regimens:  
# Capomulin, Ramicane, Infubinol, and Ceftamin
four_drugs = clean_df.loc[(clean_df["Drug Regimen"] == "Capomulin") |
             (clean_df["Drug Regimen"] == "Ramicane") |
             (clean_df["Drug Regimen"] == "Infubinol") |
             (clean_df["Drug Regimen"] == "Ceftamin"), :]
54/16: four_drugs
54/17:
# Start by getting the last (greatest) timepoint for each mouse
max_time = four_drugs.groupby("Mouse ID")["Timepoint"].max()

#create a df for max_time in order to merge it with four_drugs_df
#rename Timepoint to Timepoint2, indicating the max timepoint for each mouse
df2 = max_time.reset_index()
df2 = df2.rename(columns={"Timepoint": "Timepoint2"})
#df2

#merger df2 with four drug df
df3 = pd.merge(four_drugs, df2, how = "inner", on=["Mouse ID"])
df3
54/18:
#Create a new df with only rows that match both timepoints
#new df should only have max timepoints now
final_df = df3.loc[(df3["Timepoint"] == df3["Timepoint2"]), :]
final_df
54/19:
# Put treatments into a list for for loop (and later for plot labels)
treatments = ['Ramicane', 'Capomulin', 'Infubinol', 'Ceftamin']

# Create empty list to fill with tumor vol data (for plotting)
tumor_list = []

for x in treatments:
    tumor_data = final_df.loc[final_df["Drug Regimen"] == x, ["Tumor Volume (mm3)"]]
    
    #add subset
    tumor_list.append(tumor_data)
    
# Calculate the IQR and quantitatively determine if there are any potential outliers. 

quartiles = tumor_data.quantile([.25,.5,.75])
lowerq = quartiles[0.25]
upperq = quartiles[0.75]
iqr = upperq-lowerq

#Now calculate bounds
lower_bound = lowerq - (1.5*iqr)
upper_bound = upperq - (1.5*iqr)
outliers = tumor_data.loc[(tumor_data < lower_bound) | (tumor_data > upper_bound)]
54/20:
# Put treatments into a list for for loop (and later for plot labels)
treatments = ['Ramicane', 'Capomulin', 'Infubinol', 'Ceftamin']

# Create empty list to fill with tumor vol data (for plotting)
tumor_list = []

for x in treatments:
    tumor_data = final_df.loc[final_df["Drug Regimen"] == x, ["Tumor Volume (mm3)"]]
    
    #add subset
    tumor_list.append(tumor_data)
    
# Calculate the IQR and quantitatively determine if there are any potential outliers. 

quartiles = tumor_data.quantile([.25,.5,.75])
#lowerq = quartiles[0.25]
#upperq = quartiles[0.75]
#iqr = upperq-lowerq

#Now calculate bounds
#lower_bound = lowerq - (1.5*iqr)
#upper_bound = upperq - (1.5*iqr)
#outliers = tumor_data.loc[(tumor_data < lower_bound) | (tumor_data > upper_bound)]
54/21:
# Put treatments into a list for for loop (and later for plot labels)
treatments = ['Ramicane', 'Capomulin', 'Infubinol', 'Ceftamin']

# Create empty list to fill with tumor vol data (for plotting)
tumor_list = []

for x in treatments:
    tumor_data = final_df.loc[final_df["Drug Regimen"] == x, ["Tumor Volume (mm3)"]]
    
    #add subset
    tumor_list.append(tumor_data)
    
# Calculate the IQR and quantitatively determine if there are any potential outliers. 

quartiles = tumor_data.quantile([.25,.5,.75])
lowerq = quartiles[0.25]
#upperq = quartiles[0.75]
#iqr = upperq-lowerq

#Now calculate bounds
#lower_bound = lowerq - (1.5*iqr)
#upper_bound = upperq - (1.5*iqr)
#outliers = tumor_data.loc[(tumor_data < lower_bound) | (tumor_data > upper_bound)]
54/22:
# Put treatments into a list for for loop (and later for plot labels)
treatments = ['Ramicane', 'Capomulin', 'Infubinol', 'Ceftamin']

# Create empty list to fill with tumor vol data (for plotting)
tumor_list = []

for x in treatments:
    tumor_data = final_df.loc[final_df["Drug Regimen"] == x, ["Tumor Volume (mm3)"]]
    
    #add subset
    tumor_list.append(tumor_data)
    
# Calculate the IQR and quantitatively determine if there are any potential outliers. 

quartiles = tumor_data.quantile([.25,.5,.75])
#lowerq = quartiles[0.25]
#upperq = quartiles[0.75]
#iqr = upperq-lowerq

#Now calculate bounds
#lower_bound = lowerq - (1.5*iqr)
#upper_bound = upperq - (1.5*iqr)
#outliers = tumor_data.loc[(tumor_data < lower_bound) | (tumor_data > upper_bound)]
54/23:
# Put treatments into a list for for loop (and later for plot labels)
treatments = ['Ramicane', 'Capomulin', 'Infubinol', 'Ceftamin']

# Create empty list to fill with tumor vol data (for plotting)
tumor_list = []

for x in treatments:
    tumor_data = final_df.loc[final_df["Drug Regimen"] == x, ["Tumor Volume (mm3)"]]
    
    #add subset
    tumor_list.append(tumor_data)
    
# Calculate the IQR and quantitatively determine if there are any potential outliers. 

quartiles = tumor_data.quantile([.25,.5,.75])
lowerq = quartiles[0.25]
#upperq = quartiles[0.75]
#iqr = upperq-lowerq

#Now calculate bounds
#lower_bound = lowerq - (1.5*iqr)
#upper_bound = upperq - (1.5*iqr)
#outliers = tumor_data.loc[(tumor_data < lower_bound) | (tumor_data > upper_bound)]
54/24:
# Start by getting the last (greatest) timepoint for each mouse
max_time = four_drugs.groupby("Mouse ID")["Timepoint"].max()

#create a df for max_time in order to merge it with four_drugs_df
max_time = max_time.reset_index()


#merger max_time with four drug df
df3 = max_time.merge(four_drugs, on=["Mouse ID", "Timepoint"], how = "left")
df3
54/25:
# Put treatments into a list for for loop (and later for plot labels)
treatments = ['Ramicane', 'Capomulin', 'Infubinol', 'Ceftamin']

# Create empty list to fill with tumor vol data (for plotting)
tumor_list = []

for x in treatments:
    tumor_data = final_df.loc[final_df["Drug Regimen"] == x, ["Tumor Volume (mm3)"]]
    
    #add subset
    tumor_list.append(tumor_data)
    
# Calculate the IQR and quantitatively determine if there are any potential outliers. 

quartiles = tumor_data.quantile([.25,.5,.75])
lowerq = quartiles[0.25]
#upperq = quartiles[0.75]
#iqr = upperq-lowerq

#Now calculate bounds
#lower_bound = lowerq - (1.5*iqr)
#upper_bound = upperq - (1.5*iqr)
#outliers = tumor_data.loc[(tumor_data < lower_bound) | (tumor_data > upper_bound)]
54/26:
# Put treatments into a list for for loop (and later for plot labels)
treatments = ['Ramicane', 'Capomulin', 'Infubinol', 'Ceftamin']

# Create empty list to fill with tumor vol data (for plotting)
tumor_list = []

for x in treatments:
    tumor_data = df3.loc[df3["Drug Regimen"] == x, ["Tumor Volume (mm3)"]]
    
    #add subset
    tumor_list.append(tumor_data)
    
# Calculate the IQR and quantitatively determine if there are any potential outliers. 

quartiles = tumor_data.quantile([.25,.5,.75])
lowerq = quartiles[0.25]
#upperq = quartiles[0.75]
#iqr = upperq-lowerq

#Now calculate bounds
#lower_bound = lowerq - (1.5*iqr)
#upper_bound = upperq - (1.5*iqr)
#outliers = tumor_data.loc[(tumor_data < lower_bound) | (tumor_data > upper_bound)]
54/27:
# Put treatments into a list for for loop (and later for plot labels)
treatments = ['Ramicane', 'Capomulin', 'Infubinol', 'Ceftamin']

# Create empty list to fill with tumor vol data (for plotting)
tumor_list = []

for x in treatments:
    tumor_data = df3.loc[df3["Drug Regimen"] == x, ["Tumor Volume (mm3)"]]
    
    #add subset
    tumor_list.append(tumor_data)
    
# Calculate the IQR and quantitatively determine if there are any potential outliers. 

quartiles = tumor_data.quantile([.25,.5,.75])
lowerq = quartiles[.25]
#upperq = quartiles[0.75]
#iqr = upperq-lowerq

#Now calculate bounds
#lower_bound = lowerq - (1.5*iqr)
#upper_bound = upperq - (1.5*iqr)
#outliers = tumor_data.loc[(tumor_data < lower_bound) | (tumor_data > upper_bound)]
54/28:
# Dependencies and Setup
import matplotlib.pyplot as plt
import pandas as pd
import scipy.stats as st
import numpy as np

# Study data files
mouse_metadata_path = "Mouse_metadata.csv"
study_results_path = "Study_results.csv"

# Read the mouse data and the study results
mouse_metadata = pd.read_csv(mouse_metadata_path)
study_results = pd.read_csv(study_results_path)

# Combine the data into a single dataset
combined_df = mouse_metadata.merge(study_results, how='inner', on='Mouse ID')
# Display the data table for preview
combined_df.head()
54/29:
# Put treatments into a list for for loop (and later for plot labels)
treatments = ['Ramicane', 'Capomulin', 'Infubinol', 'Ceftamin']

# Create empty list to fill with tumor vol data (for plotting)
tumor_list = []

for x in treatments:
    tumor_data = df3.loc[df3["Drug Regimen"] == x, ["Tumor Volume (mm3)"]]
    
    #add subset
    tumor_list.append(tumor_data)
    
# Calculate the IQR and quantitatively determine if there are any potential outliers. 

quartiles = tumor_data.quantile([.25,.5,.75])
#lowerq = quartiles[.25]
upperq = quartiles[0.75]
#iqr = upperq-lowerq

#Now calculate bounds
#lower_bound = lowerq - (1.5*iqr)
#upper_bound = upperq - (1.5*iqr)
#outliers = tumor_data.loc[(tumor_data < lower_bound) | (tumor_data > upper_bound)]
54/30:
# Put treatments into a list for for loop (and later for plot labels)
treatments = ['Ramicane', 'Capomulin', 'Infubinol', 'Ceftamin']

# Create empty list to fill with tumor vol data (for plotting)
tumor_list = []

for x in treatments:
    tumor_data = df3.loc[df3["Drug Regimen"] == x, ["Tumor Volume (mm3)"]]
    
    #add subset
    tumor_list.append(tumor_data)
    
# Calculate the IQR and quantitatively determine if there are any potential outliers. 

quartiles = tumor_data.quantile([.25,.5,.75])
lowerq = quartiles[0.25]
upperq = quartiles[0.75]
#iqr = upperq-lowerq

#Now calculate bounds
#lower_bound = lowerq - (1.5*iqr)
#upper_bound = upperq - (1.5*iqr)
#outliers = tumor_data.loc[(tumor_data < lower_bound) | (tumor_data > upper_bound)]
54/31:
# Put treatments into a list for for loop (and later for plot labels)
treatments = ['Ramicane', 'Capomulin', 'Infubinol', 'Ceftamin']

# Create empty list to fill with tumor vol data (for plotting)
tumor_list = []

for x in treatments:
    tumor_data = df3.loc[df3["Drug Regimen"] == x, ["Tumor Volume (mm3)"]]
    
    #add subset
    tumor_list.append(tumor_data)
    
# Calculate the IQR and quantitatively determine if there are any potential outliers. 

    quartiles = tumor_data.quantile([.25,.5,.75])
    lowerq = quartiles[0.25]
    upperq = quartiles[0.75]
#iqr = upperq-lowerq

#Now calculate bounds
#lower_bound = lowerq - (1.5*iqr)
#upper_bound = upperq - (1.5*iqr)
#outliers = tumor_data.loc[(tumor_data < lower_bound) | (tumor_data > upper_bound)]
54/32:
# Put treatments into a list for for loop (and later for plot labels)
treatments = ['Ramicane', 'Capomulin', 'Infubinol', 'Ceftamin']

# Create empty list to fill with tumor vol data (for plotting)
tumor_list = []

for x in treatments:
    tumor_data = df3.loc[df3["Drug Regimen"] == x, "Tumor Volume (mm3)"]
    
    #add subset
    tumor_list.append(tumor_data)
    
    #Calculate the IQR and quantitatively determine if there are any potential outliers. 

    quartiles = tumor_data.quantile([.25,.5,.75])
    lowerq = quartiles[0.25]
    upperq = quartiles[0.75]
    #iqr = upperq-lowerq

#Now calculate bounds
#lower_bound = lowerq - (1.5*iqr)
#upper_bound = upperq - (1.5*iqr)
#outliers = tumor_data.loc[(tumor_data < lower_bound) | (tumor_data > upper_bound)]
54/33:
# Put treatments into a list for for loop (and later for plot labels)
treatments = ['Ramicane', 'Capomulin', 'Infubinol', 'Ceftamin']

# Create empty list to fill with tumor vol data (for plotting)
tumor_list = []

for x in treatments:
    tumor_data = df3.loc[df3["Drug Regimen"] == x, "Tumor Volume (mm3)"]
    
    #add subset
    tumor_list.append(tumor_data)
    
    #Calculate the IQR and quantitatively determine if there are any potential outliers. 

    quartiles = tumor_data.quantile([.25,.5,.75])
    lowerq = quartiles[0.25]
    upperq = quartiles[0.75]
    iqr = upperq-lowerq

    #Now calculate bounds
    lower_bound = lowerq - (1.5*iqr)
    upper_bound = upperq - (1.5*iqr)
    outliers = tumor_data.loc[(tumor_data < lower_bound) | (tumor_data > upper_bound)]
54/34:
# Put treatments into a list for for loop (and later for plot labels)
treatments = ['Ramicane', 'Capomulin', 'Infubinol', 'Ceftamin']

# Create empty list to fill with tumor vol data (for plotting)
tumor_list = []

for x in treatments:
    tumor_data = df3.loc[df3["Drug Regimen"] == x, "Tumor Volume (mm3)"]
    
    #add subset
    tumor_list.append(tumor_data)
    
    #Calculate the IQR and quantitatively determine if there are any potential outliers. 

    quartiles = tumor_data.quantile([.25,.5,.75])
    lowerq = quartiles[0.25]
    upperq = quartiles[0.75]
    iqr = upperq-lowerq

    #Now calculate bounds
    lower_bound = lowerq - (1.5*iqr)
    upper_bound = upperq - (1.5*iqr)
    outliers = tumor_data.loc[(tumor_data < lower_bound) | (tumor_data > upper_bound)]
    
    #Determine outliers by using the upper and lower bounds, and then print the results.
    print(f"{x}'s potential outliers: {outliers}")
54/35:
# Generate a box plot of the final tumor volume of each mouse across four regimens of interest
orange_out = dict(markerfacecolor='red',markersize=12)
plt.boxplot(tumor_list, labels = treatment_list,flierprops=orange_out)
plt.ylabel('Final Tumor Volume (mm3)')
plt.show()
54/36:
# Generate a box plot of the final tumor volume of each mouse across four regimens of interest
orange_out = dict(markerfacecolor='red',markersize=12)
plt.boxplot(tumor_list, labels = treatments,flierprops=orange_out)
plt.ylabel('Final Tumor Volume (mm3)')
plt.show()
54/37: # Line and Scatter Plots
54/38:
# Generate a line plot of tumor volume vs. time point for a mouse treated with Capomulin
capomulin_df = clean_df.loc[clean_df["Drug Regimen"] == "Capomulin"]
mousedata = capomulin_df.loc[capomulin_df["Mouse ID"] == "1509"]
54/39:
# Generate a line plot of tumor volume vs. time point for a mouse treated with Capomulin
capomulin_df = clean_df.loc[clean_df["Drug Regimen"] == "Capomulin"]
mouse_df = capomulin_df.loc[capomulin_df["Mouse ID"] == "y793"]
plt.plot(mouse_df["Timepoint"], mousedata["Tumor Volume (mm3)"])
plt.xlabel("Days")
plt.ylabel("Tumor Volume")
plt.title("Capomulin treatment of mouse y793")
plt.show()
54/40:
# Generate a line plot of tumor volume vs. time point for a mouse treated with Capomulin
capomulin_df = clean_df.loc[clean_df["Drug Regimen"] == "Capomulin"]
mouse_df = capomulin_df.loc[capomulin_df["Mouse ID"] == "y793"]

#plt.plot(mouse_df["Timepoint"], mousedata["Tumor Volume (mm3)"])
#plt.xlabel("Days")
#plt.ylabel("Tumor Volume")
#plt.title("Capomulin treatment of mouse y793")
#plt.show()
54/41:
# Generate a line plot of tumor volume vs. time point for a mouse treated with Capomulin
capomulin_df = clean_df.loc[clean_df["Drug Regimen"] == "Capomulin"]
mouse_df = capomulin_df.loc[capomulin_df["Mouse ID"] == "y793"]

plt.plot(mouse_df["Timepoint"], mousedata["Tumor Volume (mm3)"])
#plt.xlabel("Days")
#plt.ylabel("Tumor Volume")
#plt.title("Capomulin treatment of mouse y793")
#plt.show()
54/42:
# Generate a line plot of tumor volume vs. time point for a mouse treated with Capomulin
capomulin_df = clean_df.loc[clean_df["Drug Regimen"] == "Capomulin"]
mouse_df = capomulin_df.loc[capomulin_df["Mouse ID"] == "y793"]

plt.plot(mouse_df["Timepoint"], mouse_df["Tumor Volume (mm3)"])
#plt.xlabel("Days")
#plt.ylabel("Tumor Volume")
#plt.title("Capomulin treatment of mouse y793")
#plt.show()
54/43:
# Generate a line plot of tumor volume vs. time point for a mouse treated with Capomulin
capomulin_df = clean_df.loc[clean_df["Drug Regimen"] == "Capomulin"]
mouse_df = capomulin_df.loc[capomulin_df["Mouse ID"] == "y793"]

plt.plot(mouse_df["Timepoint"], mouse_df["Tumor Volume (mm3)"])
plt.xlabel("Days")
#plt.ylabel("Tumor Volume")
#plt.title("Capomulin treatment of mouse y793")
#plt.show()
54/44:
# Generate a line plot of tumor volume vs. time point for a mouse treated with Capomulin
capomulin_df = clean_df.loc[clean_df["Drug Regimen"] == "Capomulin"]
mouse_df = capomulin_df.loc[capomulin_df["Mouse ID"] == "y793"]

plt.plot(mouse_df["Timepoint"], mouse_df["Tumor Volume (mm3)"])
plt.xlabel("Days")
plt.ylabel("Tumor Volume")
plt.title("Capomulin treatment of mouse y793")
plt.show()
54/45:
# Generate a scatter plot of average tumor volume vs. mouse weight for the Capomulin regimen
capomulin_mean = capomulin_df.groupby (["Mouse ID"]).mean()

plt.scatter(capomulin_mean['Weight (g)'],capomulin_average['Tumor Volume (mm3)'])
plt.xlabel('Weight (g)')
plt.ylabel('Average Tumor Volume (mm3)')
plt.show()
54/46:
# Generate a scatter plot of average tumor volume vs. mouse weight for the Capomulin regimen
capomulin_mean = capomulin_df.groupby (["Mouse ID"]).mean()

plt.scatter(capomulin_mean['Weight (g)'],capomulin_mean['Tumor Volume (mm3)'])
plt.xlabel('Weight (g)')
plt.ylabel('Average Tumor Volume (mm3)')
plt.show()
54/47: #Correlation Regression
54/48:
# Calculate the correlation coefficient and linear regression model for
#mouse weight and average tumor volume for the Capomulin regimen
corr_coefficient = round(st.pearsonr(capomulin_mean['Weight (g)'],capomulin_mean['Tumor Volume (mm3)'])[0],2)
print(f"The correlation between weight and the average tumor volume is {corr_coefficient}")
regression = st.linregress(capomulin_average['Weight (g)'],capomulin_average['Tumor Volume (mm3)'])


y_values = capomulin_mean['Weight (g)']*regression[0]+regression[1]
plt.scatter(capomulin_mean['Weight (g)'],capomulin_mean['Tumor Volume (mm3)'])
plt.plot(capomulin_mean['Weight (g)'],y_values,color="red")
plt.xlabel('Weight (g)')
plt.ylabel('Average Tumor Volume (mm3)')
plt.show()
54/49:
# Calculate the correlation coefficient and linear regression model for
#mouse weight and average tumor volume for the Capomulin regimen
corr_coefficient = round(st.pearsonr(capomulin_mean['Weight (g)'],capomulin_mean['Tumor Volume (mm3)'])[0],2)
print(f"The correlation between weight and the average tumor volume is {corr_coefficient}")
regression = st.linregress(capomulin_mean['Weight (g)'],capomulin_mean['Tumor Volume (mm3)'])


y_values = capomulin_mean['Weight (g)']*regression[0]+regression[1]
plt.scatter(capomulin_mean['Weight (g)'],capomulin_mean['Tumor Volume (mm3)'])
plt.plot(capomulin_mean['Weight (g)'],y_values,color="red")
plt.xlabel('Weight (g)')
plt.ylabel('Average Tumor Volume (mm3)')
plt.show()
54/50:
# Generate a box plot of the final tumor volume of each mouse across four regimens of interest
orange_out = dict(markerfacecolor='red',markersize=12)
plt.boxplot(tumor_list, labels = treatments)
plt.ylabel('Final Tumor Volume (mm3)')
plt.show()
54/51:
# Generate a box plot of the final tumor volume of each mouse across four regimens of interest
orange_out = dict(markerfacecolor='red',markersize=12)
plt.boxplot(tumor_list, labels = treatments, ,flierprops=orange_out)
plt.ylabel('Final Tumor Volume (mm3)')
plt.show()
54/52:
# Generate a box plot of the final tumor volume of each mouse across four regimens of interest
orange_out = dict(markerfacecolor='red',markersize=12)
plt.boxplot(tumor_list, labels = treatments,flierprops=orange_out)
plt.ylabel('Final Tumor Volume (mm3)')
plt.show()
54/53:
# Generate a box plot of the final tumor volume of each mouse across four regimens of interest
outlier = dict(markerfacecolor='red',markersize=12)
plt.boxplot(tumor_list, labels = treatments,flierprops=outlier)
plt.ylabel('Final Tumor Volume (mm3)')
plt.show()
56/1:
#import dependencies
import requests
import json
56/2: url = "https://api.spacexdata.com/v3/missions"
56/3: response = requests.get(url)
56/4: print(response.json())
56/5: print(json.dumps(response, indent = 4, sort_keys= True))
56/6:
#import dependencies
import requests
import json
56/7: url = "https://api.spacexdata.com/v3/missions"
56/8: response = requests.get(url)
56/9: print(json.dumps(response, indent = 4, sort_keys= True))
56/10: url = "https://api.spacexdata.com/v3/launchpads"
56/11: response = requests.get(url)
56/12: print(json.dumps(response, indent = 4, sort_keys= True))
56/13: response = requests.get(url).json()
56/14: print(json.dumps(response, indent = 4, sort_keys= True))
56/15: response = requests.get(url + "/5").json()
56/16: print(json.dumps(response, indent = 4, sort_keys= True))
56/17: response = requests.get(url + "5").json()
56/18: response = requests.get(url + "/5").json()
56/19: response = requests.get(url + "/5").json()
56/20: print(json.dumps(response, indent = 4, sort_keys= True))
56/21: response = requests.get(url + "/5e9e4502f509094188566f88").json()
56/22: print(json.dumps(response, indent = 4, sort_keys= True))
56/23: print(url + "/5e9e4502f509094188566f88")
56/24: response = requests.get(url).json()
56/25: print(json.dumps(response, indent = 4, sort_keys= True))
56/26: print(url + "/6")
56/27: response = requests.get(url + "/6").json()
56/28: print(json.dumps(response, indent = 4, sort_keys= True))
56/29:
#import dependencies
import requests
import json
56/30: url = "https://api.spacexdata.com/v3/launchpads"
56/31: response = requests.get(url + "/6").json()
56/32: print(json.dumps(response, indent = 4, sort_keys= True))
57/1:
#import dependencies
import requests
import json
57/2: url = "https://api.spacexdata.com/v2/rockets/falcon9"
57/3: response = requests.get(url)
57/4: response = requests.get(url).json()
57/5: print(json.dumps(response, indent = 4, sort_keys=True))
57/6: json_dict = print(json.dumps(response, indent = 4, sort_keys=True))
57/7: type(json_dict)
57/8: json_dict = json.dumps(response, indent = 4, sort_keys=True)
57/9: type(json_dict)
57/10: len(json_dict)
57/11: json_dict = print(json.dumps(response, indent = 4, sort_keys=True))
57/12: print(json.dumps(response, indent = 4, sort_keys=True))
57/13: print(response["cost_per_launch"])
57/14:
number_payloads = len(response_json["payload_weights"])
print(f"There are {number_payloads} payloads.")
57/15:
number_payloads = len(response["payload_weights"])
print(f"There are {number_payloads} payloads.")
57/16: payload_weight = response["payload_weights"][0]["kg"]
57/17: payload_weight
59/1:
#import dependencies
import pandas as pd
59/2:
csv_file = "/Users/Jerry/Downloads/US_Accidents_Dec21_updated.csv"
accidents_df = pd.read_csv(csv_file)
59/3: accidents_df.head()
59/4: accidents_df.columns
59/5: accidents_df["State"].head()
59/6:
cal_ari = accidents_df.loc[(accidents_df["State"] == "CA") |
                          accidents_df["State"] == "AZ"), :]
59/7:
cal_ari = accidents_df.loc[(accidents_df["State"] == "CA") |
                          (accidents_df["State"] == "AZ"), :]
59/8: cal_ari.head()
59/9: cal_ari.columns
59/10: cal_ari["ID"].count()
59/11: cal_ari["Start_Time"].head()
59/12: cali_df = accidents_df.loc[(accidents_df["State"] == "CA"), :]
59/13: cal_ari["End_Time"].head()
59/14: cali_df["Severity"].unique()
59/15: cali_df["Severity"]
59/16: type(cal_ari["End_Time"])
59/17: cali_df[["Sunrise_Sunset"]]
59/18: cali_df["Sunrise_Sunset"].unique()
59/19: cali_df.head()
59/20: cali_df[['Traffic_Calming']]
59/21: cali_df[['Airport_Code']]
59/22: cali_df[['Precipitation(in)']]
59/23: cali_df[['Wind_Chill(F)']]
59/24: cali_df[['Amenity']]
59/25: cali_df[['Civil_Twilight']]
59/26:
cali_df[['Civil_Twilight', 'Nautical_Twilight',
       'Astronomical_Twilight']]
59/27: cali_df[["Sunrise_Sunset"]]
59/28: cali_df[["Amenity"]]
59/29: cali_df[["Bump"]]
59/30: cali_df["Bump"].unique()
59/31: cali_df["Crossing"].unique()
59/32: cali_df["Give_Way"].unique()
59/33: cali_df["Junction"].unique()
59/34: cali_df["No_Exit"].unique()
59/35: cali_df["Railway"].unique()
59/36: cali_df["Number"].unique()
59/37:
cleaned_df = cali_df[['ID', 'Severity', 'Start_Time', 'Start_Lat', 'Start_Lng', 'Description',
                      'City', 'County', 'State', 'Zipcode', 'Country', 'Timezone',
                      'Weather_Timestamp', 'Temperature(F)', 'Wind_Chill(F)', 'Humidity(%)',
                      'Pressure(in)', 'Visibility(mi)', 'Wind_Direction', 'Wind_Speed(mph)', 
                      'Precipitation(in)', 'Weather_Condition', 'Crossing', 'Junction', 
                      'No_Exit', 'Station', 'Stop', 'Traffic_Signal', 'Sunrise_Sunset']]
59/38: cleaned_df.head()
62/1:
# Dependencies and Setup
import matplotlib.pyplot as plt
import pandas as pd
import numpy as np
import requests
import time
from scipy.stats import linregress

# Import API key
from api_keys import weather_api_key

# Incorporated citipy to determine city based on latitude and longitude
from citipy import citipy

# Output File (CSV)
output_data_file = "cities.csv"

# Range of latitudes and longitudes
lat_range = (-90, 90)
lng_range = (-180, 180)
62/2:
# Dependencies and Setup
import matplotlib.pyplot as plt
import pandas as pd
import numpy as np
import requests
import time
from scipy.stats import linregress

# Import API key
#from api_keys import weather_api_key

# Incorporated citipy to determine city based on latitude and longitude
from citipy import citipy

# Output File (CSV)
output_data_file = "cities.csv"

# Range of latitudes and longitudes
lat_range = (-90, 90)
lng_range = (-180, 180)
62/3:
# Dependencies and Setup
import matplotlib.pyplot as plt
import pandas as pd
import numpy as np
import requests
import time
from scipy.stats import linregress

# Import API key
#from api_keys import weather_api_key

# Incorporated citipy to determine city based on latitude and longitude
#from citipy import citipy

# Output File (CSV)
output_data_file = "cities.csv"

# Range of latitudes and longitudes
lat_range = (-90, 90)
lng_range = (-180, 180)
62/4:
# Dependencies and Setup
import matplotlib.pyplot as plt
import pandas as pd
import numpy as np
import requests
import time
from scipy.stats import linregress

# Import API key
#from api_keys import weather_api_key

# Incorporated citipy to determine city based on latitude and longitude
from citipy import citipy

# Output File (CSV)
output_data_file = "cities.csv"

# Range of latitudes and longitudes
lat_range = (-90, 90)
lng_range = (-180, 180)
62/5: output_data_file.head()
62/6:
#read the csv file
cities_df = pd.read_csv(output_data_file)
62/7:
#read the csv file
cities_df = pd.read_csv(output_data_file)
cities_df.head()
62/8:
 # List for holding lat_lngs and cities
lat_lngs = []
cities = []

# Create a set of random lat and lng combinations
lats = np.random.uniform(lat_range[0], lat_range[1], size=1500)
lngs = np.random.uniform(lng_range[0], lng_range[1], size=1500)
lat_lngs = zip(lats, lngs)

# Identify nearest city for each lat, lng combination
for lat_lng in lat_lngs:
    city = citipy.nearest_city(lat_lng[0], lat_lng[1]).city_name
    
    # If the city is unique, then add it to a our cities list
    if city not in cities:
        cities.append(city)

# Print the city count to confirm sufficient count
len(cities)
65/1:
#Stranger hieghts
#import dependencies
import pandas as pd
import scipy.stats as stats
65/2:
df = pd.read_csv("/Users/Jerry/Downloads/stranger_heights.csv")
df.head()
65/3: # Calculate the population mean for stranger heights in San Francisco
65/4:  # Calculate the population mean for stranger heights in Denver
65/5:
# Calculate the population mean for stranger heights in San Francisco
df_loc1 = df.loc(df["location"] == 1, ;)
65/6:
# Calculate the population mean for stranger heights in San Francisco
df_loc1 = df.loc(df["location"] == 1, :)
65/7:
# Calculate the population mean for stranger heights in San Francisco
df_loc1 = df.loc(df["location"] == 1)
65/8:
# Calculate the population mean for stranger heights in San Francisco
df_loc1 = df.loc[df["location"] == 1]
65/9:
# Calculate the population mean for stranger heights in San Francisco
df_loc1 = df.loc[df["location"] == 1]
df_loc1["stranger_heights"].mean()
65/10:
 # Calculate the population mean for stranger heights in Denver
df_loc5 = df.loc[df["location"] == 5]
df_loc5["stranger_heights"].mean()
65/11:
# Calculate Independent (Two Sample) t-test
stats.ttest_ind(df_loc1, df_loc5, equal_var = True)
65/12: stats.ttest_ind(df_loc1, df_loc5, equal_var = False)
65/13: stats.ttest_ind(df_loc1, df_loc5, equal_var = False)
66/1: #Number of Workouts Per Week vs. Pain Tolerance ANOVA
66/2:
import warnings
warnings.filterwarnings('ignore')
66/3:
%matplotlib inline
import pandas as pd
import scipy.stats as stats
66/4: df = pd.read_csv("/Users/Jerry/Downloads/pain_tolerance.csv")
66/5: df.head()
66/6: df["num_workouts"].unique()
66/7: df.head()
66/8: df.boxplot("pain_tolerance", by = "num_workouts", figsize=(20,10))
66/9:
zero_df = df[df["num_workouts"] == 0]["pain_tolerance"]
one_df = df[df["num_workouts"] == 1]["pain_tolerance"]
two_df = df[df["num_workouts"] == 2]["pain_tolerance"]
three_df = df[df["num_workouts"] == 3]["pain_tolerance"]
four_df = df[df["num_workouts"] == 4]["pain_tolerance"]

#perform the NOVA
stats.f_oneway(zero_df, one_df, two_df, three_df, four_df)
66/10: zero_df.head()
67/1:
 import numpy as np
import pandas as pd
67/2:
# The statistical module used to run chi square test
import scipy.stats as stats
67/3:
# Observed data in a (hypothetical) survey of 6000 people 
observed = pd.Series([1500, 1350, 1600, 1550], index=["1", "2", "3", "4"])
67/4:
# Create a data frame
df = pd.DataFrame([observed]).T
67/5:
# Add a column whose default values are the expected values
df["expected_values"] = 1500
67/6: df.head()
67/7: df.columns = ["actual_values", "expected_values"]
67/8: df.head()
67/9:
#the degrees of freedom = 4-1 = 3
#with the p-value = .05, the confidence level is 1.00-.05 = .95
# Calculate the critical value
critical_val = stat.chi2.ppf(q = 0.95, df = 3)
67/10:
import numpy as np
import pandas as pd
67/11:
# The statistical module used to run chi square test
import scipy.stats as stats
67/12:
#the degrees of freedom = 4-1 = 3
#with the p-value = .05, the confidence level is 1.00-.05 = .95
# Calculate the critical value
critical_val = stats.chi2.ppf(q = 0.95, df = 3)
67/13:
#the degrees of freedom = 4-1 = 3
#with the p-value = .05, the confidence level is 1.00-.05 = .95
# Calculate the critical value
critical_val = stats.chi2.ppf(q = 0.95, df = 3)
critical_val
67/14:
# Run the chi square test with stats.chisquare()
stats.chissquare(df["actual_values"], df["expected_values"])
67/15:
# Run the chi square test with stats.chisquare()
stats.chisquare(df["actual_values"], df["expected_values"])
68/1:
#Our Main df with only CA data and neccessary columns
cleaned_df.head()
68/2:
#import dependencies
import pandas as pd
68/3:
csv_file = "US_Accidents_Dec21_updated.csv"
accidents_df = pd.read_csv(csv_file)
68/4:
csv_file = "/Users/Jerry/Documents/Homework/Project_1/US_Accidents_Dec21_updated.csv"
accidents_df = pd.read_csv(csv_file)
68/5:
#A data frame with only CA and AZ data
cal_ari = accidents_df.loc[(accidents_df["State"] == "CA") |
                          (accidents_df["State"] == "AZ"), :]
68/6: #cal_ari.columns
68/7:
#Unnecessary Columns
#End_Time, End_Lat, End_Lng, Airport_Code, Side, Nautical_Twilight, 
#Astronomical_Twilight, Civil_Twilight
#Amenity, Number, Street, Bump, Give_Way, Railway, Roundabout, Turning_Loop, Traffic_Calming
68/8:
#Our data frame with only CA data
cali_df = accidents_df.loc[(accidents_df["State"] == "CA"), :]
68/9:
cleaned_df = cali_df[['ID', 'Severity', 'Start_Time', 'Start_Lat', 'Start_Lng', 'Description',
                      'City', 'County', 'State', 'Zipcode', 'Country', 'Timezone',
                      'Weather_Timestamp', 'Temperature(F)', 'Wind_Chill(F)', 'Humidity(%)',
                      'Pressure(in)', 'Visibility(mi)', 'Wind_Direction', 'Wind_Speed(mph)', 
                      'Precipitation(in)', 'Weather_Condition', 'Crossing', 'Junction', 
                      'No_Exit', 'Station', 'Stop', 'Traffic_Signal', 'Sunrise_Sunset']]
68/10:
#Our Main df with only CA data and neccessary columns
cleaned_df.head()
68/11:
#df.to_csv('file_name.csv')
cleaned_df.to_csv("accidents_in_california.csv")
68/12: type(cleaned_df["Start_Time"])
68/13:
#create a new column with just month
cleaned_df[["date", "time"]] = cleaned_df["Start_Time"].str.spilt(" ", expand = True)
68/14:
#import dependencies
import pandas as pd
from datetime import datetime
68/15:
#datetime_object = datetime.strptime('Jun 1 2005  1:33PM', '%b %d %Y %I:%M%p')
#from datetime import datetime
datetime.today().strftime('%m %d')
68/16:
#datetime_object = datetime.strptime('Jun 1 2005  1:33PM', '%b %d %Y %I:%M%p')
#from datetime import datetime
datetime.today().strftime('%m-%d')
68/17: datetime.cleaned_df["Start_Time"].strftime('%m-%d')
68/18:
import datetime

date_time_str = '2018-06-29 08:15:27.243860'
date_month_obj = datetime.datetime.strptime(date_time_str, '%m')

print('Month:', date_time_obj)
68/19:
import datetime

date_time_str = '2018-06-29 08:15:27.243860'
date_month_obj = datetime.datetime.strptime(date_time_str, '%m')

print('Month:', date_month_obj)
68/20:
import datetime

date_time_str = '2018-06-29 08:15:27.243860'
date_month_obj = datetime.datetime.strptime(date_time_str, '%m')

print('Month:', date_month_obj)
68/21:
import datetime

date_time_str = '2018-06-29 08:15:27.243860'
date_month_obj = datetime.strptime(date_time_str, '%m')

print('Month:', date_month_obj)
68/22:
import datetime

date_time_str = '2018-06-29 08:15:27.243860'
date_month_obj = datetime.datetime.strptime(date_time_str, '%m')

print('Month:', date_month_obj)
68/23:
#10 days before late oct early nov
#10 days after late feb early march
cleaned_df[["date", "time"]] = cleaned_df["Start_Time"].str.split(" ", expand = True)
68/24: cleaned_df.head()
68/25: cleaned_df[["year", "month", "day"]] = int(cleaned_df["date"].str.split("-", expand = True))
68/26: cleaned_df[["year", "month", "day"]] = cleaned_df["date"].str.split("-", expand = True)
68/27: cleaned_df[["year", "month", "day"]] = int(cleaned_df["date"].str.split("-", expand = True))
68/28: cleaned_df[["year", "month", "day"]] = cleaned_df["date"].str.split("-", expand = True)
68/29: cleaned_df.head()
68/30: type(day)
68/31: type(cleaned_df["day"])
68/32: cleaned_df[["year", "month", "day"]].astype(int)
68/33: cleaned_df = cleaned_df[["year", "month", "day"]].astype(int)
68/34:
cleaned_df = cleaned_df[["year", "month", "day"]].astype(int)
cleaned_df.head()
68/35: cleaned_df[["year", "month", "day"]] = (cleaned_df["date"].str.split("-", expand = True)).astype(int)
68/36: cleaned_df[["year", "month", "day"]] = cleaned_df["date"].str.split("-", expand = True))
68/37: cleaned_df[["year", "month", "day"]] = cleaned_df["date"].str.split("-", expand = True)
68/38:
#10 days before late oct early nov
#10 days after late feb early march
cleaned_df[["date", "time"]] = cleaned_df["Start_Time"].str.split(" ", expand = True)
68/39:
#import dependencies
import pandas as pd
from datetime import datetime
68/40:
csv_file = "/Users/Jerry/Documents/Homework/Project_1/US_Accidents_Dec21_updated.csv"
accidents_df = pd.read_csv(csv_file)
68/41:
csv_file = "/Users/Jerry/Documents/US_Accidents_Dec21_updated.csv"
accidents_df = pd.read_csv(csv_file)
68/42:
#A data frame with only CA and AZ data
cal_ari = accidents_df.loc[(accidents_df["State"] == "CA") |
                          (accidents_df["State"] == "AZ"), :]
68/43:
#Our data frame with only CA data
cali_df = accidents_df.loc[(accidents_df["State"] == "CA"), :]
68/44:
cleaned_df = cali_df[['ID', 'Severity', 'Start_Time', 'Start_Lat', 'Start_Lng', 'Description',
                      'City', 'County', 'State', 'Zipcode', 'Country', 'Timezone',
                      'Weather_Timestamp', 'Temperature(F)', 'Wind_Chill(F)', 'Humidity(%)',
                      'Pressure(in)', 'Visibility(mi)', 'Wind_Direction', 'Wind_Speed(mph)', 
                      'Precipitation(in)', 'Weather_Condition', 'Crossing', 'Junction', 
                      'No_Exit', 'Station', 'Stop', 'Traffic_Signal', 'Sunrise_Sunset']]
68/45:
#Our Main df with only CA data and neccessary columns
cleaned_df.head()
68/46:
#10 days before late oct early nov
#10 days after late feb early march
cleaned_df[["date", "time"]] = cleaned_df["Start_Time"].str.split(" ", expand = True)
68/47: cleaned_df[["year", "month", "day"]] = cleaned_df["date"].str.split("-", expand = True)
68/48: cleaned_df.head()
68/49:
cleaned_df[["year", "month", "day"]] = cleaned_df[["year", "month", "day"]].astype(int)
cleaned_df.head()
68/50:
cleaned_df.loc[(cleaned_df["month"] == 3) | 
               (cleaned_df["month"] == 10) |
              (cleaned_df["month"] == 11), :]
68/51:
cleaned_df.loc[(cleaned_df["month"] == 2) | 
               (cleaned_df["month"] == 3) |
               (cleaned_df["month"] == 10) |
              (cleaned_df["month"] == 11), :]
68/52: cleaned_df["year"].unique()
68/53:
#df.to_csv('file_name.csv')
cleaned_df.to_csv("accidents_in_california.csv")
68/54:
#df.to_csv('file_name.csv')
final_df.to_csv("accidents_in_california.csv")
68/55:
final_df = cleaned_df.loc[(cleaned_df["month"] == 2) | 
               (cleaned_df["month"] == 3) |
               (cleaned_df["month"] == 10) |
              (cleaned_df["month"] == 11), :]
68/56:
#df.to_csv('file_name.csv')
final_df.to_csv("accidents_in_california.csv")
68/57:
#df.to_csv('file_name.csv')
final_df.to_csv("california_accidents.csv")
68/58:
#df.to_csv('file_name.csv')
final_df.to_csv("california_accidents.csv", index = False, compression = "zip")
68/59:
#df.to_csv('file_name.csv')
final_df.to_csv("california_accidents.zip", index = False, compression = "zip")
71/1:
# Dependencies and Setup
import matplotlib.pyplot as plt
import pandas as pd
import numpy as np
import requests
import time
from scipy.stats import linregress

# Import API key
#from api_keys import weather_api_key

# Incorporated citipy to determine city based on latitude and longitude
from citipy import citipy

# Output File (CSV)
output_data_file = "cities.csv"

# Range of latitudes and longitudes
lat_range = (-90, 90)
lng_range = (-180, 180)
71/2:
# Dependencies and Setup
import matplotlib.pyplot as plt
import pandas as pd
import numpy as np
import requests
import time
from scipy.stats import linregress

# Import API key
from api_keys import weather_api_key

# Incorporated citipy to determine city based on latitude and longitude
from citipy import citipy

# Output File (CSV)
output_data_file = "cities.csv"

# Range of latitudes and longitudes
lat_range = (-90, 90)
lng_range = (-180, 180)
71/3:
# Dependencies and Setup
import matplotlib.pyplot as plt
import pandas as pd
import numpy as np
import requests
import time
from scipy.stats import linregress

# Import API key
from api_keys import weather_api_key

# Incorporated citipy to determine city based on latitude and longitude
from citipy import citipy

# Output File (CSV)
output_data_file = "cities.csv"

# Range of latitudes and longitudes
lat_range = (-90, 90)
lng_range = (-180, 180)
71/4: weather_api_key
71/5:
#Generate Cities List
# List for holding lat_lngs and cities
lat_lngs = []
cities = []

# Create a set of random lat and lng combinations
lats = np.random.uniform(lat_range[0], lat_range[1], size=1500)
lngs = np.random.uniform(lng_range[0], lng_range[1], size=1500)
lat_lngs = zip(lats, lngs)

# Identify nearest city for each lat, lng combination
for lat_lng in lat_lngs:
    city = citipy.nearest_city(lat_lng[0], lat_lng[1]).city_name
    
    # If the city is unique, then add it to a our cities list
    if city not in cities:
        cities.append(city)

# Print the city count to confirm sufficient count
len(cities)
71/6:
# Dependencies and Setup
import matplotlib.pyplot as plt
import pandas as pd
import numpy as np
import requests
import time
from scipy.stats import linregress

# Import API key
from api_keys import weather_api_key

# Incorporated citipy to determine city based on latitude and longitude
from citipy import citipy

# Output File (CSV)
output_data_file = "cities.csv"

# Range of latitudes and longitudes
lat_range = (-90, 90)
lng_range = (-180, 180)
71/7:
#read the csv file
cities_df = pd.read_csv(output_data_file)
cities_df.head()
71/8: weather_api_key
71/9:
# Dependencies and Setup
import matplotlib.pyplot as plt
import pandas as pd
import numpy as np
import requests
import time
from scipy.stats import linregress

# Import API key
from api_keys import weather_api_key

# Incorporated citipy to determine city based on latitude and longitude
from citipy import citipy

# Output File (CSV)
output_data_file = "cities.csv"

# Range of latitudes and longitudes
lat_range = (-90, 90)
lng_range = (-180, 180)
71/10:
#read the csv file
cities_df = pd.read_csv(output_data_file)
cities_df.head()
71/11: weather_api_key
71/12: weather_api_key
71/13:
base_url = https://api.openweathermap.org/data/2.5/weather?q=
    #{city name}
api_part = &appid=weather_api_key

full_url = full_url = base_url + city + api_part
71/14:
base_url = "https://api.openweathermap.org/data/2.5/weather?q=""
    #{city name}
api_part = "&appid=" + weather_api_key

full_url = full_url = base_url + city + api_part
71/15:
base_url = "https://api.openweathermap.org/data/2.5/weather?q="
    #{city name}
api_part = "&appid=" + weather_api_key

full_url = full_url = base_url + city + api_part
71/16:
base_url = "https://api.openweathermap.org/data/2.5/weather?q="
    #{city name}
api_part = "&appid=" + weather_api_key

full_url = full_url = base_url + city + api_part
full_url
74/1:
response = request.gets(full_url).json()
response["sys"]["name"]
74/2:
response = requests.get(full_url).json()
response["sys"]["name"]
74/3:
# Dependencies and Setup
import matplotlib.pyplot as plt
import pandas as pd
import numpy as np
import requests
import time
from scipy.stats import linregress

# Import API key
from api_keys import weather_api_key

# Incorporated citipy to determine city based on latitude and longitude
from citipy import citipy

# Output File (CSV)
output_data_file = "cities.csv"

# Range of latitudes and longitudes
lat_range = (-90, 90)
lng_range = (-180, 180)
74/4:
# Dependencies and Setup
import matplotlib.pyplot as plt
import pandas as pd
import numpy as np
import requests
import time
from scipy.stats import linregress

# Import API key
from api_keys import weather_api_key

# Incorporated citipy to determine city based on latitude and longitude
from citipy import citipy

# Output File (CSV)
output_data_file = "cities.csv"

# Range of latitudes and longitudes
lat_range = (-90, 90)
lng_range = (-180, 180)
74/5:
#read the csv file
cities_df = pd.read_csv(output_data_file)
cities_df.head()
74/6:
base_url = "https://api.openweathermap.org/data/2.5/weather?q="
    #{city name}
api_part = "&appid=" + weather_api_key

full_url = base_url + city + api_part
full_url
74/7:
base_url = "https://api.openweathermap.org/data/2.5/weather?q="
    #{city name}
api_part = "&appid=" + weather_api_key

full_url = base_url + "Hermanus" + api_part
full_url
74/8:
response = requests.get(full_url).json()
response["sys"]["name"]
74/9:
response = requests.get(full_url).json()
response["sys"]
74/10:
response = requests.get(full_url).json()
response["name"]
74/11:
#Perform API Calls
base_url = https://api.openweathermap.org/data/2.5/weather?q=
api_part = &appid=weather_api_key
#Perform a weather check on each city using a series of successive API calls.
for city in cities:
    full_url = base_url + city + api_part
    response = requests.get(full_url).json()
    print(response["name"])
#Include a print log of each city as it'sbeing processed (with the city number and city name).
74/12:
#Perform API Calls
base_url = "https://api.openweathermap.org/data/2.5/weather?q="
api_part = "&appid=" + weather_api_key
#Perform a weather check on each city using a series of successive API calls.
for city in cities:
    full_url = base_url + city + api_part
    response = requests.get(full_url).json()
    print(response["name"])
#Include a print log of each city as it'sbeing processed (with the city number and city name).
74/13:
#Generate Cities List
# List for holding lat_lngs and cities
lat_lngs = []
cities = []

# Create a set of random lat and lng combinations
lats = np.random.uniform(lat_range[0], lat_range[1], size=1500)
lngs = np.random.uniform(lng_range[0], lng_range[1], size=1500)
lat_lngs = zip(lats, lngs)

# Identify nearest city for each lat, lng combination
for lat_lng in lat_lngs:
    city = citipy.nearest_city(lat_lng[0], lat_lng[1]).city_name
    
    # If the city is unique, then add it to a our cities list
    if city not in cities:
        cities.append(city)

# Print the city count to confirm sufficient count
len(cities)
74/14:
#Perform API Calls
base_url = "https://api.openweathermap.org/data/2.5/weather?q="
api_part = "&appid=" + weather_api_key
#Perform a weather check on each city using a series of successive API calls.
for city in cities:
    full_url = base_url + city + api_part
    response = requests.get(full_url).json()
    print(response["name"])
#Include a print log of each city as it'sbeing processed (with the city number and city name).
74/15:
response = requests.get(full_url).json()
response[["name", "id"]]
74/16:
response = requests.get(full_url).json()
print(response["name"] + response["id"])
74/17:
response = requests.get(full_url).json()
print(response["name"] & response["id"])
74/18:
response = requests.get(full_url).json()
print(response["name"]["id"])
74/19:
response = requests.get(full_url).json()
print(response["id"])
74/20:
response = requests.get(full_url).json()
print((response["id"]) + (response["name"])
74/21: cities.head()
74/22: cities[5]
74/23: cities[520]
74/24:
response = requests.get(full_url).json()
print(response)
74/25:
response = requests.get(full_url).json()
print(response["coord"])
74/26:
response = requests.get(full_url).json()
type(response["coord"])
74/27:
response = requests.get(full_url).json()
print((response["coord"]["lat"]))
74/28:
response = requests.get(full_url).json()
print((response["sys"]["country"]))
74/29:
response = requests.get(full_url).json()
print(response["sys"]["country"])
74/30:
response = requests.get(full_url).json()
print(response["wind"]["speed"])
74/31:
base_url = "https://api.openweathermap.org/data/2.5/weather?q="
    #{city name}
api_part = "&appid=" + weather_api_key

full_url = base_url + "Hermanus" + api_part
full_url
74/32:
response = requests.get(full_url).json()
print(response["wind"]["speed"])
74/33:
#Generate Cities List
# List for holding lat_lngs and cities
lat_lngs = []
cities = []

# Create a set of random lat and lng combinations
lats = np.random.uniform(lat_range[0], lat_range[1], size=1500)
lngs = np.random.uniform(lng_range[0], lng_range[1], size=1500)
lat_lngs = zip(lats, lngs)

# Identify nearest city for each lat, lng combination
for lat_lng in lat_lngs:
    city = citipy.nearest_city(lat_lng[0], lat_lng[1]).city_name
    
    # If the city is unique, then add it to a our cities list
    if city not in cities:
        cities.append(city)

# Print the city count to confirm sufficient count
len(cities)
74/34:
#Perform API Calls
base_url = "https://api.openweathermap.org/data/2.5/weather?q="
api_part = "&appid=" + weather_api_key

#create lists to hold column values for new dataframe
lat = []
lng = []
max_temp = []
humidity = []
cloudiness = []
wind_speed = []
country = []
date = []

#Perform a weather check on each city using a series of successive API calls.
for city in cities:
    full_url = base_url + city + api_part
    response = requests.get(full_url).json()
    
    #Add city info to appropiate lists
    
    lat.append(response["coord"]["lat"])
    lng.append(response["coord"]["lon"])
    max_temp.append(response["main"]["temp_max"])
    humidity.append(response["main"]["humidity"])
    cloudiness.append(response["clouds"]["all"])
    wind_speed.append(response["wind"]["speed"])
    country.append(response["sys"]["country"])
    date.append(response["dt"])
    
#Include a print log of each city as it'sbeing processed (with the city number and city name).
#print(response["name"])
74/35:
response = requests.get(full_url).json()
print(response["coord"]["lat"])
74/36:
base_url = "https://api.openweathermap.org/data/2.5/weather?q="
    #{city name}
api_part = "&appid=" + weather_api_key

full_url = base_url + "Hermanus" + api_part
full_url
74/37:
response = requests.get(full_url).json()
print(response["coord"]["lat"])
74/38:
#Perform API Calls
base_url = "https://api.openweathermap.org/data/2.5/weather?q="
api_part = "&appid=" + weather_api_key

#create lists to hold column values for new dataframe
lat = []
lng = []
max_temp = []
humidity = []
cloudiness = []
wind_speed = []
country = []
date = []

#Perform a weather check on each city using a series of successive API calls.
for city in cities:
    full_url = base_url + city + api_part
    response = requests.get(full_url).json()
    
    #Add city info to appropiate lists
    
    lat.append(response["coord"]["lat"])
    lng.append(response["coord"]["lon"])
    max_temp.append(response["main"]["temp_max"])
    humidity.append(response["main"]["humidity"])
    cloudiness.append(response["clouds"]["all"])
    wind_speed.append(response["wind"]["speed"])
    country.append(response["sys"]["country"])
    date.append(response["dt"])
    
#Include a print log of each city as it'sbeing processed (with the city number and city name).
#print(response["name"])
74/39:
main_df = pd.DataFrame({
    "": ,
    "": ,
    "": ,
    "": ,
    "": ,
    "": ,
})
74/40:
# Dependencies and Setup
import matplotlib.pyplot as plt
import pandas as pd
import numpy as np
import requests
import time
from scipy.stats import linregress

# Import API key
from api_keys import weather_api_key

# Incorporated citipy to determine city based on latitude and longitude
from citipy import citipy

# Output File (CSV)
output_data_file = "cities.csv"

# Range of latitudes and longitudes
lat_range = (-90, 90)
lng_range = (-180, 180)
74/41:
#read the csv file
cities_df = pd.read_csv(output_data_file)
cities_df.head()
74/42:
#Generate Cities List
# List for holding lat_lngs and cities
lat_lngs = []
cities = []

# Create a set of random lat and lng combinations
lats = np.random.uniform(lat_range[0], lat_range[1], size=1500)
lngs = np.random.uniform(lng_range[0], lng_range[1], size=1500)
lat_lngs = zip(lats, lngs)

# Identify nearest city for each lat, lng combination
for lat_lng in lat_lngs:
    city = citipy.nearest_city(lat_lng[0], lat_lng[1]).city_name
    
    # If the city is unique, then add it to a our cities list
    if city not in cities:
        cities.append(city)

# Print the city count to confirm sufficient count
len(cities)
74/43:
#Perform API Calls
base_url = "https://api.openweathermap.org/data/2.5/weather?q="
api_part = "&appid=" + weather_api_key

#create lists to hold column values for new dataframe
lat = []
lng = []
max_temp = []
humidity = []
cloudiness = []
wind_speed = []
country = []
date = []

#Perform a weather check on each city using a series of successive API calls.
for city in cities:
    full_url = base_url + city + api_part
    response = requests.get(full_url).json()
    
    #Add city info to appropiate lists
    
    lat.append(response["coord"]["lat"])
    lng.append(response["coord"]["lon"])
    max_temp.append(response["main"]["temp_max"])
    humidity.append(response["main"]["humidity"])
    cloudiness.append(response["clouds"]["all"])
    wind_speed.append(response["wind"]["speed"])
    country.append(response["sys"]["country"])
    date.append(response["dt"])
    
#Include a print log of each city as it'sbeing processed (with the city number and city name).
#print(response["name"])
74/44:
#Perform API Calls
base_url = "https://api.openweathermap.org/data/2.5/weather?q="
api_part = "&appid=" + weather_api_key

#create lists to hold column values for new dataframe
lat = []
lng = []
max_temp = []
humidity = []
cloudiness = []
wind_speed = []
country = []
date = []

#Perform a weather check on each city using a series of successive API calls.
for city in enumerate(cities):
    try:
        full_url = base_url + city + api_part
        response = requests.get(full_url).json()
    
        #Add city info to appropiate lists
    
        lat.append(response["coord"]["lat"])
        lng.append(response["coord"]["lon"])
        max_temp.append(response["main"]["temp_max"])
        humidity.append(response["main"]["humidity"])
        cloudiness.append(response["clouds"]["all"])
        wind_speed.append(response["wind"]["speed"])
        country.append(response["sys"]["country"])
        date.append(response["dt"])
    except:
        print("City not found. Skipping city...")
        pass

print("Appending is complete")
    
#Include a print log of each city as it'sbeing processed (with the city number and city name).
#print(response["name"])
74/45:
#Perform API Calls
base_url = "https://api.openweathermap.org/data/2.5/weather?q="
api_part = "&appid=" + weather_api_key

#Create list to store data from api call
city_data = []

#loop through all the list of cities if they are found in api if not skip
for city in enumerate(cities):
    
    #create url endpoint
    full_url = base_url + city + api_part
    
    #
    try:
        #run API request and form it in JSON formatt 
        response = requests.get(full_url).json()
        
        # Parse out the max temp, humidity, and cloudiness
        city_lat = city_weather["coord"]["lat"]
        city_lng = city_weather["coord"]["lon"]
        city_max_temp = city_weather["main"]["temp_max"]
        city_humidity = city_weather["main"]["humidity"]
        city_clouds = city_weather["clouds"]["all"]
        city_wind = city_weather["wind"]["speed"]
        city_country = city_weather["sys"]["country"]
        city_date = city_weather["dt"]
        
        # Append the City information into city_data list
        city_data.append({"City": city, 
                          "Lat": city_lat, 
                          "Lng": city_lng, 
                          "Max Temp": city_max_temp,
                          "Humidity": city_humidity,
                          "Cloudiness": city_clouds,
                          "Wind Speed": city_wind,
                          "Country": city_country,
                          "Date": city_date})
        
        # If an error is experienced, skip the city
    except:
        print("City not found. Skipping...")
        pass
              
# Indicate that Data Loading is complete 
print("-----------------------------")
print("Data Retrieval Complete      ")
print("-----------------------------")
74/46:
#Perform API Calls
#base_url = "https://api.openweathermap.org/data/2.5/weather?q="
#api_part = "&appid=" + weather_api_key
url = "http://api.openweathermap.org/data/2.5/weather?units=Imperial&APPID=" + weather_api_key

#Create list to store data from api call
city_data = []

#loop through all the list of cities if they are found in api if not skip
for city in enumerate(cities):
    
    #create url endpoint
    full_url = url + "&q=" + city 
    
    #
    try:
        #run API request and form it in JSON formatt 
        response = requests.get(full_url).json()
        
        # Parse out the max temp, humidity, and cloudiness
        city_lat = city_weather["coord"]["lat"]
        city_lng = city_weather["coord"]["lon"]
        city_max_temp = city_weather["main"]["temp_max"]
        city_humidity = city_weather["main"]["humidity"]
        city_clouds = city_weather["clouds"]["all"]
        city_wind = city_weather["wind"]["speed"]
        city_country = city_weather["sys"]["country"]
        city_date = city_weather["dt"]
        
        # Append the City information into city_data list
        city_data.append({"City": city, 
                          "Lat": city_lat, 
                          "Lng": city_lng, 
                          "Max Temp": city_max_temp,
                          "Humidity": city_humidity,
                          "Cloudiness": city_clouds,
                          "Wind Speed": city_wind,
                          "Country": city_country,
                          "Date": city_date})
        
        # If an error is experienced, skip the city
    except:
        print("City not found. Skipping...")
        pass
              
# Indicate that Data Loading is complete 
print("-----------------------------")
print("Data Retrieval Complete      ")
print("-----------------------------")
74/47:
# Dependencies and Setup
import matplotlib.pyplot as plt
import pandas as pd
import numpy as np
import requests
import time
from scipy.stats import linregress

# Import API key
from api_keys import weather_api_key

# Incorporated citipy to determine city based on latitude and longitude
from citipy import citipy

# Output File (CSV)
output_data_file = "cities.csv"

# Range of latitudes and longitudes
lat_range = (-90, 90)
lng_range = (-180, 180)
74/48:
# Dependencies and Setup
import matplotlib.pyplot as plt
import pandas as pd
import numpy as np
import requests
import time
from scipy.stats import linregress

# Import API key
from api_keys import weather_api_key

# Incorporated citipy to determine city based on latitude and longitude
from citipy import citipy

# Output File (CSV)
output_data_file = "cities.csv"

# Range of latitudes and longitudes
lat_range = (-90, 90)
lng_range = (-180, 180)
74/49:
#read the csv file
cities_df = pd.read_csv(output_data_file)
cities_df.head()
74/50:
#Generate Cities List
# List for holding lat_lngs and cities
lat_lngs = []
cities = []

# Create a set of random lat and lng combinations
lats = np.random.uniform(lat_range[0], lat_range[1], size=1500)
lngs = np.random.uniform(lng_range[0], lng_range[1], size=1500)
lat_lngs = zip(lats, lngs)

# Identify nearest city for each lat, lng combination
for lat_lng in lat_lngs:
    city = citipy.nearest_city(lat_lng[0], lat_lng[1]).city_name
    
    # If the city is unique, then add it to a our cities list
    if city not in cities:
        cities.append(city)

# Print the city count to confirm sufficient count
len(cities)
74/51:
# Starting URL for Weather Map API Call
#url = "http://api.openweathermap.org/data/2.5/weather?units=Imperial&APPID=" + weather_api_key
url = "http://api.openweathermap.org/data/2.5/weather?units=Imperial&APPID=" + weather_api_key

# List of city data
city_data = []

# Print to logger
print("Beginning Data Retrieval     ")
print("-----------------------------")

# Create counters
record_count = 1
set_count = 1

# Loop through all the cities in our list
for i, city in enumerate(cities):
        
    # Group cities in sets of 50 for logging purposes
    if (i % 50 == 0 and i >= 50):
        set_count += 1
        record_count = 0

    # Create endpoint URL with each city
    city_url = url + "&q=" + city
    
    # Log the url, record, and set numbers
    print("Processing Record %s of Set %s | %s" % (record_count, set_count, city))

    # Add 1 to the record count
    record_count += 1

    # Run an API request for each of the cities
    try:
        # Parse the JSON and retrieve data
        city_weather = requests.get(city_url).json()

        # Parse out the max temp, humidity, and cloudiness
        city_lat = city_weather["coord"]["lat"]
        city_lng = city_weather["coord"]["lon"]
        city_max_temp = city_weather["main"]["temp_max"]
        city_humidity = city_weather["main"]["humidity"]
        city_clouds = city_weather["clouds"]["all"]
        city_wind = city_weather["wind"]["speed"]
        city_country = city_weather["sys"]["country"]
        city_date = city_weather["dt"]

        # Append the City information into city_data list
        city_data.append({"City": city, 
                          "Lat": city_lat, 
                          "Lng": city_lng, 
                          "Max Temp": city_max_temp,
                          "Humidity": city_humidity,
                          "Cloudiness": city_clouds,
                          "Wind Speed": city_wind,
                          "Country": city_country,
                          "Date": city_date})

    # If an error is experienced, skip the city
    except:
        print("City not found. Skipping...")
        pass
              
# Indicate that Data Loading is complete 
print("-----------------------------")
print("Data Retrieval Complete      ")
print("-----------------------------")
74/52:
# Starting URL for Weather Map API Call
#url = "http://api.openweathermap.org/data/2.5/weather?units=Imperial&APPID=" + weather_api_key
url = "http://api.openweathermap.org/data/2.5/weather?units=Imperial&APPID=" + weather_api_key

# List of city data
city_data = []

# Print to logger
print("Beginning Data Retrieval     ")
print("-----------------------------")

# Create counters
record_count = 1
set_count = 1

# Loop through all the cities in our list
for city in enumerate(cities):
        
    # Group cities in sets of 50 for logging purposes
    #if (i % 50 == 0 and i >= 50):
        #set_count += 1
        record_count = 0

    # Create endpoint URL with each city
    city_url = url + "&q=" + city
    
    # Log the url, record, and set numbers
    #print("Processing Record %s of Set %s | %s" % (record_count, set_count, city))

    # Add 1 to the record count
    record_count += 1

    # Run an API request for each of the cities
    try:
        # Parse the JSON and retrieve data
        city_weather = requests.get(city_url).json()

        # Parse out the max temp, humidity, and cloudiness
        city_lat = city_weather["coord"]["lat"]
        city_lng = city_weather["coord"]["lon"]
        city_max_temp = city_weather["main"]["temp_max"]
        city_humidity = city_weather["main"]["humidity"]
        city_clouds = city_weather["clouds"]["all"]
        city_wind = city_weather["wind"]["speed"]
        city_country = city_weather["sys"]["country"]
        city_date = city_weather["dt"]

        # Append the City information into city_data list
        city_data.append({"City": city, 
                          "Lat": city_lat, 
                          "Lng": city_lng, 
                          "Max Temp": city_max_temp,
                          "Humidity": city_humidity,
                          "Cloudiness": city_clouds,
                          "Wind Speed": city_wind,
                          "Country": city_country,
                          "Date": city_date})

    # If an error is experienced, skip the city
    except:
        print("City not found. Skipping...")
        pass
              
# Indicate that Data Loading is complete 
print("-----------------------------")
print("Data Retrieval Complete      ")
print("-----------------------------")
74/54:
# Starting URL for Weather Map API Call
#url = "http://api.openweathermap.org/data/2.5/weather?units=Imperial&APPID=" + weather_api_key
url = "http://api.openweathermap.org/data/2.5/weather?units=Imperial&APPID=" + weather_api_key

# List of city data
city_data = []

# Print to logger
print("Beginning Data Retrieval     ")
print("-----------------------------")

# Create counters
record_count = 1
set_count = 1

# Loop through all the cities in our list
for city in enumerate(cities):
        
    # Group cities in sets of 50 for logging purposes
    #if (i % 50 == 0 and i >= 50):
        #set_count += 1
    record_count = 0

    # Create endpoint URL with each city
    city_url = url + "&q=" + city
    
    # Log the url, record, and set numbers
    #print("Processing Record %s of Set %s | %s" % (record_count, set_count, city))

    # Add 1 to the record count
    record_count += 1

    # Run an API request for each of the cities
    try:
        # Parse the JSON and retrieve data
        city_weather = requests.get(city_url).json()

        # Parse out the max temp, humidity, and cloudiness
        city_lat = city_weather["coord"]["lat"]
        city_lng = city_weather["coord"]["lon"]
        city_max_temp = city_weather["main"]["temp_max"]
        city_humidity = city_weather["main"]["humidity"]
        city_clouds = city_weather["clouds"]["all"]
        city_wind = city_weather["wind"]["speed"]
        city_country = city_weather["sys"]["country"]
        city_date = city_weather["dt"]

        # Append the City information into city_data list
        city_data.append({"City": city, 
                          "Lat": city_lat, 
                          "Lng": city_lng, 
                          "Max Temp": city_max_temp,
                          "Humidity": city_humidity,
                          "Cloudiness": city_clouds,
                          "Wind Speed": city_wind,
                          "Country": city_country,
                          "Date": city_date})

    # If an error is experienced, skip the city
    except:
        print("City not found. Skipping...")
        pass
              
# Indicate that Data Loading is complete 
print("-----------------------------")
print("Data Retrieval Complete      ")
print("-----------------------------")
74/55:
# Starting URL for Weather Map API Call
#url = "http://api.openweathermap.org/data/2.5/weather?units=Imperial&APPID=" + weather_api_key
url = "http://api.openweathermap.org/data/2.5/weather?units=Imperial&APPID=" + weather_api_key

# List of city data
city_data = []

# Print to logger
print("Beginning Data Retrieval     ")
print("-----------------------------")

# Create counters
record_count = 1
set_count = 1

# Loop through all the cities in our list
for city in enumerate(cities):
        
    # Group cities in sets of 50 for logging purposes
    if (i % 50 == 0 and i >= 50):
        set_count += 1
        record_count = 0

    # Create endpoint URL with each city
    city_url = url + "&q=" + city
    
    # Log the url, record, and set numbers
    print("Processing Record %s of Set %s | %s" % (record_count, set_count, city))

    # Add 1 to the record count
    record_count += 1

    # Run an API request for each of the cities
    try:
        # Parse the JSON and retrieve data
        city_weather = requests.get(city_url).json()

        # Parse out the max temp, humidity, and cloudiness
        city_lat = city_weather["coord"]["lat"]
        city_lng = city_weather["coord"]["lon"]
        city_max_temp = city_weather["main"]["temp_max"]
        city_humidity = city_weather["main"]["humidity"]
        city_clouds = city_weather["clouds"]["all"]
        city_wind = city_weather["wind"]["speed"]
        city_country = city_weather["sys"]["country"]
        city_date = city_weather["dt"]

        # Append the City information into city_data list
        city_data.append({"City": city, 
                          "Lat": city_lat, 
                          "Lng": city_lng, 
                          "Max Temp": city_max_temp,
                          "Humidity": city_humidity,
                          "Cloudiness": city_clouds,
                          "Wind Speed": city_wind,
                          "Country": city_country,
                          "Date": city_date})

    # If an error is experienced, skip the city
    except:
        print("City not found. Skipping...")
        pass
              
# Indicate that Data Loading is complete 
print("-----------------------------")
print("Data Retrieval Complete      ")
print("-----------------------------")
74/56:
# Dependencies and Setup
import matplotlib.pyplot as plt
import pandas as pd
import numpy as np
import requests
import time
from scipy.stats import linregress

# Import API key
from api_keys import weather_api_key

# Incorporated citipy to determine city based on latitude and longitude
from citipy import citipy

# Output File (CSV)
output_data_file = "cities.csv"

# Range of latitudes and longitudes
lat_range = (-90, 90)
lng_range = (-180, 180)
74/57:
#read the csv file
cities_df = pd.read_csv(output_data_file)
cities_df.head()
74/58:
#response = requests.get(full_url).json()
#print(response["coord"]["lat"])
74/59:
#Generate Cities List
# List for holding lat_lngs and cities
lat_lngs = []
cities = []

# Create a set of random lat and lng combinations
lats = np.random.uniform(lat_range[0], lat_range[1], size=1500)
lngs = np.random.uniform(lng_range[0], lng_range[1], size=1500)
lat_lngs = zip(lats, lngs)

# Identify nearest city for each lat, lng combination
for lat_lng in lat_lngs:
    city = citipy.nearest_city(lat_lng[0], lat_lng[1]).city_name
    
    # If the city is unique, then add it to a our cities list
    if city not in cities:
        cities.append(city)

# Print the city count to confirm sufficient count
len(cities)
74/60:
# Starting URL for Weather Map API Call
#url = "http://api.openweathermap.org/data/2.5/weather?units=Imperial&APPID=" + weather_api_key
url = "http://api.openweathermap.org/data/2.5/weather?units=Imperial&APPID=" + weather_api_key

# List of city data
city_data = []

# Print to logger
print("Beginning Data Retrieval     ")
print("-----------------------------")

# Create counters
record_count = 1
set_count = 1

# Loop through all the cities in our list
for city in enumerate(cities):
        
    # Group cities in sets of 50 for logging purposes
    #if (i % 50 == 0 and i >= 50):
        #set_count += 1
    record_count = 0

    # Create endpoint URL with each city
    city_url = url + "&q=" + city
    
    # Log the url, record, and set numbers
    #print("Processing Record %s of Set %s | %s" % (record_count, set_count, city))

    # Add 1 to the record count
    record_count += 1

    # Run an API request for each of the cities
    try:
        # Parse the JSON and retrieve data
        city_weather = requests.get(city_url).json()

        # Parse out the max temp, humidity, and cloudiness
        city_lat = city_weather["coord"]["lat"]
        city_lng = city_weather["coord"]["lon"]
        city_max_temp = city_weather["main"]["temp_max"]
        city_humidity = city_weather["main"]["humidity"]
        city_clouds = city_weather["clouds"]["all"]
        city_wind = city_weather["wind"]["speed"]
        city_country = city_weather["sys"]["country"]
        city_date = city_weather["dt"]

        # Append the City information into city_data list
        city_data.append({"City": city, 
                          "Lat": city_lat, 
                          "Lng": city_lng, 
                          "Max Temp": city_max_temp,
                          "Humidity": city_humidity,
                          "Cloudiness": city_clouds,
                          "Wind Speed": city_wind,
                          "Country": city_country,
                          "Date": city_date})

    # If an error is experienced, skip the city
    except:
        print("City not found. Skipping...")
        pass
              
# Indicate that Data Loading is complete 
print("-----------------------------")
print("Data Retrieval Complete      ")
print("-----------------------------")
74/61:
# Starting URL for Weather Map API Call
#url = "http://api.openweathermap.org/data/2.5/weather?units=Imperial&APPID=" + weather_api_key
url = "http://api.openweathermap.org/data/2.5/weather?units=Imperial&APPID=" + weather_api_key

# List of city data
city_data = []

# Print to logger
print("Beginning Data Retrieval     ")
print("-----------------------------")

# Create counters
record_count = 1
set_count = 1

# Loop through all the cities in our list
for city in enumerate(cities):
        
    # Group cities in sets of 50 for logging purposes
    if (i % 50 == 0 and i >= 50):
        set_count += 1
        record_count = 0

    # Create endpoint URL with each city
    city_url = url + "&q=" + city
    
    # Log the url, record, and set numbers
    print("Processing Record %s of Set %s | %s" % (record_count, set_count, city))

    # Add 1 to the record count
    record_count += 1

    # Run an API request for each of the cities
    try:
        # Parse the JSON and retrieve data
        city_weather = requests.get(city_url).json()

        # Parse out the max temp, humidity, and cloudiness
        city_lat = city_weather["coord"]["lat"]
        city_lng = city_weather["coord"]["lon"]
        city_max_temp = city_weather["main"]["temp_max"]
        city_humidity = city_weather["main"]["humidity"]
        city_clouds = city_weather["clouds"]["all"]
        city_wind = city_weather["wind"]["speed"]
        city_country = city_weather["sys"]["country"]
        city_date = city_weather["dt"]

        # Append the City information into city_data list
        city_data.append({"City": city, 
                          "Lat": city_lat, 
                          "Lng": city_lng, 
                          "Max Temp": city_max_temp,
                          "Humidity": city_humidity,
                          "Cloudiness": city_clouds,
                          "Wind Speed": city_wind,
                          "Country": city_country,
                          "Date": city_date})

    # If an error is experienced, skip the city
    except:
        print("City not found. Skipping...")
        pass
              
# Indicate that Data Loading is complete 
print("-----------------------------")
print("Data Retrieval Complete      ")
print("-----------------------------")
74/62:
# Dependencies and Setup
import matplotlib.pyplot as plt
import pandas as pd
import numpy as np
import requests
import time
from scipy.stats import linregress

# Import API key
from api_keys import weather_api_key

# Incorporated citipy to determine city based on latitude and longitude
from citipy import citipy

# Output File (CSV)
output_data_file = "cities.csv"

# Range of latitudes and longitudes
lat_range = (-90, 90)
lng_range = (-180, 180)
74/63:
#read the csv file
cities_df = pd.read_csv(output_data_file)
cities_df.head()
74/64:
#Generate Cities List
# List for holding lat_lngs and cities
lat_lngs = []
cities = []

# Create a set of random lat and lng combinations
lats = np.random.uniform(lat_range[0], lat_range[1], size=1500)
lngs = np.random.uniform(lng_range[0], lng_range[1], size=1500)
lat_lngs = zip(lats, lngs)

# Identify nearest city for each lat, lng combination
for lat_lng in lat_lngs:
    city = citipy.nearest_city(lat_lng[0], lat_lng[1]).city_name
    
    # If the city is unique, then add it to a our cities list
    if city not in cities:
        cities.append(city)

# Print the city count to confirm sufficient count
len(cities)
74/65:
#Perform API Calls
#base_url = "https://api.openweathermap.org/data/2.5/weather?q="
#api_part = "&appid=" + weather_api_key
url = "http://api.openweathermap.org/data/2.5/weather?units=Imperial&APPID=" + weather_api_key

#Create list to store data from api call
city_data = []

#loop through all the list of cities if they are found in api if not skip
for city in (cities):
    
    #create url endpoint
    full_url = url + "&q=" + city 
    
    #
    try:
        #run API request and form it in JSON formatt 
        response = requests.get(full_url).json()
        
        # Parse out the max temp, humidity, and cloudiness
        city_lat = city_weather["coord"]["lat"]
        city_lng = city_weather["coord"]["lon"]
        city_max_temp = city_weather["main"]["temp_max"]
        city_humidity = city_weather["main"]["humidity"]
        city_clouds = city_weather["clouds"]["all"]
        city_wind = city_weather["wind"]["speed"]
        city_country = city_weather["sys"]["country"]
        city_date = city_weather["dt"]
        
        # Append the City information into city_data list
        city_data.append({"City": city, 
                          "Lat": city_lat, 
                          "Lng": city_lng, 
                          "Max Temp": city_max_temp,
                          "Humidity": city_humidity,
                          "Cloudiness": city_clouds,
                          "Wind Speed": city_wind,
                          "Country": city_country,
                          "Date": city_date})
        
        # If an error is experienced, skip the city
    except:
        print("City not found. Skipping...")
        pass
              
# Indicate that Data Loading is complete 
print("-----------------------------")
print("Data Retrieval Complete      ")
print("-----------------------------")
74/66:
#Create base URL for API call
url = "http://api.openweathermap.org/data/2.5/weather?units=Imperial&APPID=" + weather_api_key

#Create list to store data from api call
city_df = []

#loop through all the list of cities if they are found in api if not skip
for city in (cities):
    
    #create url endpoint
    full_url = url + "&q=" + city 
    
    #Run API requests
    try:
        #run API request and form it in JSON formatt 
        response = requests.get(full_url).json()
        
        # Parse out the max temp, humidity, and cloudiness
        lat = response["coord"]["lat"]
        lng = response["coord"]["lon"]
        max_temp = response["main"]["temp_max"]
        humidity = response["main"]["humidity"]
        clouds = response["clouds"]["all"]
        wind = response["wind"]["speed"]
        country = response["sys"]["country"]
        date = response["dt"]
        
        # Append the City information into city_data list
        city_df.append({"City": city, 
                          "Lat": lat, 
                          "Lng": lng, 
                          "Max Temp": max_temp,
                          "Humidity": humidity,
                          "Cloudiness": clouds,
                          "Wind Speed": wind,
                          "Country": country,
                          "Date": date})
        
        # If an error is experienced, skip the city
    except:
        print("City not found. Skipping...")
        pass
              
# Indicate that Data Loading is complete 
print("-----------------------------")
print("Data Retrieval Complete      ")
print("-----------------------------")
77/1:
#Generate Cities List
# List for holding lat_lngs and cities
lat_lngs = []
cities = []

# Create a set of random lat and lng combinations
lats = np.random.uniform(lat_range[0], lat_range[1], size=1500)
lngs = np.random.uniform(lng_range[0], lng_range[1], size=1500)
lat_lngs = zip(lats, lngs)

# Identify nearest city for each lat, lng combination
for lat_lng in lat_lngs:
    city = citipy.nearest_city(lat_lng[0], lat_lng[1]).city_name
    
    # If the city is unique, then add it to a our cities list
    if city not in cities:
        cities.append(city)

# Print the city count to confirm sufficient count
len(cities)
77/2:
#Check if response is running correctly before running loop
#response = requests.get(full_url).json()
#print(response["coord"]["lat"])
77/3:
# Dependencies and Setup
import matplotlib.pyplot as plt
import pandas as pd
import numpy as np
import requests
import time
from scipy.stats import linregress

# Import API key
from api_keys import weather_api_key

# Incorporated citipy to determine city based on latitude and longitude
from citipy import citipy

# Output File (CSV)
output_data_file = "cities.csv"

# Range of latitudes and longitudes
lat_range = (-90, 90)
lng_range = (-180, 180)
77/4:
#Generate Cities List
# List for holding lat_lngs and cities
lat_lngs = []
cities = []

# Create a set of random lat and lng combinations
lats = np.random.uniform(lat_range[0], lat_range[1], size=1500)
lngs = np.random.uniform(lng_range[0], lng_range[1], size=1500)
lat_lngs = zip(lats, lngs)

# Identify nearest city for each lat, lng combination
for lat_lng in lat_lngs:
    city = citipy.nearest_city(lat_lng[0], lat_lng[1]).city_name
    
    # If the city is unique, then add it to a our cities list
    if city not in cities:
        cities.append(city)

# Print the city count to confirm sufficient count
len(cities)
77/5:
# Starting URL for Weather Map API Call
#url = "http://api.openweathermap.org/data/2.5/weather?units=Imperial&APPID=" + weather_api_key
url = "http://api.openweathermap.org/data/2.5/weather?units=Imperial&APPID=" + weather_api_key

# List of city data
city_data = []

# Print to logger
print("Beginning Data Retrieval     ")
print("-----------------------------")

# Create counters
record_count = 1
set_count = 1

# Loop through all the cities in our list
for i, city in enumerate(cities):
        
    # Group cities in sets of 50 for logging purposes
    if (i % 50 == 0 and i >= 50):
        set_count += 1
        record_count = 0

    # Create endpoint URL with each city
    city_url = url + "&q=" + city
    
    # Log the url, record, and set numbers
    print("Processing Record %s of Set %s | %s" % (record_count, set_count, city))

    # Add 1 to the record count
    record_count += 1

    # Run an API request for each of the cities
    try:
        # Parse the JSON and retrieve data
        city_weather = requests.get(city_url).json()

        # Parse out the max temp, humidity, and cloudiness
        city_lat = city_weather["coord"]["lat"]
        city_lng = city_weather["coord"]["lon"]
        city_max_temp = city_weather["main"]["temp_max"]
        city_humidity = city_weather["main"]["humidity"]
        city_clouds = city_weather["clouds"]["all"]
        city_wind = city_weather["wind"]["speed"]
        city_country = city_weather["sys"]["country"]
        city_date = city_weather["dt"]

        # Append the City information into city_data list
        city_data.append({"City": city, 
                          "Lat": city_lat, 
                          "Lng": city_lng, 
                          "Max Temp": city_max_temp,
                          "Humidity": city_humidity,
                          "Cloudiness": city_clouds,
                          "Wind Speed": city_wind,
                          "Country": city_country,
                          "Date": city_date})

    # If an error is experienced, skip the city
    except:
        print("City not found. Skipping...")
        pass
              
# Indicate that Data Loading is complete 
print("-----------------------------")
print("Data Retrieval Complete      ")
print("-----------------------------")
76/1:
# Dependencies and Setup
import matplotlib.pyplot as plt
import pandas as pd
import scipy.stats as st
import numpy as np

# Study data files
mouse_metadata_path = "Mouse_metadata.csv"
study_results_path = "Study_results.csv"

# Read the mouse data and the study results
mouse_metadata = pd.read_csv(mouse_metadata_path)
study_results = pd.read_csv(study_results_path)

# Combine the data into a single dataset
combined_df = mouse_metadata.merge(study_results, how='inner', on='Mouse ID')
# Display the data table for preview
#combined_df.head()
77/6:
#Create dataframe from city_data
city_df = pd.DataFrame(data = city_data)
city_df.head()
76/2: mouse_metadata.describe()
77/7: city_df.describe()
77/8:
# Inspect the data and remove the cities where the humidity > 100%.
city_df.loc(city_df["Humidity"] < 100, :)
77/9:
# Inspect the data and remove the cities where the humidity > 100%.
city_df.loc(city_df["Humidity"] < 100, ;)
77/10:
# Inspect the data and remove the cities where the humidity > 100%.
city_df.loc((city_df["Humidity"] < 100), :)
77/11:
# Inspect the data and remove the cities where the humidity > 100%.
city_df.loc[(city_df["Humidity"] < 100), :]
77/12:
# Inspect the data and remove the cities where the humidity > 100%.
clean_city_df = city_df.loc[(city_df["Humidity"] < 100), :]

#There was 536 rows now there is 532 meaning 4 rows had humidity above 100
77/13:
#Plotting the Data
#Latitude vs Temperature Plot
plt.scatter(city_df["Lat"], city_df["Max Temp"])
77/14:
#Plotting the Data
#Latitude vs Temperature Plot
plt.scatter(city_df["Lat"], city_df["Max Temp"], alpha = .5, edgecolors = black)
77/15:
#Plotting the Data
#Latitude vs Temperature Plot
plt.scatter(city_df["Lat"], city_df["Max Temp"], alpha = .5, edgecolors = "black")
77/16:
#Plotting the Data
#Latitude vs Temperature Plot
plt.scatter(city_df["Lat"], city_df["Max Temp"], alpha = .75, edgecolors = "black")
77/17:
#Plotting the Data
#Latitude vs Temperature Plot
plt.scatter(city_df["Lat"], city_df["Max Temp"], alpha = .75, edgecolors = "black",
           labels = "Cities")
77/18:
#Plotting the Data
#Latitude vs Temperature Plot
plt.scatter(city_df["Lat"], city_df["Max Temp"], 
            alpha = .75, edgecolors = "black", labels = "Cities")
77/19:
#Plotting the Data
#Latitude vs Temperature Plot
plt.scatter(city_df["Lat"], city_df["Max Temp"], alpha = .75, edgecolors = "black", labels = "Cities")
77/20:
#Plotting the Data
#Latitude vs Temperature Plot
plt.scatter(city_df["Lat"], city_df["Max Temp"], alpha = .75, edgecolors = "black", label = "Cities")
77/21:
#Plotting the Data
#Latitude vs Temperature Plot
plt.scatter(city_df["Lat"], city_df["Max Temp"], alpha = .75, 
            edgecolors = "black", label = "Cities", linewidths = .25
           )
77/22:
#Plotting the Data
#Latitude vs Temperature Plot
plt.scatter(city_df["Lat"], city_df["Max Temp"], alpha = .75, 
            edgecolors = "black", label = "Cities", linewidths = .75
           )
77/23:
#Plotting the Data
#Latitude vs Temperature Plot
plt.scatter(city_df["Lat"], city_df["Max Temp"], alpha = .75, 
            edgecolors = "black", label = "Cities", linewidths = 1
           )
77/24:
#Plotting the Data
#Latitude vs Temperature Plot
plt.scatter(city_df["Lat"], city_df["Max Temp"], alpha = .75, 
            edgecolors = "black", label = "Cities", linewidths = 1)
plt.title = "City Latitude vs. Max Temperature"
77/25:
#Plotting the Data
#Latitude vs Temperature Plot
plt.scatter(city_df["Lat"], city_df["Max Temp"], alpha = .75, 
            edgecolors = "black", label = "Cities", linewidths = 1)
plt.title("City Latitude vs. Max Temperature")
77/26:
#Plotting the Data
#Latitude vs Temperature Plot
plt.scatter(city_df["Lat"], city_df["Max Temp"], alpha = .75, 
            edgecolors = "black", label = "Cities", linewidths = 1)
#Add supplemental information
plt.title(City Latitude vs. Max Temperature)
77/27:
#Plotting the Data
#Latitude vs Temperature Plot
plt.scatter(city_df["Lat"], city_df["Max Temp"], alpha = .75, 
            edgecolors = "black", label = "Cities", linewidths = 1)
#Add supplemental information
plt.title("City Latitude vs. Max Temperature")
77/28:
#Plotting the Data
#Latitude vs Temperature Plot
plt.scatter(city_df["Lat"], city_df["Max Temp"], alpha = .75, 
            edgecolors = "black", label = "Cities", linewidths = 1)
#Add supplemental information
plt.title = "City Latitude vs. Max Temperature"
77/29:
#Plotting the Data
#Latitude vs Temperature Plot
plt.scatter(city_df["Lat"], city_df["Max Temp"], alpha = .75, 
            edgecolors = "black", label = "Cities", linewidths = 1)
#Add supplemental information
plt.title = "City Latitude vs. Max Temperature"
plt.show
77/30:
#Plotting the Data
#Latitude vs Temperature Plot
plt.scatter(city_df["Lat"], city_df["Max Temp"], alpha = .75, 
            edgecolors = "black", label = "Cities", linewidths = 1)
#Add supplemental information
plt.title = "City Latitude vs. Max Temperature"
plt.xlabel("Latitude")
plt.ylabel("Temperature (F)")
plt.show
77/31:
#Plotting the Data
#Latitude vs Temperature Plot
plt.scatter(city_df["Lat"], city_df["Max Temp"], alpha = .75, 
            edgecolors = "black", label = "Cities", linewidths = 1)
#Add supplemental information
plt.title("City Latitude vs. Max Temperature")
plt.xlabel("Latitude")
plt.ylabel("Temperature (F)")
plt.show
77/32:
#Plotting the Data
#Latitude vs Temperature Plot
plt.scatter(city_df["Lat"], city_df["Max Temp"], alpha = .75, 
            edgecolors = "black", label = "Cities", linewidths = 1)
#Add supplemental information
plt.title("City Latitude vs Max Temperature")
plt.xlabel("Latitude")
plt.ylabel("Temperature (F)")
plt.show
77/33:
#Plotting the Data
#Latitude vs Temperature Plot
plt.scatter(city_df["Lat"], city_df["Max Temp"], alpha = .75, 
            edgecolors = "black", label = "Cities", linewidths = 1)
#Add supplemental information
#plt.title("City Latitude vs Max Temperature")
plt.xlabel("Latitude")
plt.ylabel("Temperature (F)")
plt.grid(color = "black")
plt.show
77/34:
#Plotting the Data
#Latitude vs Temperature Plot
plt.scatter(city_df["Lat"], city_df["Max Temp"], alpha = .75, 
            edgecolors = "black", label = "Cities", linewidths = 1)
#Add supplemental information
#plt.title("City Latitude vs Max Temperature")
plt.xlabel("Latitude")
plt.ylabel("Temperature (F)")
plt.grid(color = "grey")
plt.show
77/35:
#Plotting the Data
#Latitude vs Temperature Plot
plt.scatter(city_df["Lat"], city_df["Max Temp"], alpha = .75, 
            edgecolors = "black", label = "Cities", linewidths = 1)
#Add supplemental information
#plt.title("City Latitude vs Max Temperature")
plt.title("City Latitude vs. Max Temperature (%s)" % time.strftime("%x"))
plt.xlabel("Latitude")
plt.ylabel("Temperature (F)")
plt.grid(color = "grey")
plt.show
77/36:
#Plotting the Data
#Latitude vs Temperature Plot
plt.scatter(city_df["Lat"], city_df["Max Temp"], alpha = .75, 
            edgecolors = "black", label = "Cities", linewidths = 1)
#Add supplemental information
#plt.title("City Latitude vs Max Temperature")
plt.xlabel("Latitude")
plt.ylabel("Temperature (F)")
plt.grid(color = "grey")

plt.savefig("lat_vs_temp.png")
plt.show
77/37:
#Plotting the Data
#Latitude vs Temperature Plot
plt.scatter(cleaned_city_df["Lat"], cleaned_city_df["Max Temp"], alpha = .75, 
            edgecolors = "black", label = "Cities", linewidths = 1)
#Add supplemental information
#plt.title("City Latitude vs Max Temperature")
plt.xlabel("Latitude")
plt.ylabel("Temperature (F)")
plt.grid(color = "grey")

plt.savefig("lat_vs_temp.png")
plt.show
77/38:
# Inspect the data and remove the cities where the humidity > 100%.
clean_city_df = city_df.loc[(city_df["Humidity"] < 100), :]

#There was 536 rows now there is 532 meaning 4 rows had humidity above 100
77/39:
#Plotting the Data
#Latitude vs Temperature Plot
plt.scatter(cleaned_city_df["Lat"], cleaned_city_df["Max Temp"], alpha = .75, 
            edgecolors = "black", label = "Cities", linewidths = 1)
#Add supplemental information
#plt.title("City Latitude vs Max Temperature")
plt.xlabel("Latitude")
plt.ylabel("Temperature (F)")
plt.grid(color = "grey")

plt.savefig("lat_vs_temp.png")
plt.show
77/40:
# Inspect the data and remove the cities where the humidity > 100%.
cleaned_city_df = city_df.loc[(city_df["Humidity"] < 100), :]

#There was 536 rows now there is 532 meaning 4 rows had humidity above 100
77/41:
#Plotting the Data
#Latitude vs Temperature Plot
plt.scatter(cleaned_city_df["Lat"], cleaned_city_df["Max Temp"], alpha = .75, 
            edgecolors = "black", label = "Cities", linewidths = 1)
#Add supplemental information
#plt.title("City Latitude vs Max Temperature")
plt.xlabel("Latitude")
plt.ylabel("Temperature (F)")
plt.grid(color = "grey")

plt.savefig("lat_vs_temp.png")
plt.show
77/42:
# Latitude vs. Humidity Plot
plt.scatter(cleaned_city_df["Lat"], cleaned_city_df["Humidity"])
77/43:
# Latitude vs. Humidity Plot
plt.scatter(cleaned_city_df["Lat"], cleaned_city_df["Humidity"], alpha = .75,
           edgecolors = "black", label = "Cities", linewidths = 1)
77/44:
# Latitude vs. Humidity Plot
plt.scatter(cleaned_city_df["Lat"], cleaned_city_df["Humidity"], alpha = .75,
           edgecolors = "black", label = "Cities", linewidths = 1)
plt.title("Latitude vs. Humidity Plot")
77/45:
# Latitude vs. Humidity Plot
plt.scatter(cleaned_city_df["Lat"], cleaned_city_df["Humidity"], alpha = .75,
           edgecolors = "black", label = "Cities", linewidths = 1)
#plt.title("Latitude vs. Humidity Plot")
plt.xlabel("Latitude")
plt.ylabel("Humidity")
plt.grid(color = "grey")
77/46:
# Latitude vs. Humidity Plot
plt.scatter(cleaned_city_df["Lat"], cleaned_city_df["Humidity"], alpha = .75,
           edgecolors = "black", label = "Cities", linewidths = 1)
#plt.title("Latitude vs. Humidity Plot")
plt.xlabel("Latitude")
plt.ylabel("Humidity")
plt.grid(color = "grey")

plt.savefig("lat_vs_humidity.png")
plt.show
77/47:
# Latitude vs. Cloudiness Plot
plt.scatter(cleaned_city_df["Lat"], cleaned_city_df["Cloudiness"], alpha = .75,
           edgecolors = "black", label = "Cities", linewidths = 1)
77/48:
# Latitude vs. Cloudiness Plot
plt.scatter(cleaned_city_df["Lat"], cleaned_city_df["Cloudiness"], alpha = .75,
           edgecolors = "black", label = "Cities", linewidths = 1)
plt.title("Latitude vs. Cloudiness Plot")
plt.xlabel("Latitude")
plt.ylabel("Cloudiness Plot")
77/49:
# Latitude vs. Cloudiness Plot
plt.scatter(cleaned_city_df["Lat"], cleaned_city_df["Cloudiness"], alpha = .75,
           edgecolors = "black", label = "Cities", linewidths = 1)
#plt.title("Latitude vs. Cloudiness Plot")
plt.xlabel("Latitude")
plt.ylabel("Cloudiness Plot")
77/50:
# Latitude vs. Cloudiness Plot
plt.scatter(cleaned_city_df["Lat"], cleaned_city_df["Cloudiness"], alpha = .75,
           edgecolors = "black", label = "Cities", linewidths = 1)
#plt.title("Latitude vs. Cloudiness Plot")
plt.xlabel("Latitude")
plt.ylabel("Cloudiness Plot")
plt.grid(color="grey")
77/51:
# Latitude vs. Cloudiness Plot
plt.scatter(cleaned_city_df["Lat"], cleaned_city_df["Cloudiness"], alpha = .75,
           edgecolors = "black", label = "Cities", linewidths = 1)
#plt.title("Latitude vs. Cloudiness Plot")
plt.xlabel("Latitude")
plt.ylabel("Cloudiness Plot")
plt.grid(color="grey")

plt.savefig("lat_vs_cloudines.png")

plt.show()
77/52:
#Latitude vs. Wind Speed Plot
plt.scatter(cleaned_city_df["Lat"], cleaned_city_df["Wind Speed"], alpha = .75,
           edgecolors = "black", label = "Cities", linewidths = 1)
77/53:
#Latitude vs. Wind Speed Plot
plt.scatter(cleaned_city_df["Lat"], cleaned_city_df["Wind Speed"], alpha = .75,
           edgecolors = "black", label = "Cities", linewidths = 1)
#plt.title("Latitude vs. Wind Speed")
plt.xlabel("Latitude")
plt.ylabel("Wind Speed")
plt.savefig("lat_vs_windspeed.png")
plt.show()
77/54:
#Latitude vs. Wind Speed Plot
plt.scatter(cleaned_city_df["Lat"], cleaned_city_df["Wind Speed"], alpha = .75,
           edgecolors = "black", label = "Cities", linewidths = 1)
#plt.title("Latitude vs. Wind Speed")
plt.xlabel("Latitude")
plt.ylabel("Wind Speed")
plt.grid(color="grey")
plt.savefig("lat_vs_windspeed.png")
plt.show()
77/55:
# Linear Regression
#Create two dataframes for north and south hemisphere
77/56:
# Linear Regression
#Create two dataframes for north and south hemisphere
northern_df = cleaned_city_df.loc(cleaned_city_df["Lat"] >= 0)
southern_df = cleaned_city_df.loc(cleaned_city_df["Lat"] < 0)
77/57:
# Linear Regression
#Create two dataframes for north and south hemisphere
northern_df = cleaned_city_df.loc(cleaned_city_df["Lat"] => 0)
southern_df = cleaned_city_df.loc(cleaned_city_df["Lat"] < 0)
77/58:
# Linear Regression
#Create two dataframes for north and south hemisphere
northern_df = cleaned_city_df.loc[(cleaned_city_df["Lat"] => 0)]
southern_df = cleaned_city_df.loc[(cleaned_city_df["Lat"] < 0)]
77/59:
# Linear Regression
#Create two dataframes for north and south hemisphere
northern_df = cleaned_city_df.loc[(cleaned_city_df["Lat"] >= 0)]
southern_df = cleaned_city_df.loc[(cleaned_city_df["Lat"] < 0)]
77/60:
#Northern Hemisphere - Max Temp vs. Latitude Linear Regression
linregress(northern_df["Lat"], northern_df["Max Temp"])
77/61:
#Northern Hemisphere - Max Temp vs. Latitude Linear Regression
linregress(northern_df["Lat"], northern_df["Max Temp"])

#now plot scatter plot plus linear regression
plt.scatter(northern_df["Lat"], northern_df["Max Temp"], alpha = .75,
           edgecolors = "black", label = "Cities", linewidths = 1)
#plt.title("Latitude vs. Max Temp")
plt.xlabel("Latitude")
plt.ylabel("Max Temp")
plt.grid(color="grey")
#plt.savefig("lat_vs_windspeed.png")
plt.show()
77/62:
#Northern Hemisphere - Max Temp vs. Latitude Linear Regression
linregress(northern_df["Lat"], northern_df["Max Temp"])

#now plot scatter plot plus linear regression
plt.scatter(northern_df["Lat"], northern_df["Max Temp"], colors = "blue" alpha = .75,
           edgecolors = "black", linewidths = 1)
#plt.title("Latitude vs. Max Temp")
plt.xlabel("Latitude")
plt.ylabel("Max Temp")
#plt.savefig("lat_vs_windspeed.png")
plt.show()
77/63:
#Northern Hemisphere - Max Temp vs. Latitude Linear Regression
linregress(northern_df["Lat"], northern_df["Max Temp"])

#now plot scatter plot plus linear regression
plt.scatter(northern_df["Lat"], northern_df["Max Temp"], colors = "blue", alpha = .75,
           edgecolors = "black", linewidths = 1)
#plt.title("Latitude vs. Max Temp")
plt.xlabel("Latitude")
plt.ylabel("Max Temp")
#plt.savefig("lat_vs_windspeed.png")
plt.show()
77/64:
#Northern Hemisphere - Max Temp vs. Latitude Linear Regression
linregress(northern_df["Lat"], northern_df["Max Temp"])

#now plot scatter plot plus linear regression
plt.scatter(northern_df["Lat"], northern_df["Max Temp"], alpha = .75,
           edgecolors = "black", linewidths = 1)
#plt.title("Latitude vs. Max Temp")
plt.xlabel("Latitude")
plt.ylabel("Max Temp")
#plt.savefig("lat_vs_windspeed.png")
plt.show()
77/65:
#Northern Hemisphere - Max Temp vs. Latitude Linear Regression
linregress(northern_df["Lat"], northern_df["Max Temp"])

#now plot scatter plot plus linear regression
plt.scatter(northern_df["Lat"], northern_df["Max Temp"], c = "blue", alpha = .75,
           edgecolors = "black", linewidths = 1)
#plt.title("Latitude vs. Max Temp")
plt.xlabel("Latitude")
plt.ylabel("Max Temp")
#plt.savefig("lat_vs_windspeed.png")
plt.show()
77/66:
#Northern Hemisphere - Max Temp vs. Latitude Linear Regression
linregress(northern_df["Lat"], northern_df["Max Temp"])

#now plot scatter plot plus linear regression
plt.scatter(northern_df["Lat"], northern_df["Max Temp"], c = "light blue", alpha = .75,
           edgecolors = "black", linewidths = 1)
#plt.title("Latitude vs. Max Temp")
plt.xlabel("Latitude")
plt.ylabel("Max Temp")
#plt.savefig("lat_vs_windspeed.png")
plt.show()
77/67:
#Northern Hemisphere - Max Temp vs. Latitude Linear Regression
linregress(northern_df["Lat"], northern_df["Max Temp"])

#now plot scatter plot plus linear regression
plt.scatter(northern_df["Lat"], northern_df["Max Temp"], c = "blue", alpha = .75,
           edgecolors = "black", linewidths = 1)
#plt.title("Latitude vs. Max Temp")
plt.xlabel("Latitude")
plt.ylabel("Max Temp")
#plt.savefig("lat_vs_windspeed.png")
plt.show()
77/68:
#Northern Hemisphere - Max Temp vs. Latitude Linear Regression
linregress(northern_df["Lat"], northern_df["Max Temp"])

#now plot scatter plot plus linear regression
plt.scatter(northern_df["Lat"], northern_df["Max Temp"], c = "blue", alpha = .75,
           edgecolors = "black", linewidths = 1)

#obtain m (slope) and b(intercept) of linear regression
m, b = np.polyfit(northern_df["Lat"], northern_df["Max Temp"], 1)

#add linear regression line to scatterplot
plt.plot(northern_df["Lat"], m*northern_df["Lat"]+b)

#plt.title("Latitude vs. Max Temp")
plt.xlabel("Latitude")
plt.ylabel("Max Temp")
#plt.savefig("lat_vs_windspeed.png")
plt.show()
77/69:
#Northern Hemisphere - Max Temp vs. Latitude Linear Regression
linregress(northern_df["Lat"], northern_df["Max Temp"])

#now plot scatter plot plus linear regression
plt.scatter(northern_df["Lat"], northern_df["Max Temp"], c = "blue", alpha = .75,
           edgecolors = "black", linewidths = 1)

#obtain m (slope) and b(intercept) of linear regression
m, b = np.polyfit(northern_df["Lat"], northern_df["Max Temp"], 1)

#add linear regression line to scatterplot
plt.plot(northern_df["Lat"], m*northern_df["Lat"]+b, c = r)

#plt.title("Latitude vs. Max Temp")
plt.xlabel("Latitude")
plt.ylabel("Max Temp")
#plt.savefig("lat_vs_windspeed.png")
plt.show()
77/70:
#Northern Hemisphere - Max Temp vs. Latitude Linear Regression
linregress(northern_df["Lat"], northern_df["Max Temp"])

#now plot scatter plot plus linear regression
plt.scatter(northern_df["Lat"], northern_df["Max Temp"], c = "blue", alpha = .75,
           edgecolors = "black", linewidths = 1)

#obtain m (slope) and b(intercept) of linear regression
m, b = np.polyfit(northern_df["Lat"], northern_df["Max Temp"], 1)

#add linear regression line to scatterplot
plt.plot(northern_df["Lat"], m*northern_df["Lat"]+b, c = "r")

#plt.title("Latitude vs. Max Temp")
plt.xlabel("Latitude")
plt.ylabel("Max Temp")
#plt.savefig("lat_vs_windspeed.png")
plt.show()
77/71: linregress(northern_df["Lat"], northern_df["Max Temp"])
77/72:
#Northern Hemisphere - Max Temp vs. Latitude Linear Regression
linregress(northern_df["Lat"], northern_df["Max Temp"])

#now plot scatter plot plus linear regression
plt.scatter(northern_df["Lat"], northern_df["Max Temp"], c = "blue", alpha = .75,
           edgecolors = "black", linewidths = 1)

#obtain m (slope) and b(intercept) of linear regression
#m, b = np.polyfit(northern_df["Lat"], northern_df["Max Temp"], 1)

#add linear regression line to scatterplot
#plt.plot(northern_df["Lat"], m*northern_df["Lat"]+b, c = "r")
plt.plot(northern_df["Lat"], res.intercept + res.slope*northern_df["Lat"], 'r', label='fitted line')

#plt.title("Latitude vs. Max Temp")
plt.xlabel("Latitude")
plt.ylabel("Max Temp")
#plt.savefig("lat_vs_windspeed.png")
plt.show()
77/73:
#Northern Hemisphere - Max Temp vs. Latitude Linear Regression
res = linregress(northern_df["Lat"], northern_df["Max Temp"])

#now plot scatter plot plus linear regression
plt.scatter(northern_df["Lat"], northern_df["Max Temp"], c = "blue", alpha = .75,
           edgecolors = "black", linewidths = 1)

#obtain m (slope) and b(intercept) of linear regression
#m, b = np.polyfit(northern_df["Lat"], northern_df["Max Temp"], 1)

#add linear regression line to scatterplot
#plt.plot(northern_df["Lat"], m*northern_df["Lat"]+b, c = "r")
plt.plot(northern_df["Lat"], res.intercept + res.slope*northern_df["Lat"], 'r', label='fitted line')

#plt.title("Latitude vs. Max Temp")
plt.xlabel("Latitude")
plt.ylabel("Max Temp")
#plt.savefig("lat_vs_windspeed.png")
plt.show()
77/74:
#Northern Hemisphere - Max Temp vs. Latitude Linear Regression
res = linregress(northern_df["Lat"], northern_df["Max Temp"])

#now plot scatter plot plus linear regression
plt.scatter(northern_df["Lat"], northern_df["Max Temp"], c = "blue", alpha = .75,
           edgecolors = "black", linewidths = 1)

#obtain m (slope) and b(intercept) of linear regression
#m, b = np.polyfit(northern_df["Lat"], northern_df["Max Temp"], 1)

#add linear regression line to scatterplot
#plt.plot(northern_df["Lat"], m*northern_df["Lat"]+b, c = "r")
plt.plot(northern_df["Lat"], res.intercept + res.slope*northern_df["Lat"], 'r', label='fitted line')

#plt.title("Latitude vs. Max Temp")
plt.xlabel("Latitude")
plt.ylabel("Max Temp")
plt.legend
#plt.savefig("lat_vs_windspeed.png")
plt.show()
77/75:
#Northern Hemisphere - Max Temp vs. Latitude Linear Regression
res = linregress(northern_df["Lat"], northern_df["Max Temp"])

#now plot scatter plot plus linear regression
plt.scatter(northern_df["Lat"], northern_df["Max Temp"], c = "blue", alpha = .75,
           edgecolors = "black", linewidths = 1)

#obtain m (slope) and b(intercept) of linear regression
#m, b = np.polyfit(northern_df["Lat"], northern_df["Max Temp"], 1)

#add linear regression line to scatterplot
#plt.plot(northern_df["Lat"], m*northern_df["Lat"]+b, c = "r")
plt.plot(northern_df["Lat"], res.intercept + res.slope*northern_df["Lat"], 'r', label='fitted line')

#plt.title("Latitude vs. Max Temp")
plt.xlabel("Latitude")
plt.ylabel("Max Temp")
plt.legend()
#plt.savefig("lat_vs_windspeed.png")
plt.show()
77/76:
#Northern Hemisphere - Max Temp vs. Latitude Linear Regression
res = linregress(northern_df["Lat"], northern_df["Max Temp"])

#now plot scatter plot plus linear regression
plt.scatter(northern_df["Lat"], northern_df["Max Temp"], c = "blue", alpha = .75,
           edgecolors = "black", linewidths = 1)

#add linear regression line to scatterplot
plt.plot(northern_df["Lat"], res.intercept + res.slope*northern_df["Lat"], 'r', label='fitted line')

#plt.title("Latitude vs. Max Temp")
plt.xlabel("Latitude")
plt.ylabel("Max Temp")
plt.legend()
print(f"The r-value is: {res.rvalue**2})
plt.show()
77/77:
#Northern Hemisphere - Max Temp vs. Latitude Linear Regression
res = linregress(northern_df["Lat"], northern_df["Max Temp"])

#now plot scatter plot plus linear regression
plt.scatter(northern_df["Lat"], northern_df["Max Temp"], c = "blue", alpha = .75,
           edgecolors = "black", linewidths = 1)

#add linear regression line to scatterplot
plt.plot(northern_df["Lat"], res.intercept + res.slope*northern_df["Lat"], 'r', label='fitted line')

#plt.title("Latitude vs. Max Temp")
plt.xlabel("Latitude")
plt.ylabel("Max Temp")
plt.legend()
print(f"The r-value is: {res.rvalue**2}"")
plt.show()
77/78:
#Northern Hemisphere - Max Temp vs. Latitude Linear Regression
res = linregress(northern_df["Lat"], northern_df["Max Temp"])

#now plot scatter plot plus linear regression
plt.scatter(northern_df["Lat"], northern_df["Max Temp"], c = "blue", alpha = .75,
           edgecolors = "black", linewidths = 1)

#add linear regression line to scatterplot
plt.plot(northern_df["Lat"], res.intercept + res.slope*northern_df["Lat"], 'r', label='fitted line')

#plt.title("Latitude vs. Max Temp")
plt.xlabel("Latitude")
plt.ylabel("Max Temp")
plt.legend()
print(f"The r-value is: {res.rvalue**2}")
plt.show()
77/79:
#Southern Hemisphere - Max Temp vs. Latitude Linear Regression
res2 = linregress(southern_df["Lat"], southern_df["Max Temp"])

#now plot scatter plot plus linear regression
plt.scatter(southern_df["Lat"], southern_df["Max Temp"], c = "blue", alpha = .75,
           edgecolors = "black", linewidths = 1)

#add linear regression line to scatterplot
plt.plot(southern_df["Lat"], res.intercept + res.slope*southern_df["Lat"], 'r', label='fitted line')

#plt.title("Latitude vs. Max Temp")
plt.xlabel("Latitude")
plt.ylabel("Max Temp")
plt.legend()
print(f"The r-value is: {res2.rvalue**2}")
plt.show()
77/80:
#Southern Hemisphere - Max Temp vs. Latitude Linear Regression
res2 = linregress(southern_df["Lat"], southern_df["Max Temp"])

#now plot scatter plot plus linear regression
plt.scatter(southern_df["Lat"], southern_df["Max Temp"], c = "blue", alpha = .75,
           edgecolors = "black", linewidths = 1)

#add linear regression line to scatterplot
plt.plot(southern_df["Lat"], res2.intercept + res2.slope*southern_df["Lat"], 'r', label='fitted line')

#plt.title("Latitude vs. Max Temp")
plt.xlabel("Latitude")
plt.ylabel("Max Temp")
plt.legend()
print(f"The r-value is: {res2.rvalue**2}")
plt.show()
77/81:
#Northern Hemisphere - Humidity (%) vs. Latitude Linear Regression
res3 = linregress(northern_df["Lat"], northern_df["Humidity"])

#now plot scatter plot plus linear regression
plt.scatter(northern_df["Lat"], northern_df["Humidity"], c = "blue", alpha = .75,
           edgecolors = "black", linewidths = 1)

#add linear regression line to scatterplot
plt.plot(northern_df["Lat"], res3.intercept + res3.slope*northern_df["Lat"], 'r', label='fitted line')

#plt.title("Latitude vs. Max Temp")
plt.xlabel("Latitude")
plt.ylabel("Humidity")
plt.legend()
print(f"The r-value is: {res3.rvalue**2}")
plt.show()
77/82:
# Southern Hemisphere - Humidity (%) vs. Latitude Linear Regression
res4 = linregress(southern_df["Lat"], southern_df["Humidity"])

#now plot scatter plot plus linear regression
plt.scatter(southern_df["Lat"], southern_df["Humidity"], c = "blue", alpha = .75,
           edgecolors = "black", linewidths = 1)

#add linear regression line to scatterplot
plt.plot(southern_df["Lat"], res4.intercept + res4.slope*southern_df["Lat"], 'r', label='fitted line')

#plt.title("Latitude vs. Humidity")
plt.xlabel("Latitude")
plt.ylabel("Humidity")
plt.legend()
print(f"The r-value is: {res4.rvalue**2}")
plt.show()
77/83:
#Northern Hemisphere - Cloudiness (%) vs. Latitude Linear Regression
res5 = linregress(northern_df["Lat"], northern_df["Cloudiness"])

#now plot scatter plot plus linear regression
plt.scatter(northern_df["Lat"], northern_df["Cloudiness"], c = "blue", alpha = .75,
           edgecolors = "black", linewidths = 1)

#add linear regression line to scatterplot
plt.plot(northern_df["Lat"], res5.intercept + res5.slope*northern_df["Lat"], 'r', label='fitted line')

#plt.title("Latitude vs. Cloudiness")
plt.xlabel("Latitude")
plt.ylabel("Cloudiness")
plt.legend()
print(f"The r-value is: {res5.rvalue**2}")
plt.show()
77/84:
#Southern Hemisphere - Cloudiness (%) vs. Latitude Linear Regression
res6 = linregress(southern_df["Lat"], southern_df["Cloudiness"])

#now plot scatter plot plus linear regression
plt.scatter(southern_df["Lat"], southern_df["Cloudiness"], c = "blue", alpha = .75,
           edgecolors = "black", linewidths = 1)

#add linear regression line to scatterplot
plt.plot(southern_df["Lat"], res6.intercept + res6.slope*southern_df["Lat"], 'r', label='fitted line')

#plt.title("Latitude vs. Cloudiness")
plt.xlabel("Latitude")
plt.ylabel("Cloudiness")
plt.legend()
print(f"The r-value is: {res6.rvalue**2}")
plt.show()
77/85: #Northern Hemisphere - Wind Speed (mph) vs. Latitude Linear Regression
77/86:
#Northern Hemisphere - Wind Speed (mph) vs. Latitude Linear Regression
res7 = linregress(northern_df["Lat"], northern_df["Wind Speed"])

#now plot scatter plot plus linear regression
plt.scatter(northern_df["Lat"], northern_df["Wind Speed"], c = "blue", alpha = .75,
           edgecolors = "black", linewidths = 1)

#add linear regression line to scatterplot
plt.plot(northern_df["Lat"], res7.intercept + res7.slope*northern_df["Lat"], 'r', label='fitted line')

#plt.title("Latitude vs. Wind Speed")
plt.xlabel("Latitude")
plt.ylabel("Wind Speed")
plt.legend()
print(f"The r-value is: {res7.rvalue**2}")
plt.show()
77/87:
# Southern Hemisphere - Wind Speed (mph) vs. Latitude Linear Regression
res8 = linregress(southern_df["Lat"], southern_df["Wind Speed"])

#now plot scatter plot plus linear regression
plt.scatter(southern_df["Lat"], southern_df["Wind Speed"], c = "blue", alpha = .75,
           edgecolors = "black", linewidths = 1)

#add linear regression line to scatterplot
plt.plot(southern_df["Lat"], res8.intercept + res8.slope*southern_df["Lat"], 'r', label='fitted line')

#plt.title("Latitude vs. Wind Speed")
plt.xlabel("Latitude")
plt.ylabel("Wind Speed")
plt.legend()
print(f"The r-value is: {res8.rvalue**2}")
plt.show()
77/88:
#Southern Hemisphere - Max Temp vs. Latitude Linear Regression
res2 = linregress(southern_df["Lat"], southern_df["Max Temp"])

#now plot scatter plot plus linear regression
plt.scatter(southern_df["Lat"], southern_df["Max Temp"], c = "blue", alpha = .75,
           edgecolors = "black", linewidths = 1)

#add linear regression line to scatterplot
plt.plot(southern_df["Lat"], res2.intercept + res2.slope*southern_df["Lat"], 'r', label='fitted line')

#plt.title("Latitude vs. Max Temp")
plt.xlabel("Latitude")
plt.ylabel("Max Temp")
plt.legend()
print(f"The r-value is: {res2.rvalue**2}")
plt.show()
print("Since the r-value is above .05 there is a moderate correlation between latitude and max temperature in the southern hemisphere.")
77/89:
#Northern Hemisphere - Humidity (%) vs. Latitude Linear Regression
res3 = linregress(northern_df["Lat"], northern_df["Humidity"])

#now plot scatter plot plus linear regression
plt.scatter(northern_df["Lat"], northern_df["Humidity"], c = "blue", alpha = .75,
           edgecolors = "black", linewidths = 1)

#add linear regression line to scatterplot
plt.plot(northern_df["Lat"], res3.intercept + res3.slope*northern_df["Lat"], 'r', label='fitted line')

#plt.title("Latitude vs. Max Temp")
plt.xlabel("Latitude")
plt.ylabel("Humidity")
plt.legend()
print(f"The r-value is: {res3.rvalue**2}")
plt.show()
print("Since there is a low r-value there is a small to no correlation between a cities latitiude and humidity.")
77/90:
#Southern Hemisphere - Cloudiness (%) vs. Latitude Linear Regression
res6 = linregress(southern_df["Lat"], southern_df["Cloudiness"])

#now plot scatter plot plus linear regression
plt.scatter(southern_df["Lat"], southern_df["Cloudiness"], c = "blue", alpha = .75,
           edgecolors = "black", linewidths = 1)

#add linear regression line to scatterplot
plt.plot(southern_df["Lat"], res6.intercept + res6.slope*southern_df["Lat"], 'r', label='fitted line')

#plt.title("Latitude vs. Cloudiness")
plt.xlabel("Latitude")
plt.ylabel("Cloudiness")
plt.legend()
print(f"The r-value is: {res6.rvalue**2}")
plt.show()
print("Since there is a low r-value there is a small to no correlation between a cities latitiude and couldiness in either the north or south hemisphere.")
77/91:
#Northern Hemisphere - Wind Speed (mph) vs. Latitude Linear Regression
res7 = linregress(northern_df["Lat"], northern_df["Wind Speed"])

#now plot scatter plot plus linear regression
plt.scatter(northern_df["Lat"], northern_df["Wind Speed"], c = "blue", alpha = .75,
           edgecolors = "black", linewidths = 1)

#add linear regression line to scatterplot
plt.plot(northern_df["Lat"], res7.intercept + res7.slope*northern_df["Lat"], 'r', label='fitted line')

#plt.title("Latitude vs. Wind Speed")
plt.xlabel("Latitude")
plt.ylabel("Wind Speed")
plt.legend()
print(f"The r-value is: {res7.rvalue**2}")
plt.show()
print("In the northern hemisphere there is a strong correlation between the latitude of a city and its wind speed because the r-value is above 1.")
77/92:
# Southern Hemisphere - Wind Speed (mph) vs. Latitude Linear Regression
res8 = linregress(southern_df["Lat"], southern_df["Wind Speed"])

#now plot scatter plot plus linear regression
plt.scatter(southern_df["Lat"], southern_df["Wind Speed"], c = "blue", alpha = .75,
           edgecolors = "black", linewidths = 1)

#add linear regression line to scatterplot
plt.plot(southern_df["Lat"], res8.intercept + res8.slope*southern_df["Lat"], 'r', label='fitted line')

#plt.title("Latitude vs. Wind Speed")
plt.xlabel("Latitude")
plt.ylabel("Wind Speed")
plt.legend()
print(f"The r-value is: {res8.rvalue**2}")
plt.show()
print("In the southern hemisphere there is a small to no correlation between the latitude of a city and its wind speed because the r-value is close to zero.")
77/93:
#Plotting the Data
#Latitude vs Temperature Plot
plt.scatter(cleaned_city_df["Lat"], cleaned_city_df["Max Temp"], alpha = .75, 
            edgecolors = "black", label = "Cities", linewidths = 1)
#Add supplemental information
#plt.title("City Latitude vs Max Temperature")
plt.xlabel("Latitude")
plt.ylabel("Temperature (F)")
plt.grid(color = "grey")

plt.savefig("lat_vs_temp.png")
plt.show
print("This plot is determining the correlation between the latitude of a city and the cities max temperature.")
77/94:
# Latitude vs. Humidity Plot
plt.scatter(cleaned_city_df["Lat"], cleaned_city_df["Humidity"], alpha = .75,
           edgecolors = "black", label = "Cities", linewidths = 1)
#plt.title("Latitude vs. Humidity Plot")
plt.xlabel("Latitude")
plt.ylabel("Humidity")
plt.grid(color = "grey")

plt.savefig("lat_vs_humidity.png")
plt.show
print("This plot is determining the correlation between the latitude of a city and the cities humidity.")
77/95:
# Latitude vs. Cloudiness Plot
plt.scatter(cleaned_city_df["Lat"], cleaned_city_df["Cloudiness"], alpha = .75,
           edgecolors = "black", label = "Cities", linewidths = 1)
#plt.title("Latitude vs. Cloudiness Plot")
plt.xlabel("Latitude")
plt.ylabel("Cloudiness Plot")
plt.grid(color="grey")

plt.savefig("lat_vs_cloudines.png")

plt.show()
print("This plot is determining the correlation between the latitude of a city and the cities cloudiness.")
77/96:
#Latitude vs. Wind Speed Plot
plt.scatter(cleaned_city_df["Lat"], cleaned_city_df["Wind Speed"], alpha = .75,
           edgecolors = "black", label = "Cities", linewidths = 1)
#plt.title("Latitude vs. Wind Speed")
plt.xlabel("Latitude")
plt.ylabel("Wind Speed")
plt.grid(color="grey")
plt.savefig("lat_vs_windspeed.png")
plt.show()
print("This plot is determining the correlation between the latitude of a city and the cities wind speed.")
77/97:
#Create dataframe from city_data
city_df = pd.DataFrame(data = city_data)
city_df.head()

#create a csv file of this newly formed data frame
city_df.to_csv("city_weather.csv")
78/1:
# Dependencies and Setup
import matplotlib.pyplot as plt
import pandas as pd
import numpy as np
import requests
import time
from scipy.stats import linregress
78/2:
csv_file_path = "/Users/Jerry/Documents/city_weather.csv"
pd.read_csv(csv_file_path)
78/3:
csv_file_path = "/Users/Jerry/Documents/city_weather.csv"
pd.read_csv(csv_file_path, index = True)
78/4:
csv_file_path = "/Users/Jerry/Documents/city_weather.csv"
pd.read_csv(csv_file_path)
78/5:
csv_file_path = "/Users/Jerry/Documents/city_weather.csv"
cities_df = pd.read_csv(csv_file_path)
78/6: cities_df.head()
78/7:
#Narrow down the DataFrame to find your ideal weather condition. For example:
#A max temperature lower than 80 degrees but higher than 70.
#Wind speed less than 10 mph.
#Zero cloudiness.
#Drop any rows that don't satisfy all three conditions. You want to be sure the weather is ideal.

vaction_df = cities_df.loc[(cities_df["Max Temp"] >= 70 ) &
                           (cities_df["Max Temp"] < 70 ), :]
78/8:
#Narrow down the DataFrame to find your ideal weather condition. For example:
#A max temperature lower than 80 degrees but higher than 70.
vaction_df = cities_df.loc[(cities_df["Max Temp"] >= 70 ) &
                           (cities_df["Max Temp"] < 70 ), :]

#Wind speed less than 10 mph.
vaction_df = vaction_df.loc[(vaction_df["Wind Speed"] < 10), :]
#Zero cloudiness.
#Drop any rows that don't satisfy all three conditions. You want to be sure the weather is ideal.
78/9:
#Narrow down the DataFrame to find your ideal weather condition. For example:
#A max temperature lower than 80 degrees but higher than 70.
vaction_df = cities_df.loc[(cities_df["Max Temp"] >= 70 ) &
                           (cities_df["Max Temp"] < 70 ), :]

#Wind speed less than 10 mph.
vaction_df = vaction_df.loc[(vaction_df["Wind Speed"] < 10), :]

#Zero cloudiness.
vaction_df = vaction_df.loc[(vaction_df["Cloudiness"] == 0), :]
                             
#Drop any rows that don't satisfy all three conditions. You want to be sure the weather is ideal.
78/10:
#Narrow down the DataFrame to find your ideal weather condition. For example:
#Drop any rows that don't satisfy all three conditions. You want to be sure the weather is ideal.
#A max temperature lower than 80 degrees but higher than 70.
vaction_df = cities_df.loc[(cities_df["Max Temp"] >= 70 ) &
                           (cities_df["Max Temp"] < 80 ), :]

#Wind speed less than 10 mph.
vaction_df = vaction_df.loc[(vaction_df["Wind Speed"] < 10), :]

#Zero cloudiness.
vaction_df = vaction_df.loc[(vaction_df["Cloudiness"] == 0), :]
                             
#Drop any rows that don't satisfy all three conditions. You want to be sure the weather is ideal.
78/11: vaction_df.head()
78/12: vaction_df.count()
78/13: len(vaction_df["City"])
78/14: vaction_df.head()
78/15: vaction_df
78/16:
#Narrow down the DataFrame to find your ideal weather condition. For example:
#Drop any rows that don't satisfy all three conditions. You want to be sure the weather is ideal.
#A max temperature lower than 80 degrees but higher than 70.
vaction_df = cities_df.loc[(cities_df["Max Temp"] >= 70 ) &
                           (cities_df["Max Temp"] < 90 ), :]

#Wind speed less than 10 mph.
vaction_df = vaction_df.loc[(vaction_df["Wind Speed"] < 10), :]

#Zero cloudiness.
vaction_df = vaction_df.loc[(vaction_df["Cloudiness"] == 0), :]
                             
#Drop any rows that don't satisfy all three conditions. You want to be sure the weather is ideal.
78/17: vaction_df
78/18:
#Narrow down the DataFrame to find your ideal weather condition. For example:
#Drop any rows that don't satisfy all three conditions. You want to be sure the weather is ideal.
#A max temperature lower than 80 degrees but higher than 70.
vaction_df = cities_df.loc[(cities_df["Max Temp"] >= 70 ) &
                           (cities_df["Max Temp"] < 90 ), :]

#Wind speed less than 10 mph.
vaction_df = vaction_df.loc[(vaction_df["Wind Speed"] < 10), :]

#Zero cloudiness.
vaction_df = vaction_df.loc[(vaction_df["Cloudiness"] == 0), :]

#Humidity is less than 70
vaction_df = vaction_df.loc[(vaction_df["Humidity"] < 70), :]
78/19: vaction_df
78/20: len(vaction_df["City"])
78/21: vaction_df
78/22:
# Dependencies and Setup
import matplotlib.pyplot as plt
import pandas as pd
import numpy as np
import requests
import time
from scipy.stats import linregress

from api_keys import g_key
78/23: jupyter nbextension enable --py gmaps
78/24:
#configure gmaps
gmaps.configure(api_key=g_key)
80/1:
#import dependencies
import pandas as pd
from datetime import datetime
80/2:
csv_file = "/Users/Jerry/Documents/US_Accidents_Dec21_updated.csv"
accidents_df = pd.read_csv(csv_file)
80/3:
#A data frame with only CA and AZ data
cal_ari = accidents_df.loc[(accidents_df["State"] == "CA") |
                          (accidents_df["State"] == "AZ"), :]
80/4:
#Our data frame with only CA data
cali_df = accidents_df.loc[(accidents_df["State"] == "CA"), :]
80/5:
cleaned_df = cali_df[['ID', 'Severity', 'Start_Time', 'Start_Lat', 'Start_Lng', 'Description',
                      'City', 'County', 'State', 'Zipcode', 'Country', 'Timezone',
                      'Weather_Timestamp', 'Temperature(F)', 'Wind_Chill(F)', 'Humidity(%)',
                      'Pressure(in)', 'Visibility(mi)', 'Wind_Direction', 'Wind_Speed(mph)', 
                      'Precipitation(in)', 'Weather_Condition', 'Crossing', 'Junction', 
                      'No_Exit', 'Station', 'Stop', 'Traffic_Signal', 'Sunrise_Sunset']]
80/6:
#Our Main df with only CA data and neccessary columns
cleaned_df.head()
80/7:
#10 days before late oct early nov
#10 days after late feb early march
cleaned_df[["date", "time"]] = cleaned_df["Start_Time"].str.split(" ", expand = True)
80/8: cleaned_df[["year", "month", "day"]] = cleaned_df["date"].str.split("-", expand = True)
80/9:
cleaned_df[["year", "month", "day"]] = cleaned_df[["year", "month", "day"]].astype(int)
cleaned_df.head()
80/10:
final_df = cleaned_df.loc[(cleaned_df["month"] == 2) | 
               (cleaned_df["month"] == 3) |
               (cleaned_df["month"] == 10) |
              (cleaned_df["month"] == 11), :]
80/11: #datetime.today().strftime('%m-%d')
80/12:
#df.to_csv('file_name.csv')
final_df.to_csv("california_accidents.zip", index = False, compression = "zip")
   1: %history -g -f notebook_file.ipynb
